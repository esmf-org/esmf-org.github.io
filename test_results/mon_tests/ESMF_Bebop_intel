Return-Path: <svasquez@lcrc.anl.gov>
Delivered-To: unknown
Received: from mail.cgd.ucar.edu (128.117.21.245:993) by bighorn.cgd.ucar.edu
  with IMAP4-SSL; 16 Mar 2020 22:00:02 -0000
X-Original-To: esmftest@cgd.ucar.edu
Delivered-To: esmftest@cgd.ucar.edu
Received: from vscanx2.ucar.edu (vscanx2.ucar.edu [128.117.64.142])
	by post2.cgd.ucar.edu (Postfix) with ESMTP id 96B40C6
	for <esmftest@cgd.ucar.edu>; Mon, 16 Mar 2020 15:59:33 -0600 (MDT)
Received: from mail-io1-f69.google.com (mail-io1-f69.google.com [209.85.166.69])
	by vscanx2.ucar.edu (Postfix) with ESMTPS id 0722A1801980
	for <esmftest@cgd.ucar.edu>; Mon, 16 Mar 2020 15:59:33 -0600 (MDT)
Authentication-Results: vscanx2.ucar.edu;
	dkim=pass (2048-bit key) header.d=anl.gov header.i=@anl.gov header.b="M08q16ii"
Received: by mail-io1-f69.google.com with SMTP id r8so12631230ioj.21
        for <esmftest@cgd.ucar.edu>; Mon, 16 Mar 2020 14:59:33 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20161025;
        h=x-gm-message-state:dkim-signature:ironport-sdr:date:to:subject
         :user-agent:mime-version:content-transfer-encoding:message-id:from;
        bh=EhUnBVAunCD7QhI1q5KpjJeuYVaP5AojEP+pdTOtc0k=;
        b=iqH3sL/HHGxeLG+OxG0ij+odMROc5wbDh9jheAmmieP8ELZ9VckbrU+126HpgF37kD
         st8d9e3KwpIIrP/GBc1Bz6BlWDeOlog1sb2kemoOXz1OiQEUcW7GC1zQecqprKgqKQmp
         7+9DEPii2wlgvfj9c0stRvuy5NcF4g6CcuHn+0pS9HY4raFn8CEv2Lqqfd5v9JfRNbzS
         CiTZJ1afnHxMQCDk2ErvqgHQUZXGQCxn6F0ij0wrkt5wkYg9IZ7O5AfREkxYG2+sL4po
         dUQd/gSoQM9vGCyYTHuSLYRM7Dw29bqJgE8GPdZcAhOdDgcAoJn6OI5LZmEkvfo5XhhO
         Q0Rw==
X-Gm-Message-State: ANhLgQ1WhaI6V3H2VUZbxJp6ZOBcgzniFiRqP9YTqqIrCGieJ4ehpyP5
	OgRBG5TUgvuoYvMWz/DQuVJIMRxzSyMpONQc8Txtb8qXekYyw5CN6BQ6WUT262Ckf1r0kHVkkIq
	1BzA1tUgAvinPwb1/
X-Received: by 2002:a92:6c0e:: with SMTP id h14mr2028667ilc.81.1584395972329;
        Mon, 16 Mar 2020 14:59:32 -0700 (PDT)
X-Google-Smtp-Source: ADFU+vtrFMBbOZTf+MelrMw6syRCjk2gbVTWRmuLpebfdZX73M8IXiD8zMyI2+gbffwXqpuDWsZT
X-Received: by 2002:a92:6c0e:: with SMTP id h14mr2028558ilc.81.1584395970321;
        Mon, 16 Mar 2020 14:59:30 -0700 (PDT)
ARC-Seal: i=1; a=rsa-sha256; t=1584395970; cv=none;
        d=google.com; s=arc-20160816;
        b=ETP6ktNMTvFreKPYx/U5SPW7hhSa+QJQzni8v3dwEESRMw/qo45wLJDSa8BM+DBCbx
         VWoAQ5SsTysp3/4xhWn8F3+tlxa3BuigQ22rzGgGNLtIt374+55LGkf5ULaUqsnQ7M0f
         +rakUAIRD0iS8D6Rp3I7Y4DLYNMz4aZ3MrdYbCBxH9WnI/FUpscqTpLvVNQGwgIFopYq
         mhYPGcSzqZ/cMhy07WzgpItxx0lKtaZfouVXIRT6fHXt4v+Il6aO+Oid6sLFzSYi3tNN
         /M1EAR+YsqUEch6m4icB57a6mVFpksif0rvrYDd+geud+42tFm1SA7PluqeyN4cQAiY3
         Je9g==
ARC-Message-Signature: i=1; a=rsa-sha256; c=relaxed/relaxed; d=google.com; s=arc-20160816;
        h=from:message-id:content-transfer-encoding:mime-version:user-agent
         :subject:to:date:ironport-sdr:dkim-signature;
        bh=EhUnBVAunCD7QhI1q5KpjJeuYVaP5AojEP+pdTOtc0k=;
        b=05e50btz7kd2zXDXngOOiJr1TsZQvSuOX1+Ek3RpbJslrDTX5PVhOi72JQdeTaIM6c
         lFKhzEdTYJPdsvjeNrxrocW9XXd8htRojGErT1cDgIeKL1mH3hUOj2AE2SafKhn8ddfO
         cIBBNyo9kJuqGnZyUTZNGqjjAEBt+mKCdbtNycoilSjd/AahTJVHz+0JPNWTukbRmFzd
         WzAG+GM3Xlw/vnu9Yfr/REw+WTUJvfCjWKTKDTvn7I8uxUIdV48yy6ia/Px+UXg+GUKr
         eGtNvYlbiRmhTG7wAIEqtEBkAT/IQnqrTaj2U6DPuSd8lc1HxTBiQV/TjFaV5X+0iplH
         MaJg==
ARC-Authentication-Results: i=1; mx.google.com;
       dkim=pass header.i=@anl.gov header.s=selector1-anl-gov header.b=M08q16ii;
       spf=pass (google.com: domain of svasquez@lcrc.anl.gov designates 130.202.101.22 as permitted sender) smtp.mailfrom=svasquez@lcrc.anl.gov;
       dmarc=pass (p=REJECT sp=REJECT dis=NONE) header.from=anl.gov
Received: from mailrelay.anl.gov (mailrelay.anl.gov. [130.202.101.22])
        by mx.google.com with ESMTPS id h1si711153jab.64.2020.03.16.14.59.30
        for <esmftest@cgd.ucar.edu>
        (version=TLS1_2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128);
        Mon, 16 Mar 2020 14:59:30 -0700 (PDT)
Received-SPF: pass (google.com: domain of svasquez@lcrc.anl.gov designates 130.202.101.22 as permitted sender) client-ip=130.202.101.22;
Authentication-Results: mx.google.com;
       dkim=pass header.i=@anl.gov header.s=selector1-anl-gov header.b=M08q16ii;
       spf=pass (google.com: domain of svasquez@lcrc.anl.gov designates 130.202.101.22 as permitted sender) smtp.mailfrom=svasquez@lcrc.anl.gov;
       dmarc=pass (p=REJECT sp=REJECT dis=NONE) header.from=anl.gov
Received: from mailgateway.anl.gov (mailgateway.anl.gov [130.202.101.28])
	(using TLSv1.2 with cipher DHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by mailrelay.anl.gov (Postfix) with ESMTPS id DA91A20008B
	for <esmftest@cgd.ucar.edu>; Mon, 16 Mar 2020 16:59:29 -0500 (CDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
  d=anl.gov; i=@anl.gov; q=dns/txt; s=selector1-anl-gov;
  t=1584395969; x=1615931969;
  h=date:to:subject:mime-version:content-transfer-encoding:
   message-id:from;
  bh=EhUnBVAunCD7QhI1q5KpjJeuYVaP5AojEP+pdTOtc0k=;
  b=M08q16iisJeGRKVC+6qx0xhlvhnPUBK+j8rchiEuoNSrANBMPkOnBFjQ
   m8aqQYeF0MFHHC708N80l7M55A5WYBkilHF0eB8rPPC5U8zKroRpwMTmR
   e9XqlHGbxToNOSSzJsdUL5XxxWPxHXJhLiVlw/z2qOFSYQp0ch+gWaXex
   wtXX8xmVSuw9vnENacBuOlMxtVXbkGN++wT84Od8+FN21OuVfLLySqoJ8
   dDYARgQHwjMzSTgAZoZ+iNz9CKQhcRLfugSFPlf8ZYAV9lD6V0Qq3f/kN
   5v0MunN/GOFCHJeK4Oy6xxqDAHV0RQdYyGN0CfAQSYzwYk0OzLyafGtpT
   g==;
IronPort-SDR: jvpxP+9Gdmp4LcGUhFx2z5iQnehfHHKzWseiUJzw106ietfLQj1ozEXSqXI7Bi5BqN7t+07b3Y
 yVaggAinA5Zx7nWgAx6g/AZlRvbm/UjV+IZc17YS9UWOCc3srjqjRMx6WHlMVcjz4AGqOyZ8sQ
 bPPNXG7JxkzgB7pc8I5KFHpuf+2d+dJE7kjGiJb/C+iytbAD+lT0mCjaCCxL4oeRBm/c1XUW0r
 QLUVi4mNroqa0obYxRmcxo79YaNEcM6gOTlD0jBXnGzNEFdPzG4pwy8zMEcSbZYE/z2b3/AjM6
 StY=
X-IronPort-AV: E=Sophos;i="5.70,561,1574143200"; 
   d="scan'208";a="81411685"
Received: from newman-2.mcs.anl.gov (HELO mailrelay.mcs.anl.gov) ([140.221.7.6])
  by mailgateway.anl.gov with ESMTP/TLS/ECDHE-RSA-AES256-GCM-SHA384; 16 Mar 2020 16:59:29 -0500
Received: from beboplogin2.lcrc.anl.gov (beboplogin2.lcrc.anl.gov [140.221.70.6])
	by mailrelay.mcs.anl.gov (Postfix) with ESMTP id 48E90150
	for <esmftest@cgd.ucar.edu>; Mon, 16 Mar 2020 16:59:29 -0500 (CDT)
Received: by beboplogin2.lcrc.anl.gov (Postfix, from userid 2862)
	id 8D5E3ADC415B3; Mon, 16 Mar 2020 16:59:08 -0500 (CDT)
Date: Mon, 16 Mar 2020 16:59:08 -0500
To: esmftest@cgd.ucar.edu
Subject: ESMF_Bebop_intel
User-Agent: Heirloom mailx 12.5 7/5/10
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: quoted-printable
Message-Id: <20200316215908.8D5E3ADC415B3@beboplogin2.lcrc.anl.gov>
From: svasquez@lcrc.anl.gov (Silverio Vasquez)
X-Gm-Spam: 0
X-Gm-Phishy: 0
X-getmail-retrieved-from-mailbox: INBOX





Script start time: Mon Mar 16 04:15:06 CDT 2020

Script end: Mon Mar 16 16:59:08 CDT 2020


________________________________________ESMF TRUNK BUILD AND TEST SUMMA=
RY___________________________



                                           =20
                    INSTALL/
           BUILD  QUICK_START OS.COMPILER.COMM.ABI    UNIT TESTS   EXAM=
PLES  SYSTEM TESTS  APPS TESTS
_______________________________________________________________________=
______________________________
          PASS/FAIL PASS/FAIL                           PASS/FAIL   PAS=
S/FAIL  PASS/FAIL   PASS/FAIL
_______________________________________________________________________=
______________________________
beboplogin2(g)PASS      PASS    Linux.intel.mvapich2.64     8990/85    =
  85/0      46/0      18/0
beboplogin2(O)PASS      PASS    Linux.intel.mvapich2.64      9075/0    =
  85/0      45/1      18/0
beboplogin2(g)PASS      PASS    Linux.intel.mpich3.64        9075/0    =
  85/0      46/0      18/0
beboplogin2(O)PASS      PASS    Linux.intel.mpich3.64        9074/1    =
  85/0      46/0      18/0
beboplogin2(g)PASS      PASS    Linux.intel.openmpi.64       9074/1    =
  84/1      45/1      3/15
beboplogin2(O)PASS      PASS    Linux.intel.openmpi.64       9075/0    =
  85/0      46/0      3/15

_______________________________________________________________________=
________________________


Mon Mar 16 04:21:16 CDT 2020 on beboplogin2=20

ESMF Checkout Source: https://github.com/esmf-org/esmf

Compiler and configuration information:
=20
--------------------------------------------------------------=20

Currently Loaded Modules:
  1) intel/17.0.4-74uvhji
  2) mvapich2/2.3b-gk6kdue

=20

=20
Repository:
origin=09https://github.com/esmf-org/esmf (fetch)
origin=09https://github.com/esmf-org/esmf (push)
=20
ESMF_8_1_0_beta_snapshot_11
=20
=20
=20
--------------------------------------------------------------
ESMF_VERSION_STRING:    8.1.0 beta snapshot
ESMF_8_1_0_beta_snapshot_11
--------------------------------------------------------------
# On branch master
# Untracked files:
#   (use "git add <file>..." to include in what will be committed)
#
#=09tmp
nothing added to commit but untracked files present (use "git add" to t=
rack)
--------------------------------------------------------------
=20
--------------------------------------------------------------
Make version:
GNU Make 3.82
Built for x86_64-redhat-linux-gnu
Copyright (C) 2010  Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl=
.html>
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.

--------------------------------------------------------------
Fortran Compiler version:
mpifort for MVAPICH2 version 2.3b
Intel(R) Fortran Intel(R) 64 Compiler for applications running on Intel=
(R) 64, Version 17.0.4.193 Build 20170408
Copyright (C) 1985-2017 Intel Corporation.  All rights reserved.

ifort version 17.0.4

--------------------------------------------------------------
C++ Compiler version:
mpicxx for MVAPICH2 version 2.3b
Intel(R) C++ Intel(R) 64 Compiler for applications running on Intel(R) =
64, Version 17.0.4.193 Build 20170408
Copyright (C) 1985-2017 Intel Corporation.  All rights reserved.

icpc version 17.0.4 (gcc version 4.8.5 compatibility)

--------------------------------------------------------------
Preprocessor version:
gcc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-36)
Copyright (C) 2015 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is=
 NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURP=
OSE.

=20
--------------------------------------------------------------
 * User set ESMF environment variables *
ESMF_ABI=3D64
ESMF_BOPT=3Dg
ESMF_COMM=3Dmvapich2
ESMF_COMPILER=3Dintel
ESMF_DIR=3D/lcrc/project/ESMF/scripts_dirs/daily_builds/intel_bebop/esm=
f
ESMF_INSTALL_PREFIX=3D/lcrc/project/ESMF/scripts_dirs/daily_builds/inte=
l_bebop/esmf/../install_dir
ESMF_MPIRUN=3D/lcrc/project/ESMF/scripts_dirs/daily_builds/intel_bebop/=
esmf/scripts/mpirun.srun
ESMF_OS=3DLinux
ESMF_PROJ4=3Dexternal
ESMF_PROJ4_INCLUDE=3D/home/svasquez/proj4/include
ESMF_PROJ4_LIBPATH=3D/home/svasquez/proj4/lib
ESMF_SITE=3Ddefault
ESMF_TESTCOMPTUNNEL=3DOFF
ESMF_TESTEXHAUSTIVE=3DON
ESMF_TESTHARNESS_ARRAY=3DRUN_ESMF_TestHarnessArray_default
ESMF_TESTHARNESS_FIELD=3DRUN_ESMF_TestHarnessField_default
ESMF_TESTMPMD=3DOFF
ESMF_TESTWITHTHREADS=3DOFF
=20
--------------------------------------------------------------
 * ESMF environment variables *
ESMF_DIR: /lcrc/project/ESMF/scripts_dirs/daily_builds/intel_bebop/esmf
ESMF_OS:                Linux
ESMF_MACHINE:           x86_64
ESMF_ABI:               64
ESMF_COMPILER:          intel
ESMF_BOPT:              g
ESMF_COMM:              mvapich2
ESMF_SITE:              default
ESMF_PTHREADS:          ON
ESMF_OPENMP:            ON
ESMF_OPENACC:           OFF
ESMF_CXXSTD:            11
ESMF_ARRAY_LITE:        FALSE
ESMF_NO_INTEGER_1_BYTE: TRUE
ESMF_NO_INTEGER_2_BYTE: TRUE
ESMF_FORTRANSYMBOLS:    default
ESMF_MAPPER_BUILD:      OFF
ESMF_AUTO_LIB_BUILD:    ON
ESMF_DEFER_LIB_BUILD:   ON
ESMF_SHARED_LIB_BUILD:  ON
ESMF_TRACE_LIB_BUILD:   ON
ESMF_TESTEXHAUSTIVE:    ON
ESMF_TESTCOMPTUNNEL:    OFF
ESMF_TESTWITHTHREADS:   OFF
ESMF_TESTMPMD:          OFF
ESMF_TESTSHAREDOBJ:     OFF
ESMF_TESTFORCEOPENMP:   OFF
ESMF_TESTFORCEOPENACC:  OFF
ESMF_TESTHARNESS_ARRAY: RUN_ESMF_TestHarnessArray_default
ESMF_TESTHARNESS_FIELD: RUN_ESMF_TestHarnessField_default
ESMF_MPIRUN:            /lcrc/project/ESMF/scripts_dirs/daily_builds/in=
tel_bebop/esmf/scripts/mpirun.srun
=20
--------------------------------------------------------------
 * ESMF environment variables pointing to 3rd party software *
ESMF_MOAB:               internal
ESMF_LAPACK:             internal
ESMF_ACC_SOFTWARE_STACK: none
ESMF_YAMLCPP:            internal
ESMF_PIO:                internal
ESMF_PROJ4:                external
ESMF_PROJ4_INCLUDE:        /home/svasquez/proj4/include
ESMF_PROJ4_LIBS:           -lproj
ESMF_PROJ4_LIBPATH:        /home/svasquez/proj4/lib
=20
--------------------------------------------------------------
 * ESMF environment variables for final installation *
ESMF_INSTALL_PREFIX:    /lcrc/project/ESMF/scripts_dirs/daily_builds/in=
tel_bebop/esmf/../install_dir
ESMF_INSTALL_HEADERDIR: include
ESMF_INSTALL_MODDIR:    mod/modg/Linux.intel.64.mvapich2.default
ESMF_INSTALL_LIBDIR:    lib/libg/Linux.intel.64.mvapich2.default
ESMF_INSTALL_BINDIR:    bin/bing/Linux.intel.64.mvapich2.default
ESMF_INSTALL_DOCDIR:    doc
=20
--------------------------------------------------------------
 * ESMF Benchmark directory and parameters *
ESMF_BENCHMARK_PREFIX:         ./DEFAULTBENCHMARKDIR
ESMF_BENCHMARK_TOLERANCE:      20%
ESMF_BENCHMARK_THRESHOLD_MSEC: 500
=20
--------------------------------------------------------------
 * Other relevant environment variables *
PATH:    /blues/gpfs/home/software/spack-0.10.1/opt/spack/linux-centos7=
-x86_64/intel-17.0.4/mvapich2-2.3b-gk6kduezz3emvxx7gxurx5ittvqbicd6/bin=
:/blues/gpfs/home/software/spack-0.10.1/opt/spack/linux-centos7-x86_64/=
gcc-4.8.5/intel-17.0.4-74uvhjiulyqgvsmywifbbuo46v5n42xc/bin:/home/svasq=
uez/bin:/usr/bin:/bin:/usr/local/sbin:/usr/sbin:/soft/lcrc/bebop/bin:/s=
oft/lcrc/bebop/bin:/soft/lcrc/bebop/bin
LD_LIBRARY_PATH: /blues/gpfs/home/software/spack-0.10.1/opt/spack/linux=
-centos7-x86_64/intel-17.0.4/mvapich2-2.3b-gk6kduezz3emvxx7gxurx5ittvqb=
icd6/lib:/blues/gpfs/home/software/spack-0.10.1/opt/spack/linux-centos7=
-x86_64/gcc-4.8.5/intel-17.0.4-74uvhjiulyqgvsmywifbbuo46v5n42xc/tbb/lib=
/intel64/gcc4.4:/blues/gpfs/home/software/spack-0.10.1/opt/spack/linux-=
centos7-x86_64/gcc-4.8.5/intel-17.0.4-74uvhjiulyqgvsmywifbbuo46v5n42xc/=
lib/intel64
=20
--------------------------------------------------------------
 * Compilers, Linkers, Flags, and Libraries *
Location of the preprocessor:      /usr/bin/gcc
Location of the Fortran compiler:  /blues/gpfs/home/software/spack-0.10=
.1/opt/spack/linux-centos7-x86_64/intel-17.0.4/mvapich2-2.3b-gk6kduezz3=
emvxx7gxurx5ittvqbicd6/bin/mpif90
Location of the Fortran linker:    /blues/gpfs/home/software/spack-0.10=
.1/opt/spack/linux-centos7-x86_64/intel-17.0.4/mvapich2-2.3b-gk6kduezz3=
emvxx7gxurx5ittvqbicd6/bin/mpif90
Location of the C++ compiler:      /blues/gpfs/home/software/spack-0.10=
.1/opt/spack/linux-centos7-x86_64/intel-17.0.4/mvapich2-2.3b-gk6kduezz3=
emvxx7gxurx5ittvqbicd6/bin/mpicxx
Location of the C++ linker:        /blues/gpfs/home/software/spack-0.10=
.1/opt/spack/linux-centos7-x86_64/intel-17.0.4/mvapich2-2.3b-gk6kduezz3=
emvxx7gxurx5ittvqbicd6/bin/mpicxx

Fortran compiler flags:
ESMF_F90COMPILER: mpif90
ESMF_F90COMPILEOPTS: -g -traceback -check arg_temp_created,bounds,forma=
t,output_conversion,stack,uninit -fPIC -assume realloc_lhs -m64 -mcmode=
l=3Dsmall -threads  -qopenmp
ESMF_F90COMPILEPATHS: -I/lcrc/project/ESMF/scripts_dirs/daily_builds/in=
tel_bebop/esmf/mod/modg/Linux.intel.64.mvapich2.default -I/lcrc/project=
/ESMF/scripts_dirs/daily_builds/intel_bebop/esmf/src/include -I/home/sv=
asquez/proj4/include
ESMF_F90COMPILECPPFLAGS: -DESMF_NO_INTEGER_1_BYTE -DESMF_NO_INTEGER_2_B=
YTE -DESMFVERSIONGIT=3D'ESMF_8_1_0_beta_snapshot_11' -DESMF_MOAB=3D1 -D=
ESMF_LAPACK=3D1 -DESMF_LAPACK_INTERNAL=3D1 -DESMF_NO_ACC_SOFTWARE_STACK=
=3D1 -DESMF_YAMLCPP=3D1 -DESMF_YAML=3D1 -DESMF_PIO=3D1 -DESMF_MPIIO -DE=
SMF_PROJ4=3D1 -DESMF_NO_OPENACC -DESMF_TESTEXHAUSTIVE -DESMF_BOPT_g -DS=
x86_64_small=3D1 -DESMF_OS_Linux=3D1 -DESMF_COMM=3Dmvapich2 -DESMF_DIR=
=3D/lcrc/project/ESMF/scripts_dirs/daily_builds/intel_bebop/esmf
ESMF_F90COMPILEFREECPP:=20
ESMF_F90COMPILEFREENOCPP:=20
ESMF_F90COMPILEFIXCPP:=20
ESMF_F90COMPILEFIXNOCPP:=20

Fortran linker flags:
ESMF_F90LINKOPTS:   -m64 -mcmodel=3Dsmall -threads -Wl,--no-as-needed  =
-qopenmp
ESMF_F90LINKPATHS: -L/lcrc/project/ESMF/scripts_dirs/daily_builds/intel=
_bebop/esmf/lib/libg/Linux.intel.64.mvapich2.default -L/home/svasquez/p=
roj4/lib=20
ESMF_F90LINKRPATHS: -Wl,-rpath,/lcrc/project/ESMF/scripts_dirs/daily_bu=
ilds/intel_bebop/esmf/lib/libg/Linux.intel.64.mvapich2.default  -Wl,-rp=
ath,/home/svasquez/proj4/lib
ESMF_F90LINKLIBS:  -cxxlib -lrt -ldl -lproj
ESMF_F90ESMFLINKLIBS: -lesmf  -cxxlib -lrt -ldl -lproj

C++ compiler flags:
ESMF_CXXCOMPILER: mpicxx
ESMF_CXXCOMPILEOPTS: -std=3Dc++11 -g -traceback -Wcheck -fPIC -m64 -mcm=
odel=3Dsmall -pthread  -qopenmp
ESMF_CXXCOMPILEPATHS:  -I/lcrc/project/ESMF/scripts_dirs/daily_builds/i=
ntel_bebop/esmf/src/include  -I/home/svasquez/proj4/include -I/lcrc/pro=
ject/ESMF/scripts_dirs/daily_builds/intel_bebop/esmf/src/prologue/yaml-=
cpp/include
ESMF_CXXCOMPILECPPFLAGS: -DESMF_NO_INTEGER_1_BYTE -DESMF_NO_INTEGER_2_B=
YTE -DESMFVERSIONGIT=3D'ESMF_8_1_0_beta_snapshot_11' -DESMF_MOAB=3D1 -D=
ESMF_LAPACK=3D1 -DESMF_LAPACK_INTERNAL=3D1 -DESMF_NO_ACC_SOFTWARE_STACK=
=3D1 -DESMF_YAMLCPP=3D1 -DESMF_YAML=3D1 -DESMF_PIO=3D1 -DESMF_MPIIO -DE=
SMF_PROJ4=3D1 -DESMF_NO_OPENACC -DESMF_TESTEXHAUSTIVE -DESMF_BOPT_g -DS=
x86_64_small=3D1 -DESMF_OS_Linux=3D1 -DESMF_COMM=3Dmvapich2 -DESMF_DIR=
=3D/lcrc/project/ESMF/scripts_dirs/daily_builds/intel_bebop/esmf -D__SD=
IR__=3D'' -DESMF_CXXSTD=3D11

C++ linker flags:
ESMF_CXXLINKOPTS:   -m64 -mcmodel=3Dsmall -pthread -Wl,--no-as-needed  =
-qopenmp
ESMF_CXXLINKPATHS: -L/lcrc/project/ESMF/scripts_dirs/daily_builds/intel=
_bebop/esmf/lib/libg/Linux.intel.64.mvapich2.default -L/home/svasquez/p=
roj4/lib -L/blues/gpfs/home/software/spack-0.10.1/opt/spack/linux-cento=
s7-x86_64/gcc-4.8.5/intel-17.0.4-74uvhjiulyqgvsmywifbbuo46v5n42xc/compi=
lers_and_libraries_2017.4.193/linux/compiler/lib/intel64_lin/
ESMF_CXXLINKRPATHS: -Wl,-rpath,/lcrc/project/ESMF/scripts_dirs/daily_bu=
ilds/intel_bebop/esmf/lib/libg/Linux.intel.64.mvapich2.default  -Wl,-rp=
ath,/home/svasquez/proj4/lib -Wl,-rpath,/blues/gpfs/home/software/spack=
-0.10.1/opt/spack/linux-centos7-x86_64/gcc-4.8.5/intel-17.0.4-74uvhjiul=
yqgvsmywifbbuo46v5n42xc/compilers_and_libraries_2017.4.193/linux/compil=
er/lib/intel64_lin/
ESMF_CXXLINKLIBS:  -lmpifort -lifport -lifcoremt -limf -lsvml -lm -lipg=
o -liomp5 -lintlc -lpthread -lsvml -ldl -lgcc -lgcc_s -lirc_s -ldl -lrt=
 -ldl -lproj
ESMF_CXXESMFLINKLIBS: -lesmf  -lmpifort -lifport -lifcoremt -limf -lsvm=
l -lm -lipgo -liomp5 -lintlc -lpthread -lsvml -ldl -lgcc -lgcc_s -lirc_=
s -ldl -lrt -ldl -lproj

Shared library build:
ESMF_SL_LIBS_TO_MAKE: libesmf
ESMF_SL_SUFFIX:       so
ESMF_SL_LIBLINKER:    mpicxx
ESMF_SL_LIBOPTS:       -pthread -shared  -qopenmp
ESMF_SL_LIBLIBS:     =20

ESMF Tracing linker options:
ESMF_TRACE_LDPRELOAD=3D/lcrc/project/ESMF/scripts_dirs/daily_builds/int=
el_bebop/esmf/lib/libg/Linux.intel.64.mvapich2.default/libesmftrace_pre=
load.so
ESMF_TRACE_STATICLINKOPTS=3D-static -Wl,--wrap=3Dc_esmftrace_notify_wra=
ppers -Wl,--wrap=3Dc_esmftrace_isinitialized -Wl,--wrap=3Dwrite -Wl,--w=
rap=3Dwritev -Wl,--wrap=3Dpwrite -Wl,--wrap=3Dread -Wl,--wrap=3Dopen -W=
l,--wrap=3DMPI_Allgather -Wl,--wrap=3DMPI_Allgatherv -Wl,--wrap=3DMPI_A=
llreduce -Wl,--wrap=3DMPI_Alltoall -Wl,--wrap=3DMPI_Alltoallv -Wl,--wra=
p=3DMPI_Alltoallw -Wl,--wrap=3DMPI_Barrier -Wl,--wrap=3DMPI_Bcast -Wl,-=
-wrap=3DMPI_Gather -Wl,--wrap=3DMPI_Gatherv -Wl,--wrap=3DMPI_Recv -Wl,-=
-wrap=3DMPI_Reduce -Wl,--wrap=3DMPI_Scatter -Wl,--wrap=3DMPI_Send -Wl,-=
-wrap=3DMPI_Sendrecv -Wl,--wrap=3DMPI_Wait -Wl,--wrap=3DMPI_Waitall -Wl=
,--wrap=3DMPI_Waitany -Wl,--wrap=3DMPI_Waitsome -Wl,--wrap=3Dmpi_allgat=
her_ -Wl,--wrap=3Dmpi_allgather__ -Wl,--wrap=3Dmpi_allgatherv_ -Wl,--wr=
ap=3Dmpi_allgatherv__ -Wl,--wrap=3Dmpi_allreduce_ -Wl,--wrap=3Dmpi_allr=
educe__ -Wl,--wrap=3Dmpi_alltoall_ -Wl,--wrap=3Dmpi_alltoall__ -Wl,--wr=
ap=3Dmpi_alltoallv_ -Wl,--wrap=3Dmpi_alltoallv__ -Wl,--wrap=3Dmpi_allto=
allw_ -Wl,--wrap=3Dmpi_alltoallw__ -Wl,--wrap=3Dmpi_barrier_ -Wl,--wrap=
=3Dmpi_barrier__ -Wl,--wrap=3Dmpi_bcast_ -Wl,--wrap=3Dmpi_bcast__ -Wl,-=
-wrap=3Dmpi_exscan_ -Wl,--wrap=3Dmpi_exscan__ -Wl,--wrap=3Dmpi_gather_ =
-Wl,--wrap=3Dmpi_gather__ -Wl,--wrap=3Dmpi_gatherv_ -Wl,--wrap=3Dmpi_ga=
therv__ -Wl,--wrap=3Dmpi_recv_ -Wl,--wrap=3Dmpi_recv__ -Wl,--wrap=3Dmpi=
_reduce_ -Wl,--wrap=3Dmpi_reduce__ -Wl,--wrap=3Dmpi_reduce_scatter_ -Wl=
,--wrap=3Dmpi_reduce_scatter__ -Wl,--wrap=3Dmpi_scatter_ -Wl,--wrap=3Dm=
pi_scatter__ -Wl,--wrap=3Dmpi_scatterv_ -Wl,--wrap=3Dmpi_scatterv__ -Wl=
,--wrap=3Dmpi_scan_ -Wl,--wrap=3Dmpi_scan__ -Wl,--wrap=3Dmpi_send_ -Wl,=
--wrap=3Dmpi_send__ -Wl,--wrap=3Dmpi_wait_ -Wl,--wrap=3Dmpi_wait__ -Wl,=
--wrap=3Dmpi_waitall_ -Wl,--wrap=3Dmpi_waitall__ -Wl,--wrap=3Dmpi_waita=
ny_ -Wl,--wrap=3Dmpi_waitany__
ESMF_TRACE_STATICLINKLIBS=3D-lesmftrace_static


--------------------------------------------------------------
Compiling on Mon Mar 16 04:21:35 CDT 2020 on beboplogin2
Machine characteristics: Linux beboplogin2 3.10.0-957.21.3.el7.x86_64 #=
1 SMP Tue Jun 18 16:35:19 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
=20
Mon Mar 16 05:12:26 CDT 2020 library build -j16 ...........PASS
Mon Mar 16 05:13:34 CDT 2020 library install -j4 ..........PASS
Mon Mar 16 05:13:39 CDT 2020 library installcheck -j4 .....PASS
Mon Mar 16 05:19:37 CDT 2020 quickstart build -j4 .........PASS

|------------------------ APPs TESTS --------------------------|
Mon Mar 16 05:20:14 CDT 2020 apps build -j4 ...............PASS

|--------------------------------------------------------------|
Mon Mar 16 05:20:22 CDT 2020 ESMF_Regrid --help ...........PASS
The following is the output of ESMF_Regrid --help

 Usage: ESMF_Regrid
                       --source|-s src_grid_filename
                       --destination|-d dst_grid_filename
                       --src_var varname1[,varname2,...]
                       --dst_var  varname1[,varname2,...]
                       [--srcdatafile]
                       [--dstdatafile]
                       [--tilefile_path tile_file_path]
                       [--dst_loc center|corner]
                       [--method|-m bilinear|patch|neareststod|nearestd=
tos|conse
 rve|conserve2nd]
                       [--pole|-p all|none|teeth|<N>]
                       [--ignore_unmapped|-i]
                       [--ignore_degenerate]
                       [-r]
                       [--src_regional]
                       [--dst_regional]
                       [--check]
                       [--no_log]
                       [--help]
                       [--version]
                       [-V]
 where
 --source or -s - a required argument specifying the source grid file
               name
 --destination or -d - a required argument specifying the destination g=
rid
               file name
 --src_var  - a required argument specifying the variable names to be r=
egridded
               in the source grid file.  If more than one, separated th=
em with
               comma.
 --dst_var  - a required argument specifying the destination variable n=
ame in
               the destination grid file.  If more than one, separated =
them with
               comma.  The number of dst_vars has to be the same as the=
 number
               of src_var
 --srcdatafile - If the source grid is of type MOSAIC, the data is stor=
ed=20
               in separated files, one per tile. srcdatafile is the pre=
fix of
               the source data file.  The filename is srcdatafile.tilen=
ame.nc,
               where tilename is the tile name defined in the source gr=
id file
 --dstdatafile - If the destination grid is of type MOSAIC, the data is=
 stored
               in separated files, one per tile. dstdatafile is the pre=
fix of
               the destination data file.  The filename is srcdatafile.=
tilename.
 nc,
                where tilename is the tile name defined in the destinat=
ion grid=20
 file
 --tilefile_path - The alternative file path for the tile files and mos=
aic data=20
 files
               when either srcFile or dstFile is a GRIDSPEC MOSAIC grid=
.  The pa
 th
               can be either relative or absolute.  If it is relative, =
it is
               relative to the working directory.  When specified, the =
gridlocat
 ion
               variable defined in the Mosaic file will be ignored.
 --method or -m - an optional argument specifying which interpolation m=
ethod is
               used.  The default method is bilinear
 --pole or -p - an optional argument indicating what to do with the pol=
e.
               The default value is all
 --ignore_unmapped or -i - ignore unmapped destination points. If not s=
pecified,
               the default is to stop with an error.
 --ignore_degenerate - ignore degenerate cells in the input grids. If n=
ot specif
 ied,
               the default is to stop with an error.
 -r          - an optional argument specifying the source and destinati=
on grids
               are regional grids.  Without this argument, the grids ar=
e assumed
               to be global. This argument only applies to the GRIDSPEC=
 file
 --src_regional   - an optional argument specifying the source grid is =
regional.
               Without this argument, the src grids is assumed to be gl=
obal. Thi
 s=20
               argument only applies to the GRIDSPEC file
 --dst_regional   - an optional argument specifying the destination gri=
d is regi
 onal
               Without this argument, the dst grids is assumed to be gl=
obal.
               This argument only applies to the GRIDSPEC file
 --check    - Check the regridded fields by comparing the values with
              a synthetic field calculated based on its coordinates.=20
              The mean relative error between the destination field=20
              and synthetic field is computed.  The synthetic value is =
calculate
 d as=20
              data(i,j,k,l)=3D2.0+(k-1)+2*(l-1)+cos(lat(i,j))**2*cos(2*=
lon(i,j)),=20
 assuming
              it is a 2D grid=20
 --no_log    - Turn off the ESMF error log.
 --help     - Print this help message and exit.
 --version  - Print ESMF version and license information and exit.
 -V        - Print ESMF version number and exit.
=20
 For questions, comments, or feature requests please send email to:
 esmf_support@cgd.ucar.edu
=20
 Visit http://www.earthsystemmodeling.org/ to find out more about the
 Earth System Modeling Framework.
=20



|--------------------------------------------------------------|
Mon Mar 16 05:20:23 CDT 2020 ESMF_Regrid --version ........PASS
The following is the output of ESMF_Regrid --version

   ESMF_VERSION_STRING:       8.1.0 beta snapshot
   ESMF_VERSION_MAJOR:                   8
   ESMF_VERSION_MINOR:                   1
   ESMF_VERSION_REVISION:                0
   ESMF_VERSION_PATCHLEVEL:              0
   ESMF_VERSION_PUBLIC:        F
   ESMF_VERSION_BETASNAPSHOT:  T
=20
 Earth System Modeling Framework
=20
 Copyright (c) 2002-2020 University Corporation for Atmospheric Researc=
h,
 Massachusetts Institute of Technology, Geophysical Fluid Dynamics Labo=
ratory,
 University of Michigan, National Centers for Environmental Prediction,
 Los Alamos National Laboratory, Argonne National Laboratory,
 NASA Goddard Space Flight Center.
 All rights reserved.
=20
 Permission is hereby granted, free of charge, to any person obtaining =
a copy
 of this software and associated documentation files (the 'Software'), =
to
 deal with the Software without restriction, including without limitati=
on the
 rights to use, copy, modify, merge, publish, distribute, sublicense, a=
nd/or
 sell copies of the Software, and to permit persons to whom the Softwar=
e is
 furnished to do so, subject to the following conditions:
    1. Redistributions of source code must retain the above copyright n=
otice,
       this list of conditions and the following disclaimers.
    2. Redistributions in binary form must reproduce the above copyrigh=
t
       notice, this list of conditions and the following disclaimers in=
 the
       documentation and/or other materials provided with the distribut=
ion.
    3. Neither the names of the organizations developing this software,=
 nor
       the names of its contributors may be used to endorse or promote =
products
       derived from this Software without specific prior written permis=
sion.
=20
 THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRES=
S OR
 IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILIT=
Y,
 FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHAL=
L THE
 CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR =
OTHER
 LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISIN=
G
 FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DE=
ALINGS
 WITH THE SOFTWARE.



|--------------------------------------------------------------|
Mon Mar 16 05:20:24 CDT 2020 ESMF_Regrid -V ...............PASS
The following is the output of ESMF_Regrid -V

   ESMF_VERSION_STRING:       8.1.0 beta snapshot



|--------------------------------------------------------------|
Mon Mar 16 05:20:25 CDT 2020 ESMF_Info --help .............PASS
The following is the output of ESMF_Info --help=20

 ESMF_Info: Print information about the ESMF installation.
 Options:
   --help        Display this information and exit.
   --version     Display ESMF version and license information and exit.
   -V            Display ESMF version string and exit.
=20



|--------------------------------------------------------------|
Mon Mar 16 05:20:26 CDT 2020 ESMF_Info --version ..........PASS
The following is the output of ESMF_Info --version=20

   ESMF_VERSION_STRING:       8.1.0 beta snapshot
   ESMF_VERSION_MAJOR:                   8
   ESMF_VERSION_MINOR:                   1
   ESMF_VERSION_REVISION:                0
   ESMF_VERSION_PATCHLEVEL:              0
   ESMF_VERSION_PUBLIC:        F
   ESMF_VERSION_BETASNAPSHOT:  T
=20
 Earth System Modeling Framework
=20
 Copyright (c) 2002-2020 University Corporation for Atmospheric Researc=
h,
 Massachusetts Institute of Technology, Geophysical Fluid Dynamics Labo=
ratory,
 University of Michigan, National Centers for Environmental Prediction,
 Los Alamos National Laboratory, Argonne National Laboratory,
 NASA Goddard Space Flight Center.
 All rights reserved.
=20
 Permission is hereby granted, free of charge, to any person obtaining =
a copy
 of this software and associated documentation files (the 'Software'), =
to
 deal with the Software without restriction, including without limitati=
on the
 rights to use, copy, modify, merge, publish, distribute, sublicense, a=
nd/or
 sell copies of the Software, and to permit persons to whom the Softwar=
e is
 furnished to do so, subject to the following conditions:
    1. Redistributions of source code must retain the above copyright n=
otice,
       this list of conditions and the following disclaimers.
    2. Redistributions in binary form must reproduce the above copyrigh=
t
       notice, this list of conditions and the following disclaimers in=
 the
       documentation and/or other materials provided with the distribut=
ion.
    3. Neither the names of the organizations developing this software,=
 nor
       the names of its contributors may be used to endorse or promote =
products
       derived from this Software without specific prior written permis=
sion.
=20
 THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRES=
S OR
 IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILIT=
Y,
 FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHAL=
L THE
 CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR =
OTHER
 LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISIN=
G
 FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DE=
ALINGS
 WITH THE SOFTWARE.



|--------------------------------------------------------------|
Mon Mar 16 05:20:27 CDT 2020 ESMF_Info -V .................PASS
The following is the output of ESMF_Info -V=20

   ESMF_VERSION_STRING:       8.1.0 beta snapshot



|--------------------------------------------------------------|
Mon Mar 16 05:20:28 CDT 2020 ESMF_InfoC --help ............PASS
The following is the output of ESMF_InfoC --help

ESMF_InfoC: Print information about the ESMF installation.
Options:
  --help        Display this information and exit.
  --version     Display ESMF version and license information and exit.
  -V            Display ESMF version string and exit.




|--------------------------------------------------------------|
Mon Mar 16 05:20:29 CDT 2020 ESMF_InfoC --version .........PASS
The following is the output of ESMF_InfoC --version

   ESMF_VERSION_STRING:       8.1.0 beta snapshot
   ESMF_VERSION_MAJOR:                   8
   ESMF_VERSION_MINOR:                   1
   ESMF_VERSION_REVISION:                0
   ESMF_VERSION_PATCHLEVEL:              0
   ESMF_VERSION_PUBLIC:        F
   ESMF_VERSION_BETASNAPSHOT:  T
=20
 Earth System Modeling Framework
=20
 Copyright (c) 2002-2020 University Corporation for Atmospheric Researc=
h,
 Massachusetts Institute of Technology, Geophysical Fluid Dynamics Labo=
ratory,
 University of Michigan, National Centers for Environmental Prediction,
 Los Alamos National Laboratory, Argonne National Laboratory,
 NASA Goddard Space Flight Center.
 All rights reserved.
=20
 Permission is hereby granted, free of charge, to any person obtaining =
a copy
 of this software and associated documentation files (the 'Software'), =
to
 deal with the Software without restriction, including without limitati=
on the
 rights to use, copy, modify, merge, publish, distribute, sublicense, a=
nd/or
 sell copies of the Software, and to permit persons to whom the Softwar=
e is
 furnished to do so, subject to the following conditions:
    1. Redistributions of source code must retain the above copyright n=
otice,
       this list of conditions and the following disclaimers.
    2. Redistributions in binary form must reproduce the above copyrigh=
t
       notice, this list of conditions and the following disclaimers in=
 the
       documentation and/or other materials provided with the distribut=
ion.
    3. Neither the names of the organizations developing this software,=
 nor
       the names of its contributors may be used to endorse or promote =
products
       derived from this Software without specific prior written permis=
sion.
=20
 THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRES=
S OR
 IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILIT=
Y,
 FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHAL=
L THE
 CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR =
OTHER
 LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISIN=
G
 FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DE=
ALINGS
 WITH THE SOFTWARE.



|--------------------------------------------------------------|
Mon Mar 16 05:20:30 CDT 2020 ESMF_InfoC -V ................PASS
The following is the output of ESMF_InfoC -V

   ESMF_VERSION_STRING:       8.1.0 beta snapshot



|--------------------------------------------------------------|
Mon Mar 16 05:20:31 CDT 2020 ESMF_RegridWeightGen --help ..PASS
The following is the output of ESMF_RegridWeightGen --help

 Usage: ESMF_RegridWeightGen --source|-s src_grid_filename
                            --destination|-d dst_grid_filename
                       --weight|-w out_weight_file=20
                       [--method|-m bilinear|patch|neareststod|nearestd=
tos|conse
 rve|conserve2nd]
                       [--pole|-p all|none|teeth|<N>]
                       [--line_type|-l cartesian|greatcircle]
                       [--norm_type dstarea|fracarea]
                       [--extrap_method none|neareststod|nearestidavg|c=
reep]
                       [--extrap_num_src_pnts <N>]
                       [--extrap_dist_exponent <P>]
                       [--extrap_num_levels <L>]
                       [--ignore_unmapped|-i]
                       [--ignore_degenerate]
                       [-r]
                       [--src_regional]
                       [--dst_regional]
                       [--64bit_offset]
                       [--netcdf4]
                       [--weight_only]
                       [--src_missingvalue src_var_name]
                       [--dst_missingvalue dst_var_name]
                       [--src_coordinates lon_var_name,lat_var_name]
                       [--dst_coordinates lon_var_name,lat_var_name]
                       [--user_areas]
                       [--src_loc center|corner]
                       [--dst_loc center|corner]
                       [--tilefile_path tile_file_path]
                       [--no_log]
                       [--check]
                       [--help]
                       [--version]
                       [-V]
 where
 --source or -s - a required argument specifying the source grid file
                  name
 --destination or -d - a required argument specifying the destination g=
rid
                       file name
 --weight or -w - a required argument specifying the output regridding =
weight
                  file name
 --method or -m - an optional argument specifying which interpolation m=
ethod is
                  used.  The default method is bilinear.
 --pole or -p - an optional argument indicating what to do with the pol=
e.
                  The default value is all.
 --line_type or -l - an optional argument indicating the type of path
                      lines (e.g. cell edges) follow on a spherical
                     surface. The default value depends on the regrid
                     method. For non-conservative methods the default i=
s
                     cartesian. For conservative methods the default is=
 greatcir
 cle.
 --norm_type - an optional argument indicating the type of normalizatio=
n to
               do when generating conserative weights. The default valu=
e is dsta
 rea.
 --extrap_method - an optional argument specifying which extrapolation =
method is
                  used.  The default method is none.
 --extrap_num_src_pnts - an optional argument specifying how many sourc=
e points=20
 should
                 be used when the extrapolation method is nearestidavg.=
 The defa
 ult is 8.
 --extrap_dist_exponent - an optional argument specifying the exponent =
that the=20
 distance should
                 be raised to when the extrapolation method is nearesti=
davg. The
  default is 2.0.
 --extrap_num_levels - an optional argument specifying how many levels =
should
                 be filled for level based extrapolation methods (e.g. =
creep).
 --ignore_unmapped or -i - ignore unmapped destination points. If not s=
pecified,
                           the default is to stop with an error.
 --ignore_degenerate - ignore degenerate cells in the input grids. If n=
ot specif
 ied,
                           the default is to stop with an error.
 -r         - an optional argument specifying the source and destinatio=
n grids
              are regional grids.  Without this argument, the grids are=
 assumed
              to be global
 --src_regional   - an optional argument specifying the source grid is =
regional.
              Without this argument, the src grids is assumed to be glo=
bal.
 --dst_regional   - an optional argument specifying the destination gri=
d is regi
 onal
              Without this argument, the dst grids is assumed to be glo=
bal.
 --64bit_offset  - an optional argument specifying the output weight fi=
le is in
              NetCDF 64-bit offset format.  This option only works with=
 NetCDF l
 ibrary
              version 3.6 and above
 --netcdf4  - an optional argument specifying the output weight file is=
 in
              the NetCDF4 format. This option only works with NetCDF li=
brary
              version 4.1 and above
 --weight_only  - an Optional argument specifying the output weight fil=
e only co
 ntains
              the weights and the source and destination grid's indices=
.
 --src_missingvalue  - an optional argument used when the src file type=
 is GRIDS
 PEC
              or UGRID. It defines the variable name whose 'missing_val=
ue' or
              '_FillValue' attribute will be used to construct the mask=
 for the=20
 source
              grid. Without this argument,a GRIDSPEC file or a UGRID fi=
le is not
  masked.
 --dst_missingvalue  - an optional argument used when the destination f=
ile type=20
 is
              GRIDSPEC or UGRID. It defines the variable name whose 'mi=
ssing_val
 ue' or
              '_FillValue' attribute will be used to construct the mask=
 for the=20
 destination
              grid. Without this argument,a GRIDSPEC file or a UGRID fi=
le is not
  masked.
 --src_coordinates  - an optional argument used when the source grid ty=
pe is GRI
 DSPEC.
              It defines the longitude and latitude variable names sepa=
rated by=20
 comma,
              in case there are multiple coordinate variables defined i=
n the fil
 e
 --dst_coordinates  - an optional argument used when the destination gr=
id type i
 s GRIDSPEC.
              It defines the longitude and latitude variable names sepa=
rated by=20
 comma,
              in case there are multiple coordinate variables defined i=
n the fil
 e
 --user_areas  - an optional argument specifying that the conservation =
is adjust
 ed to
              hold for the user areas provided in the grid files.  If n=
ot specif
 ied,
              then the conservation will hold for the ESMF calculated (=
great cir
 cle)
              areas.  Whichever areas the conservation holds for are ou=
tput to t
 he
              weight file.
 --src_loc   - an optional argument specifying which location is used t=
o do the=20
 regridding
             The location can be either 'center' or 'corner'.  Currentl=
y, this a
 rgument
             is only required when the source grid file is an unstructu=
red grid=20
 defined
             in UGRID or ESMF format and the regridding method is non-c=
onservati
 ve. For =20
             all other cases, the default location is 'center'.
 --dst_loc   - an optional argument specifying which location is used t=
o do the=20
 regridding
             The location can be either 'center' or 'corner'.  Currentl=
y, this a
 rgument
             is 'center'.  Currently, this argument will only be used w=
hen the
             is only required when the destination grid file is an unst=
ructured=20
 grid defined
             in UGRID or ESMF format and the regridding method is non-c=
onservati
 ve. For =20
             all other cases, the default location is 'center'.
 --tilefile_path - the alternative file path for the tile files when th=
e grid fi
 le type is
             MOSAIC.
 --no_log    - Turn off the ESMF logs.
 --check    - Check that the generated weights produce reasonable regri=
dded fiel
 ds.  This
              is done by calling ESMF_FieldRegrid() on an analytic sour=
ce field=20
 using the weights
              generated by this application.  The mean relative error b=
etween th
 e destination
              and analytic field is computed, as well as the relative e=
rror betw
 een the mass
              of the source and destination fields in the conservative =
case.
 --help     - Print this help message and exit.
 --version  - Print ESMF version and license information and exit.
 -V        - Print ESMF version number and exit.
=20
 For questions, comments, or feature requests please send email to:
 esmf_support@cgd.ucar.edu
=20
 Visit http://www.earthsystemmodeling.org/ to find out more about the
 Earth System Modeling Framework.
=20



|--------------------------------------------------------------|
Mon Mar 16 05:20:32 CDT 2020 ESMF_RegridWeightGen --version PASS
The following is the output of ESMF_RegridWeightGen --version

   ESMF_VERSION_STRING:       8.1.0 beta snapshot
   ESMF_VERSION_MAJOR:                   8
   ESMF_VERSION_MINOR:                   1
   ESMF_VERSION_REVISION:                0
   ESMF_VERSION_PATCHLEVEL:              0
   ESMF_VERSION_PUBLIC:        F
   ESMF_VERSION_BETASNAPSHOT:  T
=20
 Earth System Modeling Framework
=20
 Copyright (c) 2002-2020 University Corporation for Atmospheric Researc=
h,
 Massachusetts Institute of Technology, Geophysical Fluid Dynamics Labo=
ratory,
 University of Michigan, National Centers for Environmental Prediction,
 Los Alamos National Laboratory, Argonne National Laboratory,
 NASA Goddard Space Flight Center.
 All rights reserved.
=20
 Permission is hereby granted, free of charge, to any person obtaining =
a copy
 of this software and associated documentation files (the 'Software'), =
to
 deal with the Software without restriction, including without limitati=
on the
 rights to use, copy, modify, merge, publish, distribute, sublicense, a=
nd/or
 sell copies of the Software, and to permit persons to whom the Softwar=
e is
 furnished to do so, subject to the following conditions:
    1. Redistributions of source code must retain the above copyright n=
otice,
       this list of conditions and the following disclaimers.
    2. Redistributions in binary form must reproduce the above copyrigh=
t
       notice, this list of conditions and the following disclaimers in=
 the
       documentation and/or other materials provided with the distribut=
ion.
    3. Neither the names of the organizations developing this software,=
 nor
       the names of its contributors may be used to endorse or promote =
products
       derived from this Software without specific prior written permis=
sion.
=20
 THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRES=
S OR
 IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILIT=
Y,
 FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHAL=
L THE
 CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR =
OTHER
 LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISIN=
G
 FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DE=
ALINGS
 WITH THE SOFTWARE.



|--------------------------------------------------------------|
Mon Mar 16 05:20:32 CDT 2020 ESMF_RegridWeightGen -V ......PASS
The following is the output of ESMF_RegridWeightGen -V

   ESMF_VERSION_STRING:       8.1.0 beta snapshot



|--------------------------------------------------------------|
Mon Mar 16 05:20:33 CDT 2020 ESMF_Scrip2Unstruct --help ...PASS
The following is the output of ESMF_Scrip2Unstruct --help

ESMF_Scrip2Unstruct: Convert an unstructured grid file in SCRIP format =
into either a ESMF unstructured file or a UGRID file format.
Usage: ESMF_Scrip2Unstruct [--help] [--version] [-V] inputfile outputfi=
le dualflag [fileformat]
    [--help]        Display this information and exit.
    [--version]     Display ESMF version and license information and ex=
it.
    [-V]            Display ESMF version string and exit.
    inputfile       input grid filename=20
    outputfile      output filename=20
    dualflag        1 to generate a dual mesh, 0 for non-dual mesh
    [fileformat]    Either ESMF or UGRID, the default is ESMF




|--------------------------------------------------------------|
Mon Mar 16 05:20:34 CDT 2020 ESMF_Scrip2Unstruct --version PASS
The following is the output of ESMF_Scrip2Unstruct --version

   ESMF_VERSION_STRING:       8.1.0 beta snapshot
   ESMF_VERSION_MAJOR:                   8
   ESMF_VERSION_MINOR:                   1
   ESMF_VERSION_REVISION:                0
   ESMF_VERSION_PATCHLEVEL:              0
   ESMF_VERSION_PUBLIC:        F
   ESMF_VERSION_BETASNAPSHOT:  T
=20
 Earth System Modeling Framework
=20
 Copyright (c) 2002-2020 University Corporation for Atmospheric Researc=
h,
 Massachusetts Institute of Technology, Geophysical Fluid Dynamics Labo=
ratory,
 University of Michigan, National Centers for Environmental Prediction,
 Los Alamos National Laboratory, Argonne National Laboratory,
 NASA Goddard Space Flight Center.
 All rights reserved.
=20
 Permission is hereby granted, free of charge, to any person obtaining =
a copy
 of this software and associated documentation files (the 'Software'), =
to
 deal with the Software without restriction, including without limitati=
on the
 rights to use, copy, modify, merge, publish, distribute, sublicense, a=
nd/or
 sell copies of the Software, and to permit persons to whom the Softwar=
e is
 furnished to do so, subject to the following conditions:
    1. Redistributions of source code must retain the above copyright n=
otice,
       this list of conditions and the following disclaimers.
    2. Redistributions in binary form must reproduce the above copyrigh=
t
       notice, this list of conditions and the following disclaimers in=
 the
       documentation and/or other materials provided with the distribut=
ion.
    3. Neither the names of the organizations developing this software,=
 nor
       the names of its contributors may be used to endorse or promote =
products
       derived from this Software without specific prior written permis=
sion.
=20
 THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRES=
S OR
 IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILIT=
Y,
 FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHAL=
L THE
 CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR =
OTHER
 LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISIN=
G
 FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DE=
ALINGS
 WITH THE SOFTWARE.



|--------------------------------------------------------------|
Mon Mar 16 05:20:35 CDT 2020 ESMF_Scrip2Unstruct -V .......PASS
The following is the output of ESMF_Scrip2Unstruct -V

   ESMF_VERSION_STRING:       8.1.0 beta snapshot



|--------------------------------------------------------------|
Mon Mar 16 05:20:39 CDT 2020 ESMF_WebServController --help PASS
The following is the output of ESMF_WebServController --help

ESMF_WebServController: Run a Process Controller that provides access t=
o an ESMF Web Service enabled Component.
Usage: ESMF_WebServController [--help] [--version] [-V] procCtrlPort re=
gistrarHost registrarPort
    [--help]        Display this information and exit.
    [--version]     Display ESMF version and license information and ex=
it.
    [-V]            Display ESMF version string and exit.
    procCtrlPort    Port num for Process Controller listener.
    registrarHost   Host name on which Registrar is running.
    registrarPort   Port num on which Registrar is listening.
    runScriptDir    Directory containing run script.
    runScriptFile   File name of run script.




|--------------------------------------------------------------|
Mon Mar 16 05:20:39 CDT 2020 ESMF_WebServController --version PASS
The following is the output of ESMF_WebServController --version

   ESMF_VERSION_STRING:       8.1.0 beta snapshot
   ESMF_VERSION_MAJOR:                   8
   ESMF_VERSION_MINOR:                   1
   ESMF_VERSION_REVISION:                0
   ESMF_VERSION_PATCHLEVEL:              0
   ESMF_VERSION_PUBLIC:        F
   ESMF_VERSION_BETASNAPSHOT:  T
=20
 Earth System Modeling Framework
=20
 Copyright (c) 2002-2020 University Corporation for Atmospheric Researc=
h,
 Massachusetts Institute of Technology, Geophysical Fluid Dynamics Labo=
ratory,
 University of Michigan, National Centers for Environmental Prediction,
 Los Alamos National Laboratory, Argonne National Laboratory,
 NASA Goddard Space Flight Center.
 All rights reserved.
=20
 Permission is hereby granted, free of charge, to any person obtaining =
a copy
 of this software and associated documentation files (the 'Software'), =
to
 deal with the Software without restriction, including without limitati=
on the
 rights to use, copy, modify, merge, publish, distribute, sublicense, a=
nd/or
 sell copies of the Software, and to permit persons to whom the Softwar=
e is
 furnished to do so, subject to the following conditions:
    1. Redistributions of source code must retain the above copyright n=
otice,
       this list of conditions and the following disclaimers.
    2. Redistributions in binary form must reproduce the above copyrigh=
t
       notice, this list of conditions and the following disclaimers in=
 the
       documentation and/or other materials provided with the distribut=
ion.
    3. Neither the names of the organizations developing this software,=
 nor
       the names of its contributors may be used to endorse or promote =
products
       derived from this Software without specific prior written permis=
sion.
=20
 THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRES=
S OR
 IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILIT=
Y,
 FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHAL=
L THE
 CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR =
OTHER
 LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISIN=
G
 FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DE=
ALINGS
 WITH THE SOFTWARE.



|--------------------------------------------------------------|
Mon Mar 16 05:20:39 CDT 2020 ESMF_WebServController -V ....PASS
The following is the output of ESMF_WebServController -V

   ESMF_VERSION_STRING:       8.1.0 beta snapshot




Ran 18 applications tests, 18 passed and 0 failed.

|----------------------- SYSTEM TESTS -------------------------|
Mon Mar 16 05:25:32 CDT 2020 build_system_tests -j4 .......PASS
Mon Mar 16 05:28:58 CDT 2020 run_system_tests .............PASS


The following system tests passed:


PASS: mvapich2/g: src/system_tests/ESMF_ArrayBundleRedist/ESMF_ArrayBun=
dleRedistSTest.F90
PASS: mvapich2/g: src/system_tests/ESMF_ArrayBundleSparseMatMul/ESMF_Ar=
rayBundleSparseMatMulSTest.F90
PASS: mvapich2/g: src/system_tests/ESMF_ArrayRedist/ESMF_ArrayRedistSTe=
st.F90
PASS: mvapich2/g: src/system_tests/ESMF_ArrayRedist3D/ESMF_ArrayRedist3=
DSTest.F90
PASS: mvapich2/g: src/system_tests/ESMF_ArrayRedistOpenACC/ESMF_ArrayRe=
distOpenACCSTest.F90
PASS: mvapich2/g: src/system_tests/ESMF_ArrayRedistOpenMP/ESMF_ArrayRed=
istOpenMPSTest.F90
PASS: mvapich2/g: src/system_tests/ESMF_ArrayScatterGather/ESMF_ArraySc=
atterGatherSTest.F90
PASS: mvapich2/g: src/system_tests/ESMF_ArraySharedDeSSI/ESMF_ArrayShar=
edDeSSISTest.F90
PASS: mvapich2/g: src/system_tests/ESMF_ArraySparseMatMul/ESMF_ArraySpa=
rseMatMulSTest.F90
PASS: mvapich2/g: src/system_tests/ESMF_Attribute/ESMF_AttributeSTest.F=
90
PASS: mvapich2/g: src/system_tests/ESMF_AttributeCIM/ESMF_AttributeCIMS=
Test.F90
PASS: mvapich2/g: src/system_tests/ESMF_CompCreate/ESMF_CompCreateSTest=
.F90
PASS: mvapich2/g: src/system_tests/ESMF_CompFortranAndC/ESMF_CompFortra=
nAndCSTest.F90
PASS: mvapich2/g: src/system_tests/ESMF_ComplianceChecker/ESMF_Complian=
ceCheckerSTest.F90
PASS: mvapich2/g: src/system_tests/ESMF_ConcurrentComponent/ESMF_Concur=
rentCompSTest.F90
PASS: mvapich2/g: src/system_tests/ESMF_ConcurrentEnsemble/ESMF_Concurr=
entEnsembleSTest.F90
PASS: mvapich2/g: src/system_tests/ESMF_DirectCoupling/ESMF_DirectCoupl=
ingSTest.F90
PASS: mvapich2/g: src/system_tests/ESMF_FieldBundleLSRedistArb2Arb/ESMF=
_FieldBundleLSRedistArb2ArbSTest.F90
PASS: mvapich2/g: src/system_tests/ESMF_FieldBundleLSRedistArb2ArbUngrd=
Dim/ESMF_FieldBundleLSRedistArb2ArbUngrdDimSTest.F90
PASS: mvapich2/g: src/system_tests/ESMF_FieldBundleRedistArb2Arb/ESMF_F=
ieldBundleRedistArb2ArbSTest.F90
PASS: mvapich2/g: src/system_tests/ESMF_FieldBundleRedistBlk2Arb/ESMF_F=
ieldBundleRedistBlk2ArbSTest.F90
PASS: mvapich2/g: src/system_tests/ESMF_FieldBundleRedistBlk2Blk/ESMF_F=
ieldBundleRedistBlk2BlkSTest.F90
PASS: mvapich2/g: src/system_tests/ESMF_FieldBundleSMM/ESMF_FieldBundle=
SMMSTest.F90
PASS: mvapich2/g: src/system_tests/ESMF_FieldBundleSMMPacked/ESMF_Field=
BundleSMMPackedSTest.F90
PASS: mvapich2/g: src/system_tests/ESMF_FieldConcurrentComp/ESMF_FieldC=
onCompSTest.F90
PASS: mvapich2/g: src/system_tests/ESMF_FieldLSRedistArb2Arb/ESMF_Field=
LSRedistArb2ArbSTest.F90
PASS: mvapich2/g: src/system_tests/ESMF_FieldLSRedistArb2ArbUngrdDim/ES=
MF_FieldLSRedistArb2ArbUngrdDimSTest.F90
PASS: mvapich2/g: src/system_tests/ESMF_FieldLSSMM/ESMF_FieldLSSMMSTest=
.F90
PASS: mvapich2/g: src/system_tests/ESMF_FieldMeshSMM/ESMF_FieldMeshSMMS=
Test.F90
PASS: mvapich2/g: src/system_tests/ESMF_FieldRedist/ESMF_FieldRedistSTe=
st.F90
PASS: mvapich2/g: src/system_tests/ESMF_FieldRedistArb2Arb/ESMF_FieldRe=
distArb2ArbSTest.F90
PASS: mvapich2/g: src/system_tests/ESMF_FieldRedistBlk2Arb/ESMF_FieldRe=
distBlk2ArbSTest.F90
PASS: mvapich2/g: src/system_tests/ESMF_FieldRedistBlk2Blk/ESMF_FieldRe=
distBlk2BlkSTest.F90
PASS: mvapich2/g: src/system_tests/ESMF_FieldRegrid/ESMF_FieldRegridSTe=
st.F90
PASS: mvapich2/g: src/system_tests/ESMF_FieldRegridDisjoint/ESMF_FieldR=
egridDisjointSTest.F90
PASS: mvapich2/g: src/system_tests/ESMF_FieldRegridMesh/ESMF_FieldRegri=
dMeshSTest.F90
PASS: mvapich2/g: src/system_tests/ESMF_FieldRegridMeshToMesh/ESMF_Fiel=
dRegridMeshToMeshSTest.F90
PASS: mvapich2/g: src/system_tests/ESMF_FieldRegridOverlap/ESMF_FieldRe=
gridOverlapSTest.F90
PASS: mvapich2/g: src/system_tests/ESMF_FieldSparseMatMul/ESMF_FieldSpa=
rseMatMulSTest.F90
PASS: mvapich2/g: src/system_tests/ESMF_RecursiveComponent/ESMF_Recursi=
veComponentSTest.F90
PASS: mvapich2/g: src/system_tests/ESMF_SequentialEnsemble/ESMF_Sequent=
ialEnsembleSTest.F90
PASS: mvapich2/g: src/system_tests/ESMF_Trace/ESMF_TraceSTest.F90
PASS: mvapich2/g: src/system_tests/ESMF_TransferGrid/ESMF_TransferGridS=
Test.F90
PASS: mvapich2/g: src/system_tests/ESMF_TransferMesh/ESMF_TransferMeshS=
Test.F90
PASS: mvapich2/g: src/system_tests/ESMF_XGridConcurrent/ESMF_XGridConcu=
rrentSTest.F90
PASS: mvapich2/g: src/system_tests/ESMF_XGridSerial/ESMF_XGridSerialSTe=
st.F90




The stdout files for the system_tests can be found at:
/lcrc/project/ESMF/scripts_dirs/daily_builds/intel_bebop/esmf/test/test=
g/Linux.intel.64.mvapich2.default


Found 46 multi-processor system tests, 46 passed and 0 failed.



|------------------------- EXAMPLES ---------------------------|
Mon Mar 16 05:40:17 CDT 2020 build_examples -j4 ...........PASS
Mon Mar 16 05:49:27 CDT 2020 run_examples .................PASS


The following examples passed:


PASS: mvapich2/g: src/Infrastructure/Array/examples/ESMF_ArrayArbHaloEx=
.F90
PASS: mvapich2/g: src/Infrastructure/Array/examples/ESMF_ArrayCommNBEx.=
F90
PASS: mvapich2/g: src/Infrastructure/Array/examples/ESMF_ArrayEx.F90
PASS: mvapich2/g: src/Infrastructure/Array/examples/ESMF_ArrayFarrayEx.=
F90
PASS: mvapich2/g: src/Infrastructure/Array/examples/ESMF_ArrayFarrayHal=
oEx.F90
PASS: mvapich2/g: src/Infrastructure/Array/examples/ESMF_ArrayHaloEx.F9=
0
PASS: mvapich2/g: src/Infrastructure/Array/examples/ESMF_ArrayLarrayEx.=
F90
PASS: mvapich2/g: src/Infrastructure/Array/examples/ESMF_ArrayRedistEx.=
F90
PASS: mvapich2/g: src/Infrastructure/Array/examples/ESMF_ArrayScatterGa=
therArbEx.F90
PASS: mvapich2/g: src/Infrastructure/Array/examples/ESMF_ArrayScatterGa=
therEx.F90
PASS: mvapich2/g: src/Infrastructure/Array/examples/ESMF_ArraySparseMat=
MulEx.F90
PASS: mvapich2/g: src/Infrastructure/ArrayBundle/examples/ESMF_ArrayBun=
dleEx.F90
PASS: mvapich2/g: src/Infrastructure/ArrayBundle/examples/ESMF_ArrayBun=
dleHaloEx.F90
PASS: mvapich2/g: src/Infrastructure/ArraySpec/examples/ESMF_ArraySpecE=
x.F90
PASS: mvapich2/g: src/Infrastructure/Config/examples/ESMF_ConfigOvervie=
wEx.F90
PASS: mvapich2/g: src/Infrastructure/DELayout/examples/ESMF_DELayoutEx.=
F90
PASS: mvapich2/g: src/Infrastructure/DistGrid/examples/ESMF_DistGridEx.=
F90
PASS: mvapich2/g: src/Infrastructure/Field/examples/ESMF_FieldArbGridEx=
.F90
PASS: mvapich2/g: src/Infrastructure/Field/examples/ESMF_FieldCommEx.F9=
0
PASS: mvapich2/g: src/Infrastructure/Field/examples/ESMF_FieldCreateEx.=
F90
PASS: mvapich2/g: src/Infrastructure/Field/examples/ESMF_FieldEx.F90
PASS: mvapich2/g: src/Infrastructure/Field/examples/ESMF_FieldHaloEx.F9=
0
PASS: mvapich2/g: src/Infrastructure/Field/examples/ESMF_FieldMeshRegri=
dEx.F90
PASS: mvapich2/g: src/Infrastructure/Field/examples/ESMF_FieldRedistEx.=
F90
PASS: mvapich2/g: src/Infrastructure/Field/examples/ESMF_FieldRegridEx.=
F90
PASS: mvapich2/g: src/Infrastructure/Field/examples/ESMF_FieldRegridMas=
kEx.F90
PASS: mvapich2/g: src/Infrastructure/Field/examples/ESMF_FieldRepDimEx.=
F90
PASS: mvapich2/g: src/Infrastructure/Field/examples/ESMF_FieldSMMEx.F90
PASS: mvapich2/g: src/Infrastructure/Field/examples/ESMF_FieldSphereReg=
ridEx.F90
PASS: mvapich2/g: src/Infrastructure/FieldBundle/examples/ESMF_FieldBun=
dleCreateEx.F90
PASS: mvapich2/g: src/Infrastructure/FieldBundle/examples/ESMF_FieldBun=
dleHaloEx.F90
PASS: mvapich2/g: src/Infrastructure/FieldBundle/examples/ESMF_FieldBun=
dleRedistEx.F90
PASS: mvapich2/g: src/Infrastructure/FieldBundle/examples/ESMF_FieldBun=
dleSMMEx.F90
PASS: mvapich2/g: src/Infrastructure/Grid/examples/ESMF_GridCreateRegFr=
omDGEx.F90
PASS: mvapich2/g: src/Infrastructure/Grid/examples/ESMF_GridUsageEx.F90
PASS: mvapich2/g: src/Infrastructure/LocStream/examples/ESMF_LocStreamE=
x.F90
PASS: mvapich2/g: src/Infrastructure/LogErr/examples/ESMF_LogErrEx.F90
PASS: mvapich2/g: src/Infrastructure/Mesh/examples/ESMF_MeshEx.F90
PASS: mvapich2/g: src/Infrastructure/Route/examples/ESMF_RHandleBitForB=
itEx.F90
PASS: mvapich2/g: src/Infrastructure/Route/examples/ESMF_RHandleDynamic=
MaskingEx.F90
PASS: mvapich2/g: src/Infrastructure/Route/examples/ESMF_RHandleFromFil=
eEx.F90
PASS: mvapich2/g: src/Infrastructure/Route/examples/ESMF_RHandleFromRHa=
ndleEx.F90
PASS: mvapich2/g: src/Infrastructure/Route/examples/ESMF_RHandleReusabi=
lityEx.F90
PASS: mvapich2/g: src/Infrastructure/TimeMgr/examples/ESMF_AlarmEx.F90
PASS: mvapich2/g: src/Infrastructure/TimeMgr/examples/ESMF_CalendarEx.F=
90
PASS: mvapich2/g: src/Infrastructure/TimeMgr/examples/ESMF_ClockEx.F90
PASS: mvapich2/g: src/Infrastructure/TimeMgr/examples/ESMF_TimeEx.F90
PASS: mvapich2/g: src/Infrastructure/TimeMgr/examples/ESMF_TimeInterval=
Ex.F90
PASS: mvapich2/g: src/Infrastructure/Trace/examples/ESMF_TraceEx.F90
PASS: mvapich2/g: src/Infrastructure/Trace/examples/ESMF_TraceUserEx.F9=
0
PASS: mvapich2/g: src/Infrastructure/VM/examples/ESMF_VMAllFullReduceEx=
.F90
PASS: mvapich2/g: src/Infrastructure/VM/examples/ESMF_VMComponentEx.F90
PASS: mvapich2/g: src/Infrastructure/VM/examples/ESMF_VMDefaultBasicsEx=
.F90
PASS: mvapich2/g: src/Infrastructure/VM/examples/ESMF_VMGetMPICommunica=
torEx.F90
PASS: mvapich2/g: src/Infrastructure/VM/examples/ESMF_VMHigherRankDataE=
x.F90
PASS: mvapich2/g: src/Infrastructure/VM/examples/ESMF_VMScatterVMGather=
Ex.F90
PASS: mvapich2/g: src/Infrastructure/VM/examples/ESMF_VMSendVMRecvEx.F9=
0
PASS: mvapich2/g: src/Infrastructure/VM/examples/ESMF_VMUserMpiCommEx.F=
90
PASS: mvapich2/g: src/Infrastructure/VM/examples/ESMF_VMUserMpiCommMult=
iEx.F90
PASS: mvapich2/g: src/Infrastructure/VM/examples/ESMF_VMUserMpiEx.F90
PASS: mvapich2/g: src/Infrastructure/XGrid/examples/ESMF_XGridEx.F90
PASS: mvapich2/g: src/Infrastructure/XGrid/examples/ESMF_XGridSparseMat=
Ex.F90
PASS: mvapich2/g: src/Superstructure/AttachMethods/examples/ESMF_Attach=
MethodsEx.F90
PASS: mvapich2/g: src/Superstructure/AttributeAPI/examples/ESMF_AttRead=
CustCplCompEx.F90
PASS: mvapich2/g: src/Superstructure/AttributeAPI/examples/ESMF_AttRead=
FieldEx.F90
PASS: mvapich2/g: src/Superstructure/AttributeAPI/examples/ESMF_AttRead=
GridCompEx.F90
PASS: mvapich2/g: src/Superstructure/AttributeAPI/examples/ESMF_Attribu=
teCIMEx.F90
PASS: mvapich2/g: src/Superstructure/AttributeAPI/examples/ESMF_Attribu=
teCustPackEx.F90
PASS: mvapich2/g: src/Superstructure/AttributeAPI/examples/ESMF_Attribu=
teEx.F90
PASS: mvapich2/g: src/Superstructure/AttributeAPI/examples/ESMF_Attribu=
teInternalInfoEx.F90
PASS: mvapich2/g: src/Superstructure/AttributeAPI/examples/ESMF_Attribu=
tePackageEx.F90
PASS: mvapich2/g: src/Superstructure/AttributeAPI/examples/ESMF_Attribu=
teUpdateEx.F90
PASS: mvapich2/g: src/Superstructure/Component/examples/ESMF_AppMainEx.=
F90
PASS: mvapich2/g: src/Superstructure/Component/examples/ESMF_CompTunnel=
Ex.F90
PASS: mvapich2/g: src/Superstructure/Component/examples/ESMF_CplEx.F90
PASS: mvapich2/g: src/Superstructure/Component/examples/ESMF_GCompEx.F9=
0
PASS: mvapich2/g: src/Superstructure/Component/examples/ESMF_InternalSt=
ateEx.F90
PASS: mvapich2/g: src/Superstructure/Component/examples/ESMF_InternalSt=
ateModEx.F90
PASS: mvapich2/g: src/Superstructure/Component/examples/ESMF_SCompEx.F9=
0
PASS: mvapich2/g: src/Superstructure/State/examples/ESMF_StateEx.F90
PASS: mvapich2/g: src/Superstructure/State/examples/ESMF_StateReadWrite=
Ex.F90
PASS: mvapich2/g: src/Superstructure/State/examples/ESMF_StateReconcile=
Ex.F90
PASS: mvapich2/g: src/Superstructure/WebServices/examples/ESMF_WebServi=
cesEx.F90
PASS: mvapich2/g: src/addon/NUOPC/examples/ESMF_NUOPCAtmModelEx.F90
PASS: mvapich2/g: src/addon/NUOPC/examples/ESMF_NUOPCBasicModelEx.F90




The stdout files for the examples can be found at:
/lcrc/project/ESMF/scripts_dirs/daily_builds/intel_bebop/esmf/examples/=
examplesg/Linux.intel.64.mvapich2.default


Found 85 multi-processor examples, 85 passed and 0 failed.



|-------------------- EXHAUSTIVE UNIT TESTS -------------------|
Mon Mar 16 06:13:17 CDT 2020 build_unit_tests -j4 .........PASS
Mon Mar 16 06:31:22 CDT 2020 run_unit_tests ...............PASS




The unit tests in the following files all pass:

PASS: mvapich2/g: src/Infrastructure/Array/tests/ESMC_ArrayUTest.C
PASS: mvapich2/g: src/Infrastructure/Array/tests/ESMF_ArrayArbIdxSMMUTe=
st.F90
PASS: mvapich2/g: src/Infrastructure/Array/tests/ESMF_ArrayCreateGetUTe=
st.F90
PASS: mvapich2/g: src/Infrastructure/Array/tests/ESMF_ArrayDataUTest.F9=
0
PASS: mvapich2/g: src/Infrastructure/Array/tests/ESMF_ArrayGatherUTest.=
F90
PASS: mvapich2/g: src/Infrastructure/Array/tests/ESMF_ArrayHaloUTest.F9=
0
PASS: mvapich2/g: src/Infrastructure/Array/tests/ESMF_ArrayIOUTest.F90
PASS: mvapich2/g: src/Infrastructure/Array/tests/ESMF_ArrayRedistPerfUT=
est.F90
PASS: mvapich2/g: src/Infrastructure/Array/tests/ESMF_ArrayRedistUTest.=
F90
PASS: mvapich2/g: src/Infrastructure/Array/tests/ESMF_ArraySMMFromFileU=
Test.F90
PASS: mvapich2/g: src/Infrastructure/Array/tests/ESMF_ArraySMMUTest.F90
PASS: mvapich2/g: src/Infrastructure/Array/tests/ESMF_ArrayScatterUTest=
.F90
PASS: mvapich2/g: src/Infrastructure/ArrayBundle/tests/ESMF_ArrayBundle=
CreateUTest.F90
PASS: mvapich2/g: src/Infrastructure/ArrayBundle/tests/ESMF_ArrayBundle=
IOUTest.F90
PASS: mvapich2/g: src/Infrastructure/ArrayBundle/tests/ESMF_ArrayBundle=
RedistUTest.F90
PASS: mvapich2/g: src/Infrastructure/ArraySpec/tests/ESMC_ArraySpecUTes=
t.C
PASS: mvapich2/g: src/Infrastructure/ArraySpec/tests/ESMF_ArraySpecUTes=
t.F90
PASS: mvapich2/g: src/Infrastructure/Base/tests/ESMC_BaseUTest.C
PASS: mvapich2/g: src/Infrastructure/Base/tests/ESMF_BaseUTest.F90
PASS: mvapich2/g: src/Infrastructure/Config/tests/ESMC_ConfigUTest.C
PASS: mvapich2/g: src/Infrastructure/Config/tests/ESMF_ConfigUTest.F90
PASS: mvapich2/g: src/Infrastructure/Container/tests/ESMF_ContainerUTes=
t.F90
PASS: mvapich2/g: src/Infrastructure/DELayout/tests/ESMF_DELayoutUTest.=
F90
PASS: mvapich2/g: src/Infrastructure/DELayout/tests/ESMF_DELayoutWorkQu=
eueUTest.F90
PASS: mvapich2/g: src/Infrastructure/DistGrid/tests/ESMC_DistGridUTest.=
C
PASS: mvapich2/g: src/Infrastructure/DistGrid/tests/ESMF_DistGridCreate=
GetUTest.F90
PASS: mvapich2/g: src/Infrastructure/Field/tests/ESMC_FieldGridGridRegr=
idCsrvUTest.C
PASS: mvapich2/g: src/Infrastructure/Field/tests/ESMC_FieldGridGridRegr=
idUTest.C
PASS: mvapich2/g: src/Infrastructure/Field/tests/ESMC_FieldGridRegrid2U=
Test.C
PASS: mvapich2/g: src/Infrastructure/Field/tests/ESMC_FieldGridRegridCs=
rv2UTest.C
PASS: mvapich2/g: src/Infrastructure/Field/tests/ESMC_FieldGridRegridCs=
rvUTest.C
PASS: mvapich2/g: src/Infrastructure/Field/tests/ESMC_FieldGridRegridPa=
rUTest.C
PASS: mvapich2/g: src/Infrastructure/Field/tests/ESMC_FieldGridRegridUT=
est.C
PASS: mvapich2/g: src/Infrastructure/Field/tests/ESMC_FieldRegridCsrvUT=
est.C
PASS: mvapich2/g: src/Infrastructure/Field/tests/ESMC_FieldRegridUTest.=
C
PASS: mvapich2/g: src/Infrastructure/Field/tests/ESMC_FieldSMMFromFileU=
Test.C
PASS: mvapich2/g: src/Infrastructure/Field/tests/ESMC_FieldUTest.C
PASS: mvapich2/g: src/Infrastructure/Field/tests/ESMF_FieldArbGridUTest=
.F90
PASS: mvapich2/g: src/Infrastructure/Field/tests/ESMF_FieldCreateGetUTe=
st.F90
PASS: mvapich2/g: src/Infrastructure/Field/tests/ESMF_FieldGatherUTest.=
F90
PASS: mvapich2/g: src/Infrastructure/Field/tests/ESMF_FieldHaloUTest.F9=
0
PASS: mvapich2/g: src/Infrastructure/Field/tests/ESMF_FieldLSSMMUTest.F=
90
PASS: mvapich2/g: src/Infrastructure/Field/tests/ESMF_FieldRedistArbUTe=
st.F90
PASS: mvapich2/g: src/Infrastructure/Field/tests/ESMF_FieldRedistUTest.=
F90
PASS: mvapich2/g: src/Infrastructure/Field/tests/ESMF_FieldRegridCSUTes=
t.F90
PASS: mvapich2/g: src/Infrastructure/Field/tests/ESMF_FieldRegridCsrv2n=
dUTest.F90
PASS: mvapich2/g: src/Infrastructure/Field/tests/ESMF_FieldRegridCsrvUT=
est.F90
PASS: mvapich2/g: src/Infrastructure/Field/tests/ESMF_FieldRegridUTest.=
F90
PASS: mvapich2/g: src/Infrastructure/Field/tests/ESMF_FieldRegridXGSMMU=
Test.F90
PASS: mvapich2/g: src/Infrastructure/Field/tests/ESMF_FieldRegridXGUTes=
t.F90
PASS: mvapich2/g: src/Infrastructure/Field/tests/ESMF_FieldSMMFromFileU=
Test.F90
PASS: mvapich2/g: src/Infrastructure/Field/tests/ESMF_FieldSMMUTest.F90
PASS: mvapich2/g: src/Infrastructure/Field/tests/ESMF_FieldStressUTest.=
F90
PASS: mvapich2/g: src/Infrastructure/Field/tests/ESMF_FieldUTest.F90
PASS: mvapich2/g: src/Infrastructure/FieldBundle/tests/ESMF_FieldBundle=
CrGetUTest.F90
PASS: mvapich2/g: src/Infrastructure/FieldBundle/tests/ESMF_FieldBundle=
IOUTest.F90
PASS: mvapich2/g: src/Infrastructure/FieldBundle/tests/ESMF_FieldBundle=
RedistUTest.F90
PASS: mvapich2/g: src/Infrastructure/FieldBundle/tests/ESMF_FieldBundle=
RegridUTest.F90
PASS: mvapich2/g: src/Infrastructure/FieldBundle/tests/ESMF_FieldBundle=
SMMUTest.F90
PASS: mvapich2/g: src/Infrastructure/FieldBundle/tests/ESMF_FieldBundle=
UTest.F90
PASS: mvapich2/g: src/Infrastructure/Grid/tests/ESMC_GridUTest.C
PASS: mvapich2/g: src/Infrastructure/Grid/tests/ESMF_GridArbitraryUTest=
.F90
PASS: mvapich2/g: src/Infrastructure/Grid/tests/ESMF_GridCoordUTest.F90
PASS: mvapich2/g: src/Infrastructure/Grid/tests/ESMF_GridCreateUTest.F9=
0
PASS: mvapich2/g: src/Infrastructure/Grid/tests/ESMF_GridItemUTest.F90
PASS: mvapich2/g: src/Infrastructure/GridUtil/tests/ESMF_GridToMeshUTes=
t.F90
PASS: mvapich2/g: src/Infrastructure/IO/tests/ESMCI_IO_NetCDFUTest.C
PASS: mvapich2/g: src/Infrastructure/IO/tests/ESMCI_IO_PIOUTest.C
PASS: mvapich2/g: src/Infrastructure/IO/tests/ESMC_IO_InqUTest.C
PASS: mvapich2/g: src/Infrastructure/IO/tests/ESMF_IOUTest.F90
PASS: mvapich2/g: src/Infrastructure/IO/tests/ESMF_IO_PIOUTest.F90
PASS: mvapich2/g: src/Infrastructure/IO/tests/ESMF_IO_YAMLUTest.F90
PASS: mvapich2/g: src/Infrastructure/LocStream/tests/ESMC_LocStreamUTes=
t.C
PASS: mvapich2/g: src/Infrastructure/LocStream/tests/ESMF_LocStreamUTes=
t.F90
PASS: mvapich2/g: src/Infrastructure/LocalArray/tests/ESMF_LocalArrayDa=
taUTest.F90
PASS: mvapich2/g: src/Infrastructure/LocalArray/tests/ESMF_LocalArrayUT=
est.F90
PASS: mvapich2/g: src/Infrastructure/LogErr/tests/ESMC_LogErrPerfUTest.=
C
PASS: mvapich2/g: src/Infrastructure/LogErr/tests/ESMC_LogErrUTest.C
PASS: mvapich2/g: src/Infrastructure/LogErr/tests/ESMF_LogErrPerfUTest.=
F90
PASS: mvapich2/g: src/Infrastructure/LogErr/tests/ESMF_LogErrUTest.F90
PASS: mvapich2/g: src/Infrastructure/Mesh/tests/ESMC_MBMesh_BilinearPar=
UTest.C
PASS: mvapich2/g: src/Infrastructure/Mesh/tests/ESMC_MBMesh_BilinearSin=
gleElemUTest.C
PASS: mvapich2/g: src/Infrastructure/Mesh/tests/ESMC_MBMesh_BilinearUTe=
st.C
PASS: mvapich2/g: src/Infrastructure/Mesh/tests/ESMC_MBMesh_CreateParUT=
est.C
PASS: mvapich2/g: src/Infrastructure/Mesh/tests/ESMC_MBMesh_CreateUTest=
.C
PASS: mvapich2/g: src/Infrastructure/Mesh/tests/ESMC_MBMesh_SearchUTest=
.C
PASS: mvapich2/g: src/Infrastructure/Mesh/tests/ESMC_MBMesh_SerializeUT=
est.C
PASS: mvapich2/g: src/Infrastructure/Mesh/tests/ESMC_MBMesh_UtilParUTes=
t.C
PASS: mvapich2/g: src/Infrastructure/Mesh/tests/ESMC_MBMesh_UtilUTest.C
PASS: mvapich2/g: src/Infrastructure/Mesh/tests/ESMC_MeshMOABUTest.C
PASS: mvapich2/g: src/Infrastructure/Mesh/tests/ESMC_MeshUTest.C
PASS: mvapich2/g: src/Infrastructure/Mesh/tests/ESMC_MeshVTKUTest.C
PASS: mvapich2/g: src/Infrastructure/Mesh/tests/ESMC_Proj4UTest.C
PASS: mvapich2/g: src/Infrastructure/Mesh/tests/ESMF_MeshOpUTest.F90
PASS: mvapich2/g: src/Infrastructure/Mesh/tests/ESMF_MeshUTest.F90
PASS: mvapich2/g: src/Infrastructure/PointList/tests/ESMF_PointListUTes=
t.F90
PASS: mvapich2/g: src/Infrastructure/Route/tests/ESMF_RouteHandleAdvanc=
edUTest.F90
PASS: mvapich2/g: src/Infrastructure/Route/tests/ESMF_RouteHandleUTest.=
F90
PASS: mvapich2/g: src/Infrastructure/TimeMgr/tests/ESMC_CalendarUTest.C
PASS: mvapich2/g: src/Infrastructure/TimeMgr/tests/ESMC_ClockUTest.C
PASS: mvapich2/g: src/Infrastructure/TimeMgr/tests/ESMC_TimeIntervalUTe=
st.C
PASS: mvapich2/g: src/Infrastructure/TimeMgr/tests/ESMC_TimeUTest.C
PASS: mvapich2/g: src/Infrastructure/TimeMgr/tests/ESMF_AlarmUTest.F90
PASS: mvapich2/g: src/Infrastructure/TimeMgr/tests/ESMF_CalRangeUTest.F=
90
PASS: mvapich2/g: src/Infrastructure/TimeMgr/tests/ESMF_CalendarUTest.F=
90
PASS: mvapich2/g: src/Infrastructure/TimeMgr/tests/ESMF_ClockUTest.F90
PASS: mvapich2/g: src/Infrastructure/TimeMgr/tests/ESMF_TimeIntervalUTe=
st.F90
PASS: mvapich2/g: src/Infrastructure/TimeMgr/tests/ESMF_TimeUTest.F90
PASS: mvapich2/g: src/Infrastructure/Trace/tests/ESMC_TraceRegionUTest.=
C
PASS: mvapich2/g: src/Infrastructure/Trace/tests/ESMF_ProfileUTest.F90
PASS: mvapich2/g: src/Infrastructure/Trace/tests/ESMF_TraceClkMonoSyncU=
Test.F90
PASS: mvapich2/g: src/Infrastructure/Trace/tests/ESMF_TraceClkMonoUTest=
.F90
PASS: mvapich2/g: src/Infrastructure/Trace/tests/ESMF_TraceIOUTest.F90
PASS: mvapich2/g: src/Infrastructure/Trace/tests/ESMF_TraceMPIUTest.F90
PASS: mvapich2/g: src/Infrastructure/Trace/tests/ESMF_TraceUTest.F90
PASS: mvapich2/g: src/Infrastructure/Util/tests/ESMF_FortranWordsizeUTe=
st.F90
PASS: mvapich2/g: src/Infrastructure/Util/tests/ESMF_InitMacrosUTest.F9=
0
PASS: mvapich2/g: src/Infrastructure/Util/tests/ESMF_TypeKindGetUTest.F=
90
PASS: mvapich2/g: src/Infrastructure/Util/tests/ESMF_UtilUTest.F90
PASS: mvapich2/g: src/Infrastructure/VM/tests/ESMC_VMUTest.C
PASS: mvapich2/g: src/Infrastructure/VM/tests/ESMF_VMAccUTest.F90
PASS: mvapich2/g: src/Infrastructure/VM/tests/ESMF_VMAllGatherUTest.F90
PASS: mvapich2/g: src/Infrastructure/VM/tests/ESMF_VMAllGatherVUTest.F9=
0
PASS: mvapich2/g: src/Infrastructure/VM/tests/ESMF_VMAllToAllUTest.F90
PASS: mvapich2/g: src/Infrastructure/VM/tests/ESMF_VMAllToAllVUTest.F90
PASS: mvapich2/g: src/Infrastructure/VM/tests/ESMF_VMBarrierUTest.F90
PASS: mvapich2/g: src/Infrastructure/VM/tests/ESMF_VMBroadcastUTest.F90
PASS: mvapich2/g: src/Infrastructure/VM/tests/ESMF_VMComponentUTest.F90
PASS: mvapich2/g: src/Infrastructure/VM/tests/ESMF_VMGatherUTest.F90
PASS: mvapich2/g: src/Infrastructure/VM/tests/ESMF_VMOpenMPUTest.F90
PASS: mvapich2/g: src/Infrastructure/VM/tests/ESMF_VMScatterUTest.F90
PASS: mvapich2/g: src/Infrastructure/VM/tests/ESMF_VMSendNbVMRecvNbUTes=
t.F90
PASS: mvapich2/g: src/Infrastructure/VM/tests/ESMF_VMSendRecvNbUTest.F9=
0
PASS: mvapich2/g: src/Infrastructure/VM/tests/ESMF_VMSendRecvUTest.F90
PASS: mvapich2/g: src/Infrastructure/VM/tests/ESMF_VMSendVMRecvUTest.F9=
0
PASS: mvapich2/g: src/Infrastructure/VM/tests/ESMF_VMUTest.F90
PASS: mvapich2/g: src/Infrastructure/VM/tests/ESMF_VMUserMpiInitUTest.F=
90
PASS: mvapich2/g: src/Infrastructure/XGrid/tests/ESMC_XGridUTest.C
PASS: mvapich2/g: src/Infrastructure/XGrid/tests/ESMF_XGridMaskingUTest=
.F90
PASS: mvapich2/g: src/Infrastructure/XGrid/tests/ESMF_XGridUTest.F90
PASS: mvapich2/g: src/Superstructure/AttributeAPI/tests/ESMF_AttInterna=
lGridUTest.F90
PASS: mvapich2/g: src/Superstructure/AttributeAPI/tests/ESMF_AttPackABu=
ndleUTest.F90
PASS: mvapich2/g: src/Superstructure/AttributeAPI/tests/ESMF_AttPackArr=
ayUTest.F90
PASS: mvapich2/g: src/Superstructure/AttributeAPI/tests/ESMF_AttPackCpl=
CompUTest.F90
PASS: mvapich2/g: src/Superstructure/AttributeAPI/tests/ESMF_AttPackDis=
tGridUTest.F90
PASS: mvapich2/g: src/Superstructure/AttributeAPI/tests/ESMF_AttPackFBu=
ndleUTest.F90
PASS: mvapich2/g: src/Superstructure/AttributeAPI/tests/ESMF_AttPackFie=
ldUTest.F90
PASS: mvapich2/g: src/Superstructure/AttributeAPI/tests/ESMF_AttPackGri=
dCompUTest.F90
PASS: mvapich2/g: src/Superstructure/AttributeAPI/tests/ESMF_AttPackGri=
dUTest.F90
PASS: mvapich2/g: src/Superstructure/AttributeAPI/tests/ESMF_AttPackLoc=
StreamUTest.F90
PASS: mvapich2/g: src/Superstructure/AttributeAPI/tests/ESMF_AttPackSci=
CompUTest.F90
PASS: mvapich2/g: src/Superstructure/AttributeAPI/tests/ESMF_AttPackSta=
teUTest.F90
PASS: mvapich2/g: src/Superstructure/AttributeAPI/tests/ESMF_AttReadCpl=
CompUTest.F90
PASS: mvapich2/g: src/Superstructure/AttributeAPI/tests/ESMF_AttReadFie=
ldUTest.F90
PASS: mvapich2/g: src/Superstructure/AttributeAPI/tests/ESMF_AttReadGri=
dCompUTest.F90
PASS: mvapich2/g: src/Superstructure/AttributeAPI/tests/ESMF_AttributeA=
BundleUTest.F90
PASS: mvapich2/g: src/Superstructure/AttributeAPI/tests/ESMF_AttributeA=
rrayUTest.F90
PASS: mvapich2/g: src/Superstructure/AttributeAPI/tests/ESMF_AttributeA=
utoLinkUTest.F90
PASS: mvapich2/g: src/Superstructure/AttributeAPI/tests/ESMF_AttributeC=
plCompUTest.F90
PASS: mvapich2/g: src/Superstructure/AttributeAPI/tests/ESMF_AttributeD=
istGridUTest.F90
PASS: mvapich2/g: src/Superstructure/AttributeAPI/tests/ESMF_AttributeF=
BundleUTest.F90
PASS: mvapich2/g: src/Superstructure/AttributeAPI/tests/ESMF_AttributeF=
ieldUTest.F90
PASS: mvapich2/g: src/Superstructure/AttributeAPI/tests/ESMF_AttributeG=
ridCompUTest.F90
PASS: mvapich2/g: src/Superstructure/AttributeAPI/tests/ESMF_AttributeG=
ridUTest.F90
PASS: mvapich2/g: src/Superstructure/AttributeAPI/tests/ESMF_AttributeJ=
SONUTest.F90
PASS: mvapich2/g: src/Superstructure/AttributeAPI/tests/ESMF_AttributeL=
ocStreamUTest.F90
PASS: mvapich2/g: src/Superstructure/AttributeAPI/tests/ESMF_AttributeS=
ciCompUTest.F90
PASS: mvapich2/g: src/Superstructure/AttributeAPI/tests/ESMF_AttributeS=
tateUTest.F90
PASS: mvapich2/g: src/Superstructure/AttributeAPI/tests/ESMF_AttributeU=
pdateCIMRespPartyUTest.F90
PASS: mvapich2/g: src/Superstructure/AttributeAPI/tests/ESMF_AttributeU=
pdateClosedLoopTreesUTest.F90
PASS: mvapich2/g: src/Superstructure/AttributeAPI/tests/ESMF_AttributeU=
pdateComponentUTest.F90
PASS: mvapich2/g: src/Superstructure/AttributeAPI/tests/ESMF_AttributeU=
pdateContainerStressUTest.F90
PASS: mvapich2/g: src/Superstructure/AttributeAPI/tests/ESMF_AttributeU=
pdateMultiReconcileUTest.F90
PASS: mvapich2/g: src/Superstructure/AttributeAPI/tests/ESMF_AttributeU=
pdateReconcileUTest.F90
PASS: mvapich2/g: src/Superstructure/AttributeAPI/tests/ESMF_AttributeU=
pdateRemoveOnlyUTest.F90
PASS: mvapich2/g: src/Superstructure/AttributeAPI/tests/ESMF_AttributeU=
pdateUTest.F90
PASS: mvapich2/g: src/Superstructure/AttributeAPI/tests/ESMF_AttributeW=
riteInternalUTest.F90
PASS: mvapich2/g: src/Superstructure/AttributeAPI/tests/ESMF_AttributeX=
MLUTest.F90
PASS: mvapich2/g: src/Superstructure/Component/tests/ESMC_ComponentUTes=
t.C
PASS: mvapich2/g: src/Superstructure/Component/tests/ESMF_CompSetServUT=
est.F90
PASS: mvapich2/g: src/Superstructure/Component/tests/ESMF_CompTunnelUTe=
st.F90
PASS: mvapich2/g: src/Superstructure/Component/tests/ESMF_ComponentUTes=
t.F90
PASS: mvapich2/g: src/Superstructure/Component/tests/ESMF_CplCompCreate=
UTest.F90
PASS: mvapich2/g: src/Superstructure/Component/tests/ESMF_GridCompCreat=
eUTest.F90
PASS: mvapich2/g: src/Superstructure/Component/tests/ESMF_SciCompCreate=
UTest.F90
PASS: mvapich2/g: src/Superstructure/Component/tests/ESMF_StdCompMethod=
sUTest.F90
PASS: mvapich2/g: src/Superstructure/ESMFMod/tests/ESMF_FrameworkUTest.=
F90
PASS: mvapich2/g: src/Superstructure/IOAPI/tests/ESMF_IOCompUTest.F90
PASS: mvapich2/g: src/Superstructure/PreESMFMod/tests/ESMF_FileRegridUT=
est.F90
PASS: mvapich2/g: src/Superstructure/PreESMFMod/tests/ESMF_RegridWeight=
GenUTest.F90
PASS: mvapich2/g: src/Superstructure/State/tests/ESMC_StateUTest.C
PASS: mvapich2/g: src/Superstructure/State/tests/ESMF_StateCreateUTest.=
F90
PASS: mvapich2/g: src/Superstructure/State/tests/ESMF_StateReadWriteUTe=
st.F90
PASS: mvapich2/g: src/Superstructure/State/tests/ESMF_StateReconcileUTe=
st.F90
PASS: mvapich2/g: src/Superstructure/State/tests/ESMF_StateUTest.F90
PASS: mvapich2/g: src/addon/NUOPC/tests/ESMF_NUOPC_UTest.F90
PASS: mvapich2/g: src/epilogue/tests/ESMCI_TestUTest.C
PASS: mvapich2/g: src/epilogue/tests/ESMC_TestUTest.C
PASS: mvapich2/g: src/epilogue/tests/ESMF_TestUTest.F90
PASS: mvapich2/g: src/prologue/tests/ESMCI_ExceptionsUTest.C
PASS: mvapich2/g: src/prologue/tests/ESMCI_FeatureUTest.C
PASS: mvapich2/g: src/prologue/tests/ESMF_F90ArrayPtrUTest.F90
PASS: mvapich2/g: src/prologue/tests/ESMF_FeatureUTest.F90
PASS: mvapich2/g: src/prologue/tests/ESMF_LAPACKUTest.F90
PASS: mvapich2/g: src/prologue/tests/ESMF_StringUTest.F90
PASS: mvapich2/g: src/prologue/tests/ESMF_WordsizeUTest.F90


The following unit test files failed to build, failed to execute or cra=
shed during execution:

CRASHED: mvapich2/g: src/Infrastructure/Field/tests/ESMF_FieldIOUTest.F=
90


The following test harness unit tests pass:
PASS: mvapich2/g: ESMF_array_default_NP4UTest
PASS: mvapich2/g: ESMF_field_default_NP4UTest


The log and stdout files for the unit tests can be found at:
/lcrc/project/ESMF/scripts_dirs/daily_builds/intel_bebop/esmf/test/test=
g/Linux.intel.64.mvapich2.default


Found 9075 exhaustive multi-processor unit tests, 8990 passed and 85 fa=
iled.



_______________________________________________________________________=
________________________


Mon Mar 16 06:37:33 CDT 2020 on beboplogin2=20

ESMF Checkout Source: https://github.com/esmf-org/esmf

Compiler and configuration information:
=20
--------------------------------------------------------------=20

Currently Loaded Modules:
  1) intel/17.0.4-74uvhji
  2) mvapich2/2.3b-gk6kdue

=20

=20
Repository:
origin=09https://github.com/esmf-org/esmf (fetch)
origin=09https://github.com/esmf-org/esmf (push)
=20
ESMF_8_1_0_beta_snapshot_11
=20
=20
=20
--------------------------------------------------------------
ESMF_VERSION_STRING:    8.1.0 beta snapshot
ESMF_8_1_0_beta_snapshot_11
--------------------------------------------------------------
# On branch master
# Untracked files:
#   (use "git add <file>..." to include in what will be committed)
#
#=09queue_results
#=09src/installcheck/esmc_application
#=09src/installcheck/esmc_application.o
#=09src/installcheck/esmf_application
#=09src/installcheck/esmf_application.o
#=09tmp
nothing added to commit but untracked files present (use "git add" to t=
rack)
--------------------------------------------------------------
=20
--------------------------------------------------------------
Make version:
GNU Make 3.82
Built for x86_64-redhat-linux-gnu
Copyright (C) 2010  Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl=
.html>
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.

--------------------------------------------------------------
Fortran Compiler version:
mpifort for MVAPICH2 version 2.3b
Intel(R) Fortran Intel(R) 64 Compiler for applications running on Intel=
(R) 64, Version 17.0.4.193 Build 20170408
Copyright (C) 1985-2017 Intel Corporation.  All rights reserved.

ifort version 17.0.4

--------------------------------------------------------------
C++ Compiler version:
mpicxx for MVAPICH2 version 2.3b
Intel(R) C++ Intel(R) 64 Compiler for applications running on Intel(R) =
64, Version 17.0.4.193 Build 20170408
Copyright (C) 1985-2017 Intel Corporation.  All rights reserved.

icpc version 17.0.4 (gcc version 4.8.5 compatibility)

--------------------------------------------------------------
Preprocessor version:
gcc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-36)
Copyright (C) 2015 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is=
 NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURP=
OSE.

=20
--------------------------------------------------------------
 * User set ESMF environment variables *
ESMF_ABI=3D64
ESMF_BOPT=3DO
ESMF_COMM=3Dmvapich2
ESMF_COMPILER=3Dintel
ESMF_DIR=3D/lcrc/project/ESMF/scripts_dirs/daily_builds/intel_bebop/esm=
f
ESMF_INSTALL_PREFIX=3D/lcrc/project/ESMF/scripts_dirs/daily_builds/inte=
l_bebop/esmf/../install_dir
ESMF_MPIRUN=3D/lcrc/project/ESMF/scripts_dirs/daily_builds/intel_bebop/=
esmf/scripts/mpirun.srun
ESMF_OS=3DLinux
ESMF_PROJ4=3Dexternal
ESMF_PROJ4_INCLUDE=3D/home/svasquez/proj4/include
ESMF_PROJ4_LIBPATH=3D/home/svasquez/proj4/lib
ESMF_SITE=3Ddefault
ESMF_TESTCOMPTUNNEL=3DOFF
ESMF_TESTEXHAUSTIVE=3DON
ESMF_TESTHARNESS_ARRAY=3DRUN_ESMF_TestHarnessArray_default
ESMF_TESTHARNESS_FIELD=3DRUN_ESMF_TestHarnessField_default
ESMF_TESTMPMD=3DOFF
ESMF_TESTWITHTHREADS=3DOFF
=20
--------------------------------------------------------------
 * ESMF environment variables *
ESMF_DIR: /lcrc/project/ESMF/scripts_dirs/daily_builds/intel_bebop/esmf
ESMF_OS:                Linux
ESMF_MACHINE:           x86_64
ESMF_ABI:               64
ESMF_COMPILER:          intel
ESMF_BOPT:              O
ESMF_COMM:              mvapich2
ESMF_SITE:              default
ESMF_PTHREADS:          ON
ESMF_OPENMP:            ON
ESMF_OPENACC:           OFF
ESMF_CXXSTD:            11
ESMF_ARRAY_LITE:        FALSE
ESMF_NO_INTEGER_1_BYTE: TRUE
ESMF_NO_INTEGER_2_BYTE: TRUE
ESMF_FORTRANSYMBOLS:    default
ESMF_MAPPER_BUILD:      OFF
ESMF_AUTO_LIB_BUILD:    ON
ESMF_DEFER_LIB_BUILD:   ON
ESMF_SHARED_LIB_BUILD:  ON
ESMF_TRACE_LIB_BUILD:   ON
ESMF_TESTEXHAUSTIVE:    ON
ESMF_TESTCOMPTUNNEL:    OFF
ESMF_TESTWITHTHREADS:   OFF
ESMF_TESTMPMD:          OFF
ESMF_TESTSHAREDOBJ:     OFF
ESMF_TESTFORCEOPENMP:   OFF
ESMF_TESTFORCEOPENACC:  OFF
ESMF_TESTHARNESS_ARRAY: RUN_ESMF_TestHarnessArray_default
ESMF_TESTHARNESS_FIELD: RUN_ESMF_TestHarnessField_default
ESMF_MPIRUN:            /lcrc/project/ESMF/scripts_dirs/daily_builds/in=
tel_bebop/esmf/scripts/mpirun.srun
=20
--------------------------------------------------------------
 * ESMF environment variables pointing to 3rd party software *
ESMF_MOAB:               internal
ESMF_LAPACK:             internal
ESMF_ACC_SOFTWARE_STACK: none
ESMF_YAMLCPP:            internal
ESMF_PIO:                internal
ESMF_PROJ4:                external
ESMF_PROJ4_INCLUDE:        /home/svasquez/proj4/include
ESMF_PROJ4_LIBS:           -lproj
ESMF_PROJ4_LIBPATH:        /home/svasquez/proj4/lib
=20
--------------------------------------------------------------
 * ESMF environment variables for final installation *
ESMF_INSTALL_PREFIX:    /lcrc/project/ESMF/scripts_dirs/daily_builds/in=
tel_bebop/esmf/../install_dir
ESMF_INSTALL_HEADERDIR: include
ESMF_INSTALL_MODDIR:    mod/modO/Linux.intel.64.mvapich2.default
ESMF_INSTALL_LIBDIR:    lib/libO/Linux.intel.64.mvapich2.default
ESMF_INSTALL_BINDIR:    bin/binO/Linux.intel.64.mvapich2.default
ESMF_INSTALL_DOCDIR:    doc
=20
--------------------------------------------------------------
 * ESMF Benchmark directory and parameters *
ESMF_BENCHMARK_PREFIX:         ./DEFAULTBENCHMARKDIR
ESMF_BENCHMARK_TOLERANCE:      20%
ESMF_BENCHMARK_THRESHOLD_MSEC: 500
=20
--------------------------------------------------------------
 * Other relevant environment variables *
PATH:    /blues/gpfs/home/software/spack-0.10.1/opt/spack/linux-centos7=
-x86_64/intel-17.0.4/mvapich2-2.3b-gk6kduezz3emvxx7gxurx5ittvqbicd6/bin=
:/blues/gpfs/home/software/spack-0.10.1/opt/spack/linux-centos7-x86_64/=
gcc-4.8.5/intel-17.0.4-74uvhjiulyqgvsmywifbbuo46v5n42xc/bin:/home/svasq=
uez/bin:/usr/bin:/bin:/usr/local/sbin:/usr/sbin:/soft/lcrc/bebop/bin:/s=
oft/lcrc/bebop/bin:/soft/lcrc/bebop/bin
LD_LIBRARY_PATH: /blues/gpfs/home/software/spack-0.10.1/opt/spack/linux=
-centos7-x86_64/intel-17.0.4/mvapich2-2.3b-gk6kduezz3emvxx7gxurx5ittvqb=
icd6/lib:/blues/gpfs/home/software/spack-0.10.1/opt/spack/linux-centos7=
-x86_64/gcc-4.8.5/intel-17.0.4-74uvhjiulyqgvsmywifbbuo46v5n42xc/tbb/lib=
/intel64/gcc4.4:/blues/gpfs/home/software/spack-0.10.1/opt/spack/linux-=
centos7-x86_64/gcc-4.8.5/intel-17.0.4-74uvhjiulyqgvsmywifbbuo46v5n42xc/=
lib/intel64
=20
--------------------------------------------------------------
 * Compilers, Linkers, Flags, and Libraries *
Location of the preprocessor:      /usr/bin/gcc
Location of the Fortran compiler:  /blues/gpfs/home/software/spack-0.10=
.1/opt/spack/linux-centos7-x86_64/intel-17.0.4/mvapich2-2.3b-gk6kduezz3=
emvxx7gxurx5ittvqbicd6/bin/mpif90
Location of the Fortran linker:    /blues/gpfs/home/software/spack-0.10=
.1/opt/spack/linux-centos7-x86_64/intel-17.0.4/mvapich2-2.3b-gk6kduezz3=
emvxx7gxurx5ittvqbicd6/bin/mpif90
Location of the C++ compiler:      /blues/gpfs/home/software/spack-0.10=
.1/opt/spack/linux-centos7-x86_64/intel-17.0.4/mvapich2-2.3b-gk6kduezz3=
emvxx7gxurx5ittvqbicd6/bin/mpicxx
Location of the C++ linker:        /blues/gpfs/home/software/spack-0.10=
.1/opt/spack/linux-centos7-x86_64/intel-17.0.4/mvapich2-2.3b-gk6kduezz3=
emvxx7gxurx5ittvqbicd6/bin/mpicxx

Fortran compiler flags:
ESMF_F90COMPILER: mpif90
ESMF_F90COMPILEOPTS: -O -fPIC -assume realloc_lhs -m64 -mcmodel=3Dsmall=
 -threads  -qopenmp
ESMF_F90COMPILEPATHS: -I/lcrc/project/ESMF/scripts_dirs/daily_builds/in=
tel_bebop/esmf/mod/modO/Linux.intel.64.mvapich2.default -I/lcrc/project=
/ESMF/scripts_dirs/daily_builds/intel_bebop/esmf/src/include -I/home/sv=
asquez/proj4/include
ESMF_F90COMPILECPPFLAGS: -DESMF_NO_INTEGER_1_BYTE -DESMF_NO_INTEGER_2_B=
YTE -DESMFVERSIONGIT=3D'ESMF_8_1_0_beta_snapshot_11' -DESMF_MOAB=3D1 -D=
ESMF_LAPACK=3D1 -DESMF_LAPACK_INTERNAL=3D1 -DESMF_NO_ACC_SOFTWARE_STACK=
=3D1 -DESMF_YAMLCPP=3D1 -DESMF_YAML=3D1 -DESMF_PIO=3D1 -DESMF_MPIIO -DE=
SMF_PROJ4=3D1 -DESMF_NO_OPENACC -DESMF_TESTEXHAUSTIVE -DESMF_BOPT_O -DS=
x86_64_small=3D1 -DESMF_OS_Linux=3D1 -DESMF_COMM=3Dmvapich2 -DESMF_DIR=
=3D/lcrc/project/ESMF/scripts_dirs/daily_builds/intel_bebop/esmf
ESMF_F90COMPILEFREECPP:=20
ESMF_F90COMPILEFREENOCPP:=20
ESMF_F90COMPILEFIXCPP:=20
ESMF_F90COMPILEFIXNOCPP:=20

Fortran linker flags:
ESMF_F90LINKOPTS:   -m64 -mcmodel=3Dsmall -threads -Wl,--no-as-needed  =
-qopenmp
ESMF_F90LINKPATHS: -L/lcrc/project/ESMF/scripts_dirs/daily_builds/intel=
_bebop/esmf/lib/libO/Linux.intel.64.mvapich2.default -L/home/svasquez/p=
roj4/lib=20
ESMF_F90LINKRPATHS: -Wl,-rpath,/lcrc/project/ESMF/scripts_dirs/daily_bu=
ilds/intel_bebop/esmf/lib/libO/Linux.intel.64.mvapich2.default  -Wl,-rp=
ath,/home/svasquez/proj4/lib
ESMF_F90LINKLIBS:  -cxxlib -lrt -ldl -lproj
ESMF_F90ESMFLINKLIBS: -lesmf  -cxxlib -lrt -ldl -lproj

C++ compiler flags:
ESMF_CXXCOMPILER: mpicxx
ESMF_CXXCOMPILEOPTS: -std=3Dc++11 -O -DNDEBUG -fPIC -m64 -mcmodel=3Dsma=
ll -pthread  -qopenmp
ESMF_CXXCOMPILEPATHS:  -I/lcrc/project/ESMF/scripts_dirs/daily_builds/i=
ntel_bebop/esmf/src/include  -I/home/svasquez/proj4/include -I/lcrc/pro=
ject/ESMF/scripts_dirs/daily_builds/intel_bebop/esmf/src/prologue/yaml-=
cpp/include
ESMF_CXXCOMPILECPPFLAGS: -DESMF_NO_INTEGER_1_BYTE -DESMF_NO_INTEGER_2_B=
YTE -DESMFVERSIONGIT=3D'ESMF_8_1_0_beta_snapshot_11' -DESMF_MOAB=3D1 -D=
ESMF_LAPACK=3D1 -DESMF_LAPACK_INTERNAL=3D1 -DESMF_NO_ACC_SOFTWARE_STACK=
=3D1 -DESMF_YAMLCPP=3D1 -DESMF_YAML=3D1 -DESMF_PIO=3D1 -DESMF_MPIIO -DE=
SMF_PROJ4=3D1 -DESMF_NO_OPENACC -DESMF_TESTEXHAUSTIVE -DESMF_BOPT_O -DS=
x86_64_small=3D1 -DESMF_OS_Linux=3D1 -DESMF_COMM=3Dmvapich2 -DESMF_DIR=
=3D/lcrc/project/ESMF/scripts_dirs/daily_builds/intel_bebop/esmf -D__SD=
IR__=3D'' -DESMF_CXXSTD=3D11

C++ linker flags:
ESMF_CXXLINKOPTS:   -m64 -mcmodel=3Dsmall -pthread -Wl,--no-as-needed  =
-qopenmp
ESMF_CXXLINKPATHS: -L/lcrc/project/ESMF/scripts_dirs/daily_builds/intel=
_bebop/esmf/lib/libO/Linux.intel.64.mvapich2.default -L/home/svasquez/p=
roj4/lib -L/blues/gpfs/home/software/spack-0.10.1/opt/spack/linux-cento=
s7-x86_64/gcc-4.8.5/intel-17.0.4-74uvhjiulyqgvsmywifbbuo46v5n42xc/compi=
lers_and_libraries_2017.4.193/linux/compiler/lib/intel64_lin/
ESMF_CXXLINKRPATHS: -Wl,-rpath,/lcrc/project/ESMF/scripts_dirs/daily_bu=
ilds/intel_bebop/esmf/lib/libO/Linux.intel.64.mvapich2.default  -Wl,-rp=
ath,/home/svasquez/proj4/lib -Wl,-rpath,/blues/gpfs/home/software/spack=
-0.10.1/opt/spack/linux-centos7-x86_64/gcc-4.8.5/intel-17.0.4-74uvhjiul=
yqgvsmywifbbuo46v5n42xc/compilers_and_libraries_2017.4.193/linux/compil=
er/lib/intel64_lin/
ESMF_CXXLINKLIBS:  -lmpifort -lifport -lifcoremt -limf -lsvml -lm -lipg=
o -liomp5 -lintlc -lpthread -lsvml -lgcc -lgcc_s -lirc_s -ldl -lrt -ldl=
 -lproj
ESMF_CXXESMFLINKLIBS: -lesmf  -lmpifort -lifport -lifcoremt -limf -lsvm=
l -lm -lipgo -liomp5 -lintlc -lpthread -lsvml -lgcc -lgcc_s -lirc_s -ld=
l -lrt -ldl -lproj

Shared library build:
ESMF_SL_LIBS_TO_MAKE: libesmf
ESMF_SL_SUFFIX:       so
ESMF_SL_LIBLINKER:    mpicxx
ESMF_SL_LIBOPTS:       -pthread -shared  -qopenmp
ESMF_SL_LIBLIBS:     =20

ESMF Tracing linker options:
ESMF_TRACE_LDPRELOAD=3D/lcrc/project/ESMF/scripts_dirs/daily_builds/int=
el_bebop/esmf/lib/libO/Linux.intel.64.mvapich2.default/libesmftrace_pre=
load.so
ESMF_TRACE_STATICLINKOPTS=3D-static -Wl,--wrap=3Dc_esmftrace_notify_wra=
ppers -Wl,--wrap=3Dc_esmftrace_isinitialized -Wl,--wrap=3Dwrite -Wl,--w=
rap=3Dwritev -Wl,--wrap=3Dpwrite -Wl,--wrap=3Dread -Wl,--wrap=3Dopen -W=
l,--wrap=3DMPI_Allgather -Wl,--wrap=3DMPI_Allgatherv -Wl,--wrap=3DMPI_A=
llreduce -Wl,--wrap=3DMPI_Alltoall -Wl,--wrap=3DMPI_Alltoallv -Wl,--wra=
p=3DMPI_Alltoallw -Wl,--wrap=3DMPI_Barrier -Wl,--wrap=3DMPI_Bcast -Wl,-=
-wrap=3DMPI_Gather -Wl,--wrap=3DMPI_Gatherv -Wl,--wrap=3DMPI_Recv -Wl,-=
-wrap=3DMPI_Reduce -Wl,--wrap=3DMPI_Scatter -Wl,--wrap=3DMPI_Send -Wl,-=
-wrap=3DMPI_Sendrecv -Wl,--wrap=3DMPI_Wait -Wl,--wrap=3DMPI_Waitall -Wl=
,--wrap=3DMPI_Waitany -Wl,--wrap=3DMPI_Waitsome -Wl,--wrap=3Dmpi_allgat=
her_ -Wl,--wrap=3Dmpi_allgather__ -Wl,--wrap=3Dmpi_allgatherv_ -Wl,--wr=
ap=3Dmpi_allgatherv__ -Wl,--wrap=3Dmpi_allreduce_ -Wl,--wrap=3Dmpi_allr=
educe__ -Wl,--wrap=3Dmpi_alltoall_ -Wl,--wrap=3Dmpi_alltoall__ -Wl,--wr=
ap=3Dmpi_alltoallv_ -Wl,--wrap=3Dmpi_alltoallv__ -Wl,--wrap=3Dmpi_allto=
allw_ -Wl,--wrap=3Dmpi_alltoallw__ -Wl,--wrap=3Dmpi_barrier_ -Wl,--wrap=
=3Dmpi_barrier__ -Wl,--wrap=3Dmpi_bcast_ -Wl,--wrap=3Dmpi_bcast__ -Wl,-=
-wrap=3Dmpi_exscan_ -Wl,--wrap=3Dmpi_exscan__ -Wl,--wrap=3Dmpi_gather_ =
-Wl,--wrap=3Dmpi_gather__ -Wl,--wrap=3Dmpi_gatherv_ -Wl,--wrap=3Dmpi_ga=
therv__ -Wl,--wrap=3Dmpi_recv_ -Wl,--wrap=3Dmpi_recv__ -Wl,--wrap=3Dmpi=
_reduce_ -Wl,--wrap=3Dmpi_reduce__ -Wl,--wrap=3Dmpi_reduce_scatter_ -Wl=
,--wrap=3Dmpi_reduce_scatter__ -Wl,--wrap=3Dmpi_scatter_ -Wl,--wrap=3Dm=
pi_scatter__ -Wl,--wrap=3Dmpi_scatterv_ -Wl,--wrap=3Dmpi_scatterv__ -Wl=
,--wrap=3Dmpi_scan_ -Wl,--wrap=3Dmpi_scan__ -Wl,--wrap=3Dmpi_send_ -Wl,=
--wrap=3Dmpi_send__ -Wl,--wrap=3Dmpi_wait_ -Wl,--wrap=3Dmpi_wait__ -Wl,=
--wrap=3Dmpi_waitall_ -Wl,--wrap=3Dmpi_waitall__ -Wl,--wrap=3Dmpi_waita=
ny_ -Wl,--wrap=3Dmpi_waitany__
ESMF_TRACE_STATICLINKLIBS=3D-lesmftrace_static


--------------------------------------------------------------
Compiling on Mon Mar 16 06:37:52 CDT 2020 on beboplogin2
Machine characteristics: Linux beboplogin2 3.10.0-957.21.3.el7.x86_64 #=
1 SMP Tue Jun 18 16:35:19 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
=20
Mon Mar 16 07:29:59 CDT 2020 library build -j16 ...........PASS
Mon Mar 16 07:31:29 CDT 2020 library install -j4 ..........PASS
Mon Mar 16 07:31:35 CDT 2020 library installcheck -j4 .....PASS
Mon Mar 16 07:37:54 CDT 2020 quickstart build -j4 .........PASS

|------------------------ APPs TESTS --------------------------|
Mon Mar 16 07:38:26 CDT 2020 apps build -j4 ...............PASS

|--------------------------------------------------------------|
Mon Mar 16 07:45:54 CDT 2020 ESMF_Regrid --help ...........PASS
The following is the output of ESMF_Regrid --help

 Usage: ESMF_Regrid
                       --source|-s src_grid_filename
                       --destination|-d dst_grid_filename
                       --src_var varname1[,varname2,...]
                       --dst_var  varname1[,varname2,...]
                       [--srcdatafile]
                       [--dstdatafile]
                       [--tilefile_path tile_file_path]
                       [--dst_loc center|corner]
                       [--method|-m bilinear|patch|neareststod|nearestd=
tos|conse
 rve|conserve2nd]
                       [--pole|-p all|none|teeth|<N>]
                       [--ignore_unmapped|-i]
                       [--ignore_degenerate]
                       [-r]
                       [--src_regional]
                       [--dst_regional]
                       [--check]
                       [--no_log]
                       [--help]
                       [--version]
                       [-V]
 where
 --source or -s - a required argument specifying the source grid file
               name
 --destination or -d - a required argument specifying the destination g=
rid
               file name
 --src_var  - a required argument specifying the variable names to be r=
egridded
               in the source grid file.  If more than one, separated th=
em with
               comma.
 --dst_var  - a required argument specifying the destination variable n=
ame in
               the destination grid file.  If more than one, separated =
them with
               comma.  The number of dst_vars has to be the same as the=
 number
               of src_var
 --srcdatafile - If the source grid is of type MOSAIC, the data is stor=
ed=20
               in separated files, one per tile. srcdatafile is the pre=
fix of
               the source data file.  The filename is srcdatafile.tilen=
ame.nc,
               where tilename is the tile name defined in the source gr=
id file
 --dstdatafile - If the destination grid is of type MOSAIC, the data is=
 stored
               in separated files, one per tile. dstdatafile is the pre=
fix of
               the destination data file.  The filename is srcdatafile.=
tilename.
 nc,
                where tilename is the tile name defined in the destinat=
ion grid=20
 file
 --tilefile_path - The alternative file path for the tile files and mos=
aic data=20
 files
               when either srcFile or dstFile is a GRIDSPEC MOSAIC grid=
.  The pa
 th
               can be either relative or absolute.  If it is relative, =
it is
               relative to the working directory.  When specified, the =
gridlocat
 ion
               variable defined in the Mosaic file will be ignored.
 --method or -m - an optional argument specifying which interpolation m=
ethod is
               used.  The default method is bilinear
 --pole or -p - an optional argument indicating what to do with the pol=
e.
               The default value is all
 --ignore_unmapped or -i - ignore unmapped destination points. If not s=
pecified,
               the default is to stop with an error.
 --ignore_degenerate - ignore degenerate cells in the input grids. If n=
ot specif
 ied,
               the default is to stop with an error.
 -r          - an optional argument specifying the source and destinati=
on grids
               are regional grids.  Without this argument, the grids ar=
e assumed
               to be global. This argument only applies to the GRIDSPEC=
 file
 --src_regional   - an optional argument specifying the source grid is =
regional.
               Without this argument, the src grids is assumed to be gl=
obal. Thi
 s=20
               argument only applies to the GRIDSPEC file
 --dst_regional   - an optional argument specifying the destination gri=
d is regi
 onal
               Without this argument, the dst grids is assumed to be gl=
obal.
               This argument only applies to the GRIDSPEC file
 --check    - Check the regridded fields by comparing the values with
              a synthetic field calculated based on its coordinates.=20
              The mean relative error between the destination field=20
              and synthetic field is computed.  The synthetic value is =
calculate
 d as=20
              data(i,j,k,l)=3D2.0+(k-1)+2*(l-1)+cos(lat(i,j))**2*cos(2*=
lon(i,j)),=20
 assuming
              it is a 2D grid=20
 --no_log    - Turn off the ESMF error log.
 --help     - Print this help message and exit.
 --version  - Print ESMF version and license information and exit.
 -V        - Print ESMF version number and exit.
=20
 For questions, comments, or feature requests please send email to:
 esmf_support@cgd.ucar.edu
=20
 Visit http://www.earthsystemmodeling.org/ to find out more about the
 Earth System Modeling Framework.
=20



|--------------------------------------------------------------|
Mon Mar 16 07:45:55 CDT 2020 ESMF_Regrid --version ........PASS
The following is the output of ESMF_Regrid --version

   ESMF_VERSION_STRING:       8.1.0 beta snapshot
   ESMF_VERSION_MAJOR:                   8
   ESMF_VERSION_MINOR:                   1
   ESMF_VERSION_REVISION:                0
   ESMF_VERSION_PATCHLEVEL:              0
   ESMF_VERSION_PUBLIC:        F
   ESMF_VERSION_BETASNAPSHOT:  T
=20
 Earth System Modeling Framework
=20
 Copyright (c) 2002-2020 University Corporation for Atmospheric Researc=
h,
 Massachusetts Institute of Technology, Geophysical Fluid Dynamics Labo=
ratory,
 University of Michigan, National Centers for Environmental Prediction,
 Los Alamos National Laboratory, Argonne National Laboratory,
 NASA Goddard Space Flight Center.
 All rights reserved.
=20
 Permission is hereby granted, free of charge, to any person obtaining =
a copy
 of this software and associated documentation files (the 'Software'), =
to
 deal with the Software without restriction, including without limitati=
on the
 rights to use, copy, modify, merge, publish, distribute, sublicense, a=
nd/or
 sell copies of the Software, and to permit persons to whom the Softwar=
e is
 furnished to do so, subject to the following conditions:
    1. Redistributions of source code must retain the above copyright n=
otice,
       this list of conditions and the following disclaimers.
    2. Redistributions in binary form must reproduce the above copyrigh=
t
       notice, this list of conditions and the following disclaimers in=
 the
       documentation and/or other materials provided with the distribut=
ion.
    3. Neither the names of the organizations developing this software,=
 nor
       the names of its contributors may be used to endorse or promote =
products
       derived from this Software without specific prior written permis=
sion.
=20
 THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRES=
S OR
 IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILIT=
Y,
 FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHAL=
L THE
 CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR =
OTHER
 LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISIN=
G
 FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DE=
ALINGS
 WITH THE SOFTWARE.



|--------------------------------------------------------------|
Mon Mar 16 07:45:56 CDT 2020 ESMF_Regrid -V ...............PASS
The following is the output of ESMF_Regrid -V

   ESMF_VERSION_STRING:       8.1.0 beta snapshot



|--------------------------------------------------------------|
Mon Mar 16 07:45:56 CDT 2020 ESMF_Info --help .............PASS
The following is the output of ESMF_Info --help=20

 ESMF_Info: Print information about the ESMF installation.
 Options:
   --help        Display this information and exit.
   --version     Display ESMF version and license information and exit.
   -V            Display ESMF version string and exit.
=20



|--------------------------------------------------------------|
Mon Mar 16 07:45:57 CDT 2020 ESMF_Info --version ..........PASS
The following is the output of ESMF_Info --version=20

   ESMF_VERSION_STRING:       8.1.0 beta snapshot
   ESMF_VERSION_MAJOR:                   8
   ESMF_VERSION_MINOR:                   1
   ESMF_VERSION_REVISION:                0
   ESMF_VERSION_PATCHLEVEL:              0
   ESMF_VERSION_PUBLIC:        F
   ESMF_VERSION_BETASNAPSHOT:  T
=20
 Earth System Modeling Framework
=20
 Copyright (c) 2002-2020 University Corporation for Atmospheric Researc=
h,
 Massachusetts Institute of Technology, Geophysical Fluid Dynamics Labo=
ratory,
 University of Michigan, National Centers for Environmental Prediction,
 Los Alamos National Laboratory, Argonne National Laboratory,
 NASA Goddard Space Flight Center.
 All rights reserved.
=20
 Permission is hereby granted, free of charge, to any person obtaining =
a copy
 of this software and associated documentation files (the 'Software'), =
to
 deal with the Software without restriction, including without limitati=
on the
 rights to use, copy, modify, merge, publish, distribute, sublicense, a=
nd/or
 sell copies of the Software, and to permit persons to whom the Softwar=
e is
 furnished to do so, subject to the following conditions:
    1. Redistributions of source code must retain the above copyright n=
otice,
       this list of conditions and the following disclaimers.
    2. Redistributions in binary form must reproduce the above copyrigh=
t
       notice, this list of conditions and the following disclaimers in=
 the
       documentation and/or other materials provided with the distribut=
ion.
    3. Neither the names of the organizations developing this software,=
 nor
       the names of its contributors may be used to endorse or promote =
products
       derived from this Software without specific prior written permis=
sion.
=20
 THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRES=
S OR
 IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILIT=
Y,
 FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHAL=
L THE
 CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR =
OTHER
 LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISIN=
G
 FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DE=
ALINGS
 WITH THE SOFTWARE.



|--------------------------------------------------------------|
Mon Mar 16 07:45:58 CDT 2020 ESMF_Info -V .................PASS
The following is the output of ESMF_Info -V=20

   ESMF_VERSION_STRING:       8.1.0 beta snapshot



|--------------------------------------------------------------|
Mon Mar 16 07:45:59 CDT 2020 ESMF_InfoC --help ............PASS
The following is the output of ESMF_InfoC --help

ESMF_InfoC: Print information about the ESMF installation.
Options:
  --help        Display this information and exit.
  --version     Display ESMF version and license information and exit.
  -V            Display ESMF version string and exit.




|--------------------------------------------------------------|
Mon Mar 16 07:46:00 CDT 2020 ESMF_InfoC --version .........PASS
The following is the output of ESMF_InfoC --version

   ESMF_VERSION_STRING:       8.1.0 beta snapshot
   ESMF_VERSION_MAJOR:                   8
   ESMF_VERSION_MINOR:                   1
   ESMF_VERSION_REVISION:                0
   ESMF_VERSION_PATCHLEVEL:              0
   ESMF_VERSION_PUBLIC:        F
   ESMF_VERSION_BETASNAPSHOT:  T
=20
 Earth System Modeling Framework
=20
 Copyright (c) 2002-2020 University Corporation for Atmospheric Researc=
h,
 Massachusetts Institute of Technology, Geophysical Fluid Dynamics Labo=
ratory,
 University of Michigan, National Centers for Environmental Prediction,
 Los Alamos National Laboratory, Argonne National Laboratory,
 NASA Goddard Space Flight Center.
 All rights reserved.
=20
 Permission is hereby granted, free of charge, to any person obtaining =
a copy
 of this software and associated documentation files (the 'Software'), =
to
 deal with the Software without restriction, including without limitati=
on the
 rights to use, copy, modify, merge, publish, distribute, sublicense, a=
nd/or
 sell copies of the Software, and to permit persons to whom the Softwar=
e is
 furnished to do so, subject to the following conditions:
    1. Redistributions of source code must retain the above copyright n=
otice,
       this list of conditions and the following disclaimers.
    2. Redistributions in binary form must reproduce the above copyrigh=
t
       notice, this list of conditions and the following disclaimers in=
 the
       documentation and/or other materials provided with the distribut=
ion.
    3. Neither the names of the organizations developing this software,=
 nor
       the names of its contributors may be used to endorse or promote =
products
       derived from this Software without specific prior written permis=
sion.
=20
 THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRES=
S OR
 IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILIT=
Y,
 FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHAL=
L THE
 CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR =
OTHER
 LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISIN=
G
 FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DE=
ALINGS
 WITH THE SOFTWARE.



|--------------------------------------------------------------|
Mon Mar 16 07:46:01 CDT 2020 ESMF_InfoC -V ................PASS
The following is the output of ESMF_InfoC -V

   ESMF_VERSION_STRING:       8.1.0 beta snapshot



|--------------------------------------------------------------|
Mon Mar 16 07:46:02 CDT 2020 ESMF_RegridWeightGen --help ..PASS
The following is the output of ESMF_RegridWeightGen --help

 Usage: ESMF_RegridWeightGen --source|-s src_grid_filename
                            --destination|-d dst_grid_filename
                       --weight|-w out_weight_file=20
                       [--method|-m bilinear|patch|neareststod|nearestd=
tos|conse
 rve|conserve2nd]
                       [--pole|-p all|none|teeth|<N>]
                       [--line_type|-l cartesian|greatcircle]
                       [--norm_type dstarea|fracarea]
                       [--extrap_method none|neareststod|nearestidavg|c=
reep]
                       [--extrap_num_src_pnts <N>]
                       [--extrap_dist_exponent <P>]
                       [--extrap_num_levels <L>]
                       [--ignore_unmapped|-i]
                       [--ignore_degenerate]
                       [-r]
                       [--src_regional]
                       [--dst_regional]
                       [--64bit_offset]
                       [--netcdf4]
                       [--weight_only]
                       [--src_missingvalue src_var_name]
                       [--dst_missingvalue dst_var_name]
                       [--src_coordinates lon_var_name,lat_var_name]
                       [--dst_coordinates lon_var_name,lat_var_name]
                       [--user_areas]
                       [--src_loc center|corner]
                       [--dst_loc center|corner]
                       [--tilefile_path tile_file_path]
                       [--no_log]
                       [--check]
                       [--help]
                       [--version]
                       [-V]
 where
 --source or -s - a required argument specifying the source grid file
                  name
 --destination or -d - a required argument specifying the destination g=
rid
                       file name
 --weight or -w - a required argument specifying the output regridding =
weight
                  file name
 --method or -m - an optional argument specifying which interpolation m=
ethod is
                  used.  The default method is bilinear.
 --pole or -p - an optional argument indicating what to do with the pol=
e.
                  The default value is all.
 --line_type or -l - an optional argument indicating the type of path
                      lines (e.g. cell edges) follow on a spherical
                     surface. The default value depends on the regrid
                     method. For non-conservative methods the default i=
s
                     cartesian. For conservative methods the default is=
 greatcir
 cle.
 --norm_type - an optional argument indicating the type of normalizatio=
n to
               do when generating conserative weights. The default valu=
e is dsta
 rea.
 --extrap_method - an optional argument specifying which extrapolation =
method is
                  used.  The default method is none.
 --extrap_num_src_pnts - an optional argument specifying how many sourc=
e points=20
 should
                 be used when the extrapolation method is nearestidavg.=
 The defa
 ult is 8.
 --extrap_dist_exponent - an optional argument specifying the exponent =
that the=20
 distance should
                 be raised to when the extrapolation method is nearesti=
davg. The
  default is 2.0.
 --extrap_num_levels - an optional argument specifying how many levels =
should
                 be filled for level based extrapolation methods (e.g. =
creep).
 --ignore_unmapped or -i - ignore unmapped destination points. If not s=
pecified,
                           the default is to stop with an error.
 --ignore_degenerate - ignore degenerate cells in the input grids. If n=
ot specif
 ied,
                           the default is to stop with an error.
 -r         - an optional argument specifying the source and destinatio=
n grids
              are regional grids.  Without this argument, the grids are=
 assumed
              to be global
 --src_regional   - an optional argument specifying the source grid is =
regional.
              Without this argument, the src grids is assumed to be glo=
bal.
 --dst_regional   - an optional argument specifying the destination gri=
d is regi
 onal
              Without this argument, the dst grids is assumed to be glo=
bal.
 --64bit_offset  - an optional argument specifying the output weight fi=
le is in
              NetCDF 64-bit offset format.  This option only works with=
 NetCDF l
 ibrary
              version 3.6 and above
 --netcdf4  - an optional argument specifying the output weight file is=
 in
              the NetCDF4 format. This option only works with NetCDF li=
brary
              version 4.1 and above
 --weight_only  - an Optional argument specifying the output weight fil=
e only co
 ntains
              the weights and the source and destination grid's indices=
.
 --src_missingvalue  - an optional argument used when the src file type=
 is GRIDS
 PEC
              or UGRID. It defines the variable name whose 'missing_val=
ue' or
              '_FillValue' attribute will be used to construct the mask=
 for the=20
 source
              grid. Without this argument,a GRIDSPEC file or a UGRID fi=
le is not
  masked.
 --dst_missingvalue  - an optional argument used when the destination f=
ile type=20
 is
              GRIDSPEC or UGRID. It defines the variable name whose 'mi=
ssing_val
 ue' or
              '_FillValue' attribute will be used to construct the mask=
 for the=20
 destination
              grid. Without this argument,a GRIDSPEC file or a UGRID fi=
le is not
  masked.
 --src_coordinates  - an optional argument used when the source grid ty=
pe is GRI
 DSPEC.
              It defines the longitude and latitude variable names sepa=
rated by=20
 comma,
              in case there are multiple coordinate variables defined i=
n the fil
 e
 --dst_coordinates  - an optional argument used when the destination gr=
id type i
 s GRIDSPEC.
              It defines the longitude and latitude variable names sepa=
rated by=20
 comma,
              in case there are multiple coordinate variables defined i=
n the fil
 e
 --user_areas  - an optional argument specifying that the conservation =
is adjust
 ed to
              hold for the user areas provided in the grid files.  If n=
ot specif
 ied,
              then the conservation will hold for the ESMF calculated (=
great cir
 cle)
              areas.  Whichever areas the conservation holds for are ou=
tput to t
 he
              weight file.
 --src_loc   - an optional argument specifying which location is used t=
o do the=20
 regridding
             The location can be either 'center' or 'corner'.  Currentl=
y, this a
 rgument
             is only required when the source grid file is an unstructu=
red grid=20
 defined
             in UGRID or ESMF format and the regridding method is non-c=
onservati
 ve. For =20
             all other cases, the default location is 'center'.
 --dst_loc   - an optional argument specifying which location is used t=
o do the=20
 regridding
             The location can be either 'center' or 'corner'.  Currentl=
y, this a
 rgument
             is 'center'.  Currently, this argument will only be used w=
hen the
             is only required when the destination grid file is an unst=
ructured=20
 grid defined
             in UGRID or ESMF format and the regridding method is non-c=
onservati
 ve. For =20
             all other cases, the default location is 'center'.
 --tilefile_path - the alternative file path for the tile files when th=
e grid fi
 le type is
             MOSAIC.
 --no_log    - Turn off the ESMF logs.
 --check    - Check that the generated weights produce reasonable regri=
dded fiel
 ds.  This
              is done by calling ESMF_FieldRegrid() on an analytic sour=
ce field=20
 using the weights
              generated by this application.  The mean relative error b=
etween th
 e destination
              and analytic field is computed, as well as the relative e=
rror betw
 een the mass
              of the source and destination fields in the conservative =
case.
 --help     - Print this help message and exit.
 --version  - Print ESMF version and license information and exit.
 -V        - Print ESMF version number and exit.
=20
 For questions, comments, or feature requests please send email to:
 esmf_support@cgd.ucar.edu
=20
 Visit http://www.earthsystemmodeling.org/ to find out more about the
 Earth System Modeling Framework.
=20



|--------------------------------------------------------------|
Mon Mar 16 07:46:03 CDT 2020 ESMF_RegridWeightGen --version PASS
The following is the output of ESMF_RegridWeightGen --version

   ESMF_VERSION_STRING:       8.1.0 beta snapshot
   ESMF_VERSION_MAJOR:                   8
   ESMF_VERSION_MINOR:                   1
   ESMF_VERSION_REVISION:                0
   ESMF_VERSION_PATCHLEVEL:              0
   ESMF_VERSION_PUBLIC:        F
   ESMF_VERSION_BETASNAPSHOT:  T
=20
 Earth System Modeling Framework
=20
 Copyright (c) 2002-2020 University Corporation for Atmospheric Researc=
h,
 Massachusetts Institute of Technology, Geophysical Fluid Dynamics Labo=
ratory,
 University of Michigan, National Centers for Environmental Prediction,
 Los Alamos National Laboratory, Argonne National Laboratory,
 NASA Goddard Space Flight Center.
 All rights reserved.
=20
 Permission is hereby granted, free of charge, to any person obtaining =
a copy
 of this software and associated documentation files (the 'Software'), =
to
 deal with the Software without restriction, including without limitati=
on the
 rights to use, copy, modify, merge, publish, distribute, sublicense, a=
nd/or
 sell copies of the Software, and to permit persons to whom the Softwar=
e is
 furnished to do so, subject to the following conditions:
    1. Redistributions of source code must retain the above copyright n=
otice,
       this list of conditions and the following disclaimers.
    2. Redistributions in binary form must reproduce the above copyrigh=
t
       notice, this list of conditions and the following disclaimers in=
 the
       documentation and/or other materials provided with the distribut=
ion.
    3. Neither the names of the organizations developing this software,=
 nor
       the names of its contributors may be used to endorse or promote =
products
       derived from this Software without specific prior written permis=
sion.
=20
 THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRES=
S OR
 IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILIT=
Y,
 FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHAL=
L THE
 CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR =
OTHER
 LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISIN=
G
 FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DE=
ALINGS
 WITH THE SOFTWARE.



|--------------------------------------------------------------|
Mon Mar 16 07:46:04 CDT 2020 ESMF_RegridWeightGen -V ......PASS
The following is the output of ESMF_RegridWeightGen -V

   ESMF_VERSION_STRING:       8.1.0 beta snapshot



|--------------------------------------------------------------|
Mon Mar 16 07:46:05 CDT 2020 ESMF_Scrip2Unstruct --help ...PASS
The following is the output of ESMF_Scrip2Unstruct --help

ESMF_Scrip2Unstruct: Convert an unstructured grid file in SCRIP format =
into either a ESMF unstructured file or a UGRID file format.
Usage: ESMF_Scrip2Unstruct [--help] [--version] [-V] inputfile outputfi=
le dualflag [fileformat]
    [--help]        Display this information and exit.
    [--version]     Display ESMF version and license information and ex=
it.
    [-V]            Display ESMF version string and exit.
    inputfile       input grid filename=20
    outputfile      output filename=20
    dualflag        1 to generate a dual mesh, 0 for non-dual mesh
    [fileformat]    Either ESMF or UGRID, the default is ESMF




|--------------------------------------------------------------|
Mon Mar 16 07:46:05 CDT 2020 ESMF_Scrip2Unstruct --version PASS
The following is the output of ESMF_Scrip2Unstruct --version

   ESMF_VERSION_STRING:       8.1.0 beta snapshot
   ESMF_VERSION_MAJOR:                   8
   ESMF_VERSION_MINOR:                   1
   ESMF_VERSION_REVISION:                0
   ESMF_VERSION_PATCHLEVEL:              0
   ESMF_VERSION_PUBLIC:        F
   ESMF_VERSION_BETASNAPSHOT:  T
=20
 Earth System Modeling Framework
=20
 Copyright (c) 2002-2020 University Corporation for Atmospheric Researc=
h,
 Massachusetts Institute of Technology, Geophysical Fluid Dynamics Labo=
ratory,
 University of Michigan, National Centers for Environmental Prediction,
 Los Alamos National Laboratory, Argonne National Laboratory,
 NASA Goddard Space Flight Center.
 All rights reserved.
=20
 Permission is hereby granted, free of charge, to any person obtaining =
a copy
 of this software and associated documentation files (the 'Software'), =
to
 deal with the Software without restriction, including without limitati=
on the
 rights to use, copy, modify, merge, publish, distribute, sublicense, a=
nd/or
 sell copies of the Software, and to permit persons to whom the Softwar=
e is
 furnished to do so, subject to the following conditions:
    1. Redistributions of source code must retain the above copyright n=
otice,
       this list of conditions and the following disclaimers.
    2. Redistributions in binary form must reproduce the above copyrigh=
t
       notice, this list of conditions and the following disclaimers in=
 the
       documentation and/or other materials provided with the distribut=
ion.
    3. Neither the names of the organizations developing this software,=
 nor
       the names of its contributors may be used to endorse or promote =
products
       derived from this Software without specific prior written permis=
sion.
=20
 THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRES=
S OR
 IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILIT=
Y,
 FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHAL=
L THE
 CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR =
OTHER
 LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISIN=
G
 FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DE=
ALINGS
 WITH THE SOFTWARE.



|--------------------------------------------------------------|
Mon Mar 16 07:46:06 CDT 2020 ESMF_Scrip2Unstruct -V .......PASS
The following is the output of ESMF_Scrip2Unstruct -V

   ESMF_VERSION_STRING:       8.1.0 beta snapshot



|--------------------------------------------------------------|
Mon Mar 16 07:46:08 CDT 2020 ESMF_WebServController --help PASS
The following is the output of ESMF_WebServController --help

ESMF_WebServController: Run a Process Controller that provides access t=
o an ESMF Web Service enabled Component.
Usage: ESMF_WebServController [--help] [--version] [-V] procCtrlPort re=
gistrarHost registrarPort
    [--help]        Display this information and exit.
    [--version]     Display ESMF version and license information and ex=
it.
    [-V]            Display ESMF version string and exit.
    procCtrlPort    Port num for Process Controller listener.
    registrarHost   Host name on which Registrar is running.
    registrarPort   Port num on which Registrar is listening.
    runScriptDir    Directory containing run script.
    runScriptFile   File name of run script.




|--------------------------------------------------------------|
Mon Mar 16 07:46:08 CDT 2020 ESMF_WebServController --version PASS
The following is the output of ESMF_WebServController --version

   ESMF_VERSION_STRING:       8.1.0 beta snapshot
   ESMF_VERSION_MAJOR:                   8
   ESMF_VERSION_MINOR:                   1
   ESMF_VERSION_REVISION:                0
   ESMF_VERSION_PATCHLEVEL:              0
   ESMF_VERSION_PUBLIC:        F
   ESMF_VERSION_BETASNAPSHOT:  T
=20
 Earth System Modeling Framework
=20
 Copyright (c) 2002-2020 University Corporation for Atmospheric Researc=
h,
 Massachusetts Institute of Technology, Geophysical Fluid Dynamics Labo=
ratory,
 University of Michigan, National Centers for Environmental Prediction,
 Los Alamos National Laboratory, Argonne National Laboratory,
 NASA Goddard Space Flight Center.
 All rights reserved.
=20
 Permission is hereby granted, free of charge, to any person obtaining =
a copy
 of this software and associated documentation files (the 'Software'), =
to
 deal with the Software without restriction, including without limitati=
on the
 rights to use, copy, modify, merge, publish, distribute, sublicense, a=
nd/or
 sell copies of the Software, and to permit persons to whom the Softwar=
e is
 furnished to do so, subject to the following conditions:
    1. Redistributions of source code must retain the above copyright n=
otice,
       this list of conditions and the following disclaimers.
    2. Redistributions in binary form must reproduce the above copyrigh=
t
       notice, this list of conditions and the following disclaimers in=
 the
       documentation and/or other materials provided with the distribut=
ion.
    3. Neither the names of the organizations developing this software,=
 nor
       the names of its contributors may be used to endorse or promote =
products
       derived from this Software without specific prior written permis=
sion.
=20
 THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRES=
S OR
 IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILIT=
Y,
 FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHAL=
L THE
 CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR =
OTHER
 LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISIN=
G
 FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DE=
ALINGS
 WITH THE SOFTWARE.



|--------------------------------------------------------------|
Mon Mar 16 07:46:08 CDT 2020 ESMF_WebServController -V ....PASS
The following is the output of ESMF_WebServController -V

   ESMF_VERSION_STRING:       8.1.0 beta snapshot




Ran 18 applications tests, 18 passed and 0 failed.

|----------------------- SYSTEM TESTS -------------------------|
Mon Mar 16 07:56:34 CDT 2020 build_system_tests -j4 .......PASS
Mon Mar 16 08:00:26 CDT 2020 run_system_tests .............PASS


The following system tests passed:


PASS: mvapich2/O: src/system_tests/ESMF_ArrayBundleRedist/ESMF_ArrayBun=
dleRedistSTest.F90
PASS: mvapich2/O: src/system_tests/ESMF_ArrayBundleSparseMatMul/ESMF_Ar=
rayBundleSparseMatMulSTest.F90
PASS: mvapich2/O: src/system_tests/ESMF_ArrayRedist/ESMF_ArrayRedistSTe=
st.F90
PASS: mvapich2/O: src/system_tests/ESMF_ArrayRedist3D/ESMF_ArrayRedist3=
DSTest.F90
PASS: mvapich2/O: src/system_tests/ESMF_ArrayRedistOpenACC/ESMF_ArrayRe=
distOpenACCSTest.F90
PASS: mvapich2/O: src/system_tests/ESMF_ArrayRedistOpenMP/ESMF_ArrayRed=
istOpenMPSTest.F90
PASS: mvapich2/O: src/system_tests/ESMF_ArrayScatterGather/ESMF_ArraySc=
atterGatherSTest.F90
PASS: mvapich2/O: src/system_tests/ESMF_ArraySharedDeSSI/ESMF_ArrayShar=
edDeSSISTest.F90
PASS: mvapich2/O: src/system_tests/ESMF_ArraySparseMatMul/ESMF_ArraySpa=
rseMatMulSTest.F90
PASS: mvapich2/O: src/system_tests/ESMF_Attribute/ESMF_AttributeSTest.F=
90
PASS: mvapich2/O: src/system_tests/ESMF_AttributeCIM/ESMF_AttributeCIMS=
Test.F90
PASS: mvapich2/O: src/system_tests/ESMF_CompCreate/ESMF_CompCreateSTest=
.F90
PASS: mvapich2/O: src/system_tests/ESMF_CompFortranAndC/ESMF_CompFortra=
nAndCSTest.F90
PASS: mvapich2/O: src/system_tests/ESMF_ComplianceChecker/ESMF_Complian=
ceCheckerSTest.F90
PASS: mvapich2/O: src/system_tests/ESMF_ConcurrentComponent/ESMF_Concur=
rentCompSTest.F90
PASS: mvapich2/O: src/system_tests/ESMF_ConcurrentEnsemble/ESMF_Concurr=
entEnsembleSTest.F90
PASS: mvapich2/O: src/system_tests/ESMF_DirectCoupling/ESMF_DirectCoupl=
ingSTest.F90
PASS: mvapich2/O: src/system_tests/ESMF_FieldBundleLSRedistArb2Arb/ESMF=
_FieldBundleLSRedistArb2ArbSTest.F90
PASS: mvapich2/O: src/system_tests/ESMF_FieldBundleLSRedistArb2ArbUngrd=
Dim/ESMF_FieldBundleLSRedistArb2ArbUngrdDimSTest.F90
PASS: mvapich2/O: src/system_tests/ESMF_FieldBundleRedistArb2Arb/ESMF_F=
ieldBundleRedistArb2ArbSTest.F90
PASS: mvapich2/O: src/system_tests/ESMF_FieldBundleRedistBlk2Arb/ESMF_F=
ieldBundleRedistBlk2ArbSTest.F90
PASS: mvapich2/O: src/system_tests/ESMF_FieldBundleRedistBlk2Blk/ESMF_F=
ieldBundleRedistBlk2BlkSTest.F90
PASS: mvapich2/O: src/system_tests/ESMF_FieldBundleSMM/ESMF_FieldBundle=
SMMSTest.F90
PASS: mvapich2/O: src/system_tests/ESMF_FieldBundleSMMPacked/ESMF_Field=
BundleSMMPackedSTest.F90
PASS: mvapich2/O: src/system_tests/ESMF_FieldConcurrentComp/ESMF_FieldC=
onCompSTest.F90
PASS: mvapich2/O: src/system_tests/ESMF_FieldLSRedistArb2Arb/ESMF_Field=
LSRedistArb2ArbSTest.F90
PASS: mvapich2/O: src/system_tests/ESMF_FieldLSRedistArb2ArbUngrdDim/ES=
MF_FieldLSRedistArb2ArbUngrdDimSTest.F90
PASS: mvapich2/O: src/system_tests/ESMF_FieldLSSMM/ESMF_FieldLSSMMSTest=
.F90
PASS: mvapich2/O: src/system_tests/ESMF_FieldMeshSMM/ESMF_FieldMeshSMMS=
Test.F90
PASS: mvapich2/O: src/system_tests/ESMF_FieldRedist/ESMF_FieldRedistSTe=
st.F90
PASS: mvapich2/O: src/system_tests/ESMF_FieldRedistArb2Arb/ESMF_FieldRe=
distArb2ArbSTest.F90
PASS: mvapich2/O: src/system_tests/ESMF_FieldRedistBlk2Arb/ESMF_FieldRe=
distBlk2ArbSTest.F90
PASS: mvapich2/O: src/system_tests/ESMF_FieldRedistBlk2Blk/ESMF_FieldRe=
distBlk2BlkSTest.F90
PASS: mvapich2/O: src/system_tests/ESMF_FieldRegrid/ESMF_FieldRegridSTe=
st.F90
PASS: mvapich2/O: src/system_tests/ESMF_FieldRegridDisjoint/ESMF_FieldR=
egridDisjointSTest.F90
PASS: mvapich2/O: src/system_tests/ESMF_FieldRegridMesh/ESMF_FieldRegri=
dMeshSTest.F90
PASS: mvapich2/O: src/system_tests/ESMF_FieldRegridMeshToMesh/ESMF_Fiel=
dRegridMeshToMeshSTest.F90
PASS: mvapich2/O: src/system_tests/ESMF_FieldRegridOverlap/ESMF_FieldRe=
gridOverlapSTest.F90
PASS: mvapich2/O: src/system_tests/ESMF_FieldSparseMatMul/ESMF_FieldSpa=
rseMatMulSTest.F90
PASS: mvapich2/O: src/system_tests/ESMF_RecursiveComponent/ESMF_Recursi=
veComponentSTest.F90
PASS: mvapich2/O: src/system_tests/ESMF_SequentialEnsemble/ESMF_Sequent=
ialEnsembleSTest.F90
PASS: mvapich2/O: src/system_tests/ESMF_Trace/ESMF_TraceSTest.F90
PASS: mvapich2/O: src/system_tests/ESMF_TransferGrid/ESMF_TransferGridS=
Test.F90
PASS: mvapich2/O: src/system_tests/ESMF_TransferMesh/ESMF_TransferMeshS=
Test.F90
PASS: mvapich2/O: src/system_tests/ESMF_XGridConcurrent/ESMF_XGridConcu=
rrentSTest.F90


The following system test failed, did not build, or did not execute:


FAIL: mvapich2/O: src/system_tests/ESMF_XGridSerial/ESMF_XGridSerialSTe=
st.F90




The stdout files for the system_tests can be found at:
/lcrc/project/ESMF/scripts_dirs/daily_builds/intel_bebop/esmf/test/test=
O/Linux.intel.64.mvapich2.default


Found 46 multi-processor system tests, 45 passed and 1 failed.



|------------------------- EXAMPLES ---------------------------|
Mon Mar 16 08:15:25 CDT 2020 build_examples -j4 ...........PASS
Mon Mar 16 08:25:51 CDT 2020 run_examples .................PASS


The following examples passed:


PASS: mvapich2/O: src/Infrastructure/Array/examples/ESMF_ArrayArbHaloEx=
.F90
PASS: mvapich2/O: src/Infrastructure/Array/examples/ESMF_ArrayCommNBEx.=
F90
PASS: mvapich2/O: src/Infrastructure/Array/examples/ESMF_ArrayEx.F90
PASS: mvapich2/O: src/Infrastructure/Array/examples/ESMF_ArrayFarrayEx.=
F90
PASS: mvapich2/O: src/Infrastructure/Array/examples/ESMF_ArrayFarrayHal=
oEx.F90
PASS: mvapich2/O: src/Infrastructure/Array/examples/ESMF_ArrayHaloEx.F9=
0
PASS: mvapich2/O: src/Infrastructure/Array/examples/ESMF_ArrayLarrayEx.=
F90
PASS: mvapich2/O: src/Infrastructure/Array/examples/ESMF_ArrayRedistEx.=
F90
PASS: mvapich2/O: src/Infrastructure/Array/examples/ESMF_ArrayScatterGa=
therArbEx.F90
PASS: mvapich2/O: src/Infrastructure/Array/examples/ESMF_ArrayScatterGa=
therEx.F90
PASS: mvapich2/O: src/Infrastructure/Array/examples/ESMF_ArraySparseMat=
MulEx.F90
PASS: mvapich2/O: src/Infrastructure/ArrayBundle/examples/ESMF_ArrayBun=
dleEx.F90
PASS: mvapich2/O: src/Infrastructure/ArrayBundle/examples/ESMF_ArrayBun=
dleHaloEx.F90
PASS: mvapich2/O: src/Infrastructure/ArraySpec/examples/ESMF_ArraySpecE=
x.F90
PASS: mvapich2/O: src/Infrastructure/Config/examples/ESMF_ConfigOvervie=
wEx.F90
PASS: mvapich2/O: src/Infrastructure/DELayout/examples/ESMF_DELayoutEx.=
F90
PASS: mvapich2/O: src/Infrastructure/DistGrid/examples/ESMF_DistGridEx.=
F90
PASS: mvapich2/O: src/Infrastructure/Field/examples/ESMF_FieldArbGridEx=
.F90
PASS: mvapich2/O: src/Infrastructure/Field/examples/ESMF_FieldCommEx.F9=
0
PASS: mvapich2/O: src/Infrastructure/Field/examples/ESMF_FieldCreateEx.=
F90
PASS: mvapich2/O: src/Infrastructure/Field/examples/ESMF_FieldEx.F90
PASS: mvapich2/O: src/Infrastructure/Field/examples/ESMF_FieldHaloEx.F9=
0
PASS: mvapich2/O: src/Infrastructure/Field/examples/ESMF_FieldMeshRegri=
dEx.F90
PASS: mvapich2/O: src/Infrastructure/Field/examples/ESMF_FieldRedistEx.=
F90
PASS: mvapich2/O: src/Infrastructure/Field/examples/ESMF_FieldRegridEx.=
F90
PASS: mvapich2/O: src/Infrastructure/Field/examples/ESMF_FieldRegridMas=
kEx.F90
PASS: mvapich2/O: src/Infrastructure/Field/examples/ESMF_FieldRepDimEx.=
F90
PASS: mvapich2/O: src/Infrastructure/Field/examples/ESMF_FieldSMMEx.F90
PASS: mvapich2/O: src/Infrastructure/Field/examples/ESMF_FieldSphereReg=
ridEx.F90
PASS: mvapich2/O: src/Infrastructure/FieldBundle/examples/ESMF_FieldBun=
dleCreateEx.F90
PASS: mvapich2/O: src/Infrastructure/FieldBundle/examples/ESMF_FieldBun=
dleHaloEx.F90
PASS: mvapich2/O: src/Infrastructure/FieldBundle/examples/ESMF_FieldBun=
dleRedistEx.F90
PASS: mvapich2/O: src/Infrastructure/FieldBundle/examples/ESMF_FieldBun=
dleSMMEx.F90
PASS: mvapich2/O: src/Infrastructure/Grid/examples/ESMF_GridCreateRegFr=
omDGEx.F90
PASS: mvapich2/O: src/Infrastructure/Grid/examples/ESMF_GridUsageEx.F90
PASS: mvapich2/O: src/Infrastructure/LocStream/examples/ESMF_LocStreamE=
x.F90
PASS: mvapich2/O: src/Infrastructure/LogErr/examples/ESMF_LogErrEx.F90
PASS: mvapich2/O: src/Infrastructure/Mesh/examples/ESMF_MeshEx.F90
PASS: mvapich2/O: src/Infrastructure/Route/examples/ESMF_RHandleBitForB=
itEx.F90
PASS: mvapich2/O: src/Infrastructure/Route/examples/ESMF_RHandleDynamic=
MaskingEx.F90
PASS: mvapich2/O: src/Infrastructure/Route/examples/ESMF_RHandleFromFil=
eEx.F90
PASS: mvapich2/O: src/Infrastructure/Route/examples/ESMF_RHandleFromRHa=
ndleEx.F90
PASS: mvapich2/O: src/Infrastructure/Route/examples/ESMF_RHandleReusabi=
lityEx.F90
PASS: mvapich2/O: src/Infrastructure/TimeMgr/examples/ESMF_AlarmEx.F90
PASS: mvapich2/O: src/Infrastructure/TimeMgr/examples/ESMF_CalendarEx.F=
90
PASS: mvapich2/O: src/Infrastructure/TimeMgr/examples/ESMF_ClockEx.F90
PASS: mvapich2/O: src/Infrastructure/TimeMgr/examples/ESMF_TimeEx.F90
PASS: mvapich2/O: src/Infrastructure/TimeMgr/examples/ESMF_TimeInterval=
Ex.F90
PASS: mvapich2/O: src/Infrastructure/Trace/examples/ESMF_TraceEx.F90
PASS: mvapich2/O: src/Infrastructure/Trace/examples/ESMF_TraceUserEx.F9=
0
PASS: mvapich2/O: src/Infrastructure/VM/examples/ESMF_VMAllFullReduceEx=
.F90
PASS: mvapich2/O: src/Infrastructure/VM/examples/ESMF_VMComponentEx.F90
PASS: mvapich2/O: src/Infrastructure/VM/examples/ESMF_VMDefaultBasicsEx=
.F90
PASS: mvapich2/O: src/Infrastructure/VM/examples/ESMF_VMGetMPICommunica=
torEx.F90
PASS: mvapich2/O: src/Infrastructure/VM/examples/ESMF_VMHigherRankDataE=
x.F90
PASS: mvapich2/O: src/Infrastructure/VM/examples/ESMF_VMScatterVMGather=
Ex.F90
PASS: mvapich2/O: src/Infrastructure/VM/examples/ESMF_VMSendVMRecvEx.F9=
0
PASS: mvapich2/O: src/Infrastructure/VM/examples/ESMF_VMUserMpiCommEx.F=
90
PASS: mvapich2/O: src/Infrastructure/VM/examples/ESMF_VMUserMpiCommMult=
iEx.F90
PASS: mvapich2/O: src/Infrastructure/VM/examples/ESMF_VMUserMpiEx.F90
PASS: mvapich2/O: src/Infrastructure/XGrid/examples/ESMF_XGridEx.F90
PASS: mvapich2/O: src/Infrastructure/XGrid/examples/ESMF_XGridSparseMat=
Ex.F90
PASS: mvapich2/O: src/Superstructure/AttachMethods/examples/ESMF_Attach=
MethodsEx.F90
PASS: mvapich2/O: src/Superstructure/AttributeAPI/examples/ESMF_AttRead=
CustCplCompEx.F90
PASS: mvapich2/O: src/Superstructure/AttributeAPI/examples/ESMF_AttRead=
FieldEx.F90
PASS: mvapich2/O: src/Superstructure/AttributeAPI/examples/ESMF_AttRead=
GridCompEx.F90
PASS: mvapich2/O: src/Superstructure/AttributeAPI/examples/ESMF_Attribu=
teCIMEx.F90
PASS: mvapich2/O: src/Superstructure/AttributeAPI/examples/ESMF_Attribu=
teCustPackEx.F90
PASS: mvapich2/O: src/Superstructure/AttributeAPI/examples/ESMF_Attribu=
teEx.F90
PASS: mvapich2/O: src/Superstructure/AttributeAPI/examples/ESMF_Attribu=
teInternalInfoEx.F90
PASS: mvapich2/O: src/Superstructure/AttributeAPI/examples/ESMF_Attribu=
tePackageEx.F90
PASS: mvapich2/O: src/Superstructure/AttributeAPI/examples/ESMF_Attribu=
teUpdateEx.F90
PASS: mvapich2/O: src/Superstructure/Component/examples/ESMF_AppMainEx.=
F90
PASS: mvapich2/O: src/Superstructure/Component/examples/ESMF_CompTunnel=
Ex.F90
PASS: mvapich2/O: src/Superstructure/Component/examples/ESMF_CplEx.F90
PASS: mvapich2/O: src/Superstructure/Component/examples/ESMF_GCompEx.F9=
0
PASS: mvapich2/O: src/Superstructure/Component/examples/ESMF_InternalSt=
ateEx.F90
PASS: mvapich2/O: src/Superstructure/Component/examples/ESMF_InternalSt=
ateModEx.F90
PASS: mvapich2/O: src/Superstructure/Component/examples/ESMF_SCompEx.F9=
0
PASS: mvapich2/O: src/Superstructure/State/examples/ESMF_StateEx.F90
PASS: mvapich2/O: src/Superstructure/State/examples/ESMF_StateReadWrite=
Ex.F90
PASS: mvapich2/O: src/Superstructure/State/examples/ESMF_StateReconcile=
Ex.F90
PASS: mvapich2/O: src/Superstructure/WebServices/examples/ESMF_WebServi=
cesEx.F90
PASS: mvapich2/O: src/addon/NUOPC/examples/ESMF_NUOPCAtmModelEx.F90
PASS: mvapich2/O: src/addon/NUOPC/examples/ESMF_NUOPCBasicModelEx.F90




The stdout files for the examples can be found at:
/lcrc/project/ESMF/scripts_dirs/daily_builds/intel_bebop/esmf/examples/=
examplesO/Linux.intel.64.mvapich2.default


Found 85 multi-processor examples, 85 passed and 0 failed.



|-------------------- EXHAUSTIVE UNIT TESTS -------------------|
Mon Mar 16 09:05:36 CDT 2020 build_unit_tests -j4 .........PASS
Mon Mar 16 09:22:15 CDT 2020 run_unit_tests ...............PASS




The unit tests in the following files all pass:

PASS: mvapich2/O: src/Infrastructure/Array/tests/ESMC_ArrayUTest.C
PASS: mvapich2/O: src/Infrastructure/Array/tests/ESMF_ArrayArbIdxSMMUTe=
st.F90
PASS: mvapich2/O: src/Infrastructure/Array/tests/ESMF_ArrayCreateGetUTe=
st.F90
PASS: mvapich2/O: src/Infrastructure/Array/tests/ESMF_ArrayDataUTest.F9=
0
PASS: mvapich2/O: src/Infrastructure/Array/tests/ESMF_ArrayGatherUTest.=
F90
PASS: mvapich2/O: src/Infrastructure/Array/tests/ESMF_ArrayHaloUTest.F9=
0
PASS: mvapich2/O: src/Infrastructure/Array/tests/ESMF_ArrayIOUTest.F90
PASS: mvapich2/O: src/Infrastructure/Array/tests/ESMF_ArrayRedistPerfUT=
est.F90
PASS: mvapich2/O: src/Infrastructure/Array/tests/ESMF_ArrayRedistUTest.=
F90
PASS: mvapich2/O: src/Infrastructure/Array/tests/ESMF_ArraySMMFromFileU=
Test.F90
PASS: mvapich2/O: src/Infrastructure/Array/tests/ESMF_ArraySMMUTest.F90
PASS: mvapich2/O: src/Infrastructure/Array/tests/ESMF_ArrayScatterUTest=
.F90
PASS: mvapich2/O: src/Infrastructure/ArrayBundle/tests/ESMF_ArrayBundle=
CreateUTest.F90
PASS: mvapich2/O: src/Infrastructure/ArrayBundle/tests/ESMF_ArrayBundle=
IOUTest.F90
PASS: mvapich2/O: src/Infrastructure/ArrayBundle/tests/ESMF_ArrayBundle=
RedistUTest.F90
PASS: mvapich2/O: src/Infrastructure/ArraySpec/tests/ESMC_ArraySpecUTes=
t.C
PASS: mvapich2/O: src/Infrastructure/ArraySpec/tests/ESMF_ArraySpecUTes=
t.F90
PASS: mvapich2/O: src/Infrastructure/Base/tests/ESMC_BaseUTest.C
PASS: mvapich2/O: src/Infrastructure/Base/tests/ESMF_BaseUTest.F90
PASS: mvapich2/O: src/Infrastructure/Config/tests/ESMC_ConfigUTest.C
PASS: mvapich2/O: src/Infrastructure/Config/tests/ESMF_ConfigUTest.F90
PASS: mvapich2/O: src/Infrastructure/Container/tests/ESMF_ContainerUTes=
t.F90
PASS: mvapich2/O: src/Infrastructure/DELayout/tests/ESMF_DELayoutUTest.=
F90
PASS: mvapich2/O: src/Infrastructure/DELayout/tests/ESMF_DELayoutWorkQu=
eueUTest.F90
PASS: mvapich2/O: src/Infrastructure/DistGrid/tests/ESMC_DistGridUTest.=
C
PASS: mvapich2/O: src/Infrastructure/DistGrid/tests/ESMF_DistGridCreate=
GetUTest.F90
PASS: mvapich2/O: src/Infrastructure/Field/tests/ESMC_FieldGridGridRegr=
idCsrvUTest.C
PASS: mvapich2/O: src/Infrastructure/Field/tests/ESMC_FieldGridGridRegr=
idUTest.C
PASS: mvapich2/O: src/Infrastructure/Field/tests/ESMC_FieldGridRegrid2U=
Test.C
PASS: mvapich2/O: src/Infrastructure/Field/tests/ESMC_FieldGridRegridCs=
rv2UTest.C
PASS: mvapich2/O: src/Infrastructure/Field/tests/ESMC_FieldGridRegridCs=
rvUTest.C
PASS: mvapich2/O: src/Infrastructure/Field/tests/ESMC_FieldGridRegridPa=
rUTest.C
PASS: mvapich2/O: src/Infrastructure/Field/tests/ESMC_FieldGridRegridUT=
est.C
PASS: mvapich2/O: src/Infrastructure/Field/tests/ESMC_FieldRegridCsrvUT=
est.C
PASS: mvapich2/O: src/Infrastructure/Field/tests/ESMC_FieldRegridUTest.=
C
PASS: mvapich2/O: src/Infrastructure/Field/tests/ESMC_FieldSMMFromFileU=
Test.C
PASS: mvapich2/O: src/Infrastructure/Field/tests/ESMC_FieldUTest.C
PASS: mvapich2/O: src/Infrastructure/Field/tests/ESMF_FieldArbGridUTest=
.F90
PASS: mvapich2/O: src/Infrastructure/Field/tests/ESMF_FieldCreateGetUTe=
st.F90
PASS: mvapich2/O: src/Infrastructure/Field/tests/ESMF_FieldGatherUTest.=
F90
PASS: mvapich2/O: src/Infrastructure/Field/tests/ESMF_FieldHaloUTest.F9=
0
PASS: mvapich2/O: src/Infrastructure/Field/tests/ESMF_FieldIOUTest.F90
PASS: mvapich2/O: src/Infrastructure/Field/tests/ESMF_FieldLSSMMUTest.F=
90
PASS: mvapich2/O: src/Infrastructure/Field/tests/ESMF_FieldRedistArbUTe=
st.F90
PASS: mvapich2/O: src/Infrastructure/Field/tests/ESMF_FieldRedistUTest.=
F90
PASS: mvapich2/O: src/Infrastructure/Field/tests/ESMF_FieldRegridCSUTes=
t.F90
PASS: mvapich2/O: src/Infrastructure/Field/tests/ESMF_FieldRegridCsrv2n=
dUTest.F90
PASS: mvapich2/O: src/Infrastructure/Field/tests/ESMF_FieldRegridCsrvUT=
est.F90
PASS: mvapich2/O: src/Infrastructure/Field/tests/ESMF_FieldRegridUTest.=
F90
PASS: mvapich2/O: src/Infrastructure/Field/tests/ESMF_FieldRegridXGSMMU=
Test.F90
PASS: mvapich2/O: src/Infrastructure/Field/tests/ESMF_FieldRegridXGUTes=
t.F90
PASS: mvapich2/O: src/Infrastructure/Field/tests/ESMF_FieldSMMFromFileU=
Test.F90
PASS: mvapich2/O: src/Infrastructure/Field/tests/ESMF_FieldSMMUTest.F90
PASS: mvapich2/O: src/Infrastructure/Field/tests/ESMF_FieldStressUTest.=
F90
PASS: mvapich2/O: src/Infrastructure/Field/tests/ESMF_FieldUTest.F90
PASS: mvapich2/O: src/Infrastructure/FieldBundle/tests/ESMF_FieldBundle=
CrGetUTest.F90
PASS: mvapich2/O: src/Infrastructure/FieldBundle/tests/ESMF_FieldBundle=
IOUTest.F90
PASS: mvapich2/O: src/Infrastructure/FieldBundle/tests/ESMF_FieldBundle=
RedistUTest.F90
PASS: mvapich2/O: src/Infrastructure/FieldBundle/tests/ESMF_FieldBundle=
RegridUTest.F90
PASS: mvapich2/O: src/Infrastructure/FieldBundle/tests/ESMF_FieldBundle=
SMMUTest.F90
PASS: mvapich2/O: src/Infrastructure/FieldBundle/tests/ESMF_FieldBundle=
UTest.F90
PASS: mvapich2/O: src/Infrastructure/Grid/tests/ESMC_GridUTest.C
PASS: mvapich2/O: src/Infrastructure/Grid/tests/ESMF_GridArbitraryUTest=
.F90
PASS: mvapich2/O: src/Infrastructure/Grid/tests/ESMF_GridCoordUTest.F90
PASS: mvapich2/O: src/Infrastructure/Grid/tests/ESMF_GridCreateUTest.F9=
0
PASS: mvapich2/O: src/Infrastructure/Grid/tests/ESMF_GridItemUTest.F90
PASS: mvapich2/O: src/Infrastructure/GridUtil/tests/ESMF_GridToMeshUTes=
t.F90
PASS: mvapich2/O: src/Infrastructure/IO/tests/ESMCI_IO_NetCDFUTest.C
PASS: mvapich2/O: src/Infrastructure/IO/tests/ESMCI_IO_PIOUTest.C
PASS: mvapich2/O: src/Infrastructure/IO/tests/ESMC_IO_InqUTest.C
PASS: mvapich2/O: src/Infrastructure/IO/tests/ESMF_IOUTest.F90
PASS: mvapich2/O: src/Infrastructure/IO/tests/ESMF_IO_PIOUTest.F90
PASS: mvapich2/O: src/Infrastructure/IO/tests/ESMF_IO_YAMLUTest.F90
PASS: mvapich2/O: src/Infrastructure/LocStream/tests/ESMC_LocStreamUTes=
t.C
PASS: mvapich2/O: src/Infrastructure/LocStream/tests/ESMF_LocStreamUTes=
t.F90
PASS: mvapich2/O: src/Infrastructure/LocalArray/tests/ESMF_LocalArrayDa=
taUTest.F90
PASS: mvapich2/O: src/Infrastructure/LocalArray/tests/ESMF_LocalArrayUT=
est.F90
PASS: mvapich2/O: src/Infrastructure/LogErr/tests/ESMC_LogErrPerfUTest.=
C
PASS: mvapich2/O: src/Infrastructure/LogErr/tests/ESMC_LogErrUTest.C
PASS: mvapich2/O: src/Infrastructure/LogErr/tests/ESMF_LogErrPerfUTest.=
F90
PASS: mvapich2/O: src/Infrastructure/LogErr/tests/ESMF_LogErrUTest.F90
PASS: mvapich2/O: src/Infrastructure/Mesh/tests/ESMC_MBMesh_BilinearPar=
UTest.C
PASS: mvapich2/O: src/Infrastructure/Mesh/tests/ESMC_MBMesh_BilinearSin=
gleElemUTest.C
PASS: mvapich2/O: src/Infrastructure/Mesh/tests/ESMC_MBMesh_BilinearUTe=
st.C
PASS: mvapich2/O: src/Infrastructure/Mesh/tests/ESMC_MBMesh_CreateParUT=
est.C
PASS: mvapich2/O: src/Infrastructure/Mesh/tests/ESMC_MBMesh_CreateUTest=
.C
PASS: mvapich2/O: src/Infrastructure/Mesh/tests/ESMC_MBMesh_SearchUTest=
.C
PASS: mvapich2/O: src/Infrastructure/Mesh/tests/ESMC_MBMesh_SerializeUT=
est.C
PASS: mvapich2/O: src/Infrastructure/Mesh/tests/ESMC_MBMesh_UtilParUTes=
t.C
PASS: mvapich2/O: src/Infrastructure/Mesh/tests/ESMC_MBMesh_UtilUTest.C
PASS: mvapich2/O: src/Infrastructure/Mesh/tests/ESMC_MeshMOABUTest.C
PASS: mvapich2/O: src/Infrastructure/Mesh/tests/ESMC_MeshUTest.C
PASS: mvapich2/O: src/Infrastructure/Mesh/tests/ESMC_MeshVTKUTest.C
PASS: mvapich2/O: src/Infrastructure/Mesh/tests/ESMC_Proj4UTest.C
PASS: mvapich2/O: src/Infrastructure/Mesh/tests/ESMF_MeshOpUTest.F90
PASS: mvapich2/O: src/Infrastructure/Mesh/tests/ESMF_MeshUTest.F90
PASS: mvapich2/O: src/Infrastructure/PointList/tests/ESMF_PointListUTes=
t.F90
PASS: mvapich2/O: src/Infrastructure/Route/tests/ESMF_RouteHandleAdvanc=
edUTest.F90
PASS: mvapich2/O: src/Infrastructure/Route/tests/ESMF_RouteHandleUTest.=
F90
PASS: mvapich2/O: src/Infrastructure/TimeMgr/tests/ESMC_CalendarUTest.C
PASS: mvapich2/O: src/Infrastructure/TimeMgr/tests/ESMC_ClockUTest.C
PASS: mvapich2/O: src/Infrastructure/TimeMgr/tests/ESMC_TimeIntervalUTe=
st.C
PASS: mvapich2/O: src/Infrastructure/TimeMgr/tests/ESMC_TimeUTest.C
PASS: mvapich2/O: src/Infrastructure/TimeMgr/tests/ESMF_AlarmUTest.F90
PASS: mvapich2/O: src/Infrastructure/TimeMgr/tests/ESMF_CalRangeUTest.F=
90
PASS: mvapich2/O: src/Infrastructure/TimeMgr/tests/ESMF_CalendarUTest.F=
90
PASS: mvapich2/O: src/Infrastructure/TimeMgr/tests/ESMF_ClockUTest.F90
PASS: mvapich2/O: src/Infrastructure/TimeMgr/tests/ESMF_TimeIntervalUTe=
st.F90
PASS: mvapich2/O: src/Infrastructure/TimeMgr/tests/ESMF_TimeUTest.F90
PASS: mvapich2/O: src/Infrastructure/Trace/tests/ESMC_TraceRegionUTest.=
C
PASS: mvapich2/O: src/Infrastructure/Trace/tests/ESMF_ProfileUTest.F90
PASS: mvapich2/O: src/Infrastructure/Trace/tests/ESMF_TraceClkMonoSyncU=
Test.F90
PASS: mvapich2/O: src/Infrastructure/Trace/tests/ESMF_TraceClkMonoUTest=
.F90
PASS: mvapich2/O: src/Infrastructure/Trace/tests/ESMF_TraceIOUTest.F90
PASS: mvapich2/O: src/Infrastructure/Trace/tests/ESMF_TraceMPIUTest.F90
PASS: mvapich2/O: src/Infrastructure/Trace/tests/ESMF_TraceUTest.F90
PASS: mvapich2/O: src/Infrastructure/Util/tests/ESMF_FortranWordsizeUTe=
st.F90
PASS: mvapich2/O: src/Infrastructure/Util/tests/ESMF_InitMacrosUTest.F9=
0
PASS: mvapich2/O: src/Infrastructure/Util/tests/ESMF_TypeKindGetUTest.F=
90
PASS: mvapich2/O: src/Infrastructure/Util/tests/ESMF_UtilUTest.F90
PASS: mvapich2/O: src/Infrastructure/VM/tests/ESMC_VMUTest.C
PASS: mvapich2/O: src/Infrastructure/VM/tests/ESMF_VMAccUTest.F90
PASS: mvapich2/O: src/Infrastructure/VM/tests/ESMF_VMAllGatherUTest.F90
PASS: mvapich2/O: src/Infrastructure/VM/tests/ESMF_VMAllGatherVUTest.F9=
0
PASS: mvapich2/O: src/Infrastructure/VM/tests/ESMF_VMAllToAllUTest.F90
PASS: mvapich2/O: src/Infrastructure/VM/tests/ESMF_VMAllToAllVUTest.F90
PASS: mvapich2/O: src/Infrastructure/VM/tests/ESMF_VMBarrierUTest.F90
PASS: mvapich2/O: src/Infrastructure/VM/tests/ESMF_VMBroadcastUTest.F90
PASS: mvapich2/O: src/Infrastructure/VM/tests/ESMF_VMComponentUTest.F90
PASS: mvapich2/O: src/Infrastructure/VM/tests/ESMF_VMGatherUTest.F90
PASS: mvapich2/O: src/Infrastructure/VM/tests/ESMF_VMOpenMPUTest.F90
PASS: mvapich2/O: src/Infrastructure/VM/tests/ESMF_VMScatterUTest.F90
PASS: mvapich2/O: src/Infrastructure/VM/tests/ESMF_VMSendNbVMRecvNbUTes=
t.F90
PASS: mvapich2/O: src/Infrastructure/VM/tests/ESMF_VMSendRecvNbUTest.F9=
0
PASS: mvapich2/O: src/Infrastructure/VM/tests/ESMF_VMSendRecvUTest.F90
PASS: mvapich2/O: src/Infrastructure/VM/tests/ESMF_VMSendVMRecvUTest.F9=
0
PASS: mvapich2/O: src/Infrastructure/VM/tests/ESMF_VMUTest.F90
PASS: mvapich2/O: src/Infrastructure/VM/tests/ESMF_VMUserMpiInitUTest.F=
90
PASS: mvapich2/O: src/Infrastructure/XGrid/tests/ESMC_XGridUTest.C
PASS: mvapich2/O: src/Infrastructure/XGrid/tests/ESMF_XGridMaskingUTest=
.F90
PASS: mvapich2/O: src/Infrastructure/XGrid/tests/ESMF_XGridUTest.F90
PASS: mvapich2/O: src/Superstructure/AttributeAPI/tests/ESMF_AttInterna=
lGridUTest.F90
PASS: mvapich2/O: src/Superstructure/AttributeAPI/tests/ESMF_AttPackABu=
ndleUTest.F90
PASS: mvapich2/O: src/Superstructure/AttributeAPI/tests/ESMF_AttPackArr=
ayUTest.F90
PASS: mvapich2/O: src/Superstructure/AttributeAPI/tests/ESMF_AttPackCpl=
CompUTest.F90
PASS: mvapich2/O: src/Superstructure/AttributeAPI/tests/ESMF_AttPackDis=
tGridUTest.F90
PASS: mvapich2/O: src/Superstructure/AttributeAPI/tests/ESMF_AttPackFBu=
ndleUTest.F90
PASS: mvapich2/O: src/Superstructure/AttributeAPI/tests/ESMF_AttPackFie=
ldUTest.F90
PASS: mvapich2/O: src/Superstructure/AttributeAPI/tests/ESMF_AttPackGri=
dCompUTest.F90
PASS: mvapich2/O: src/Superstructure/AttributeAPI/tests/ESMF_AttPackGri=
dUTest.F90
PASS: mvapich2/O: src/Superstructure/AttributeAPI/tests/ESMF_AttPackLoc=
StreamUTest.F90
PASS: mvapich2/O: src/Superstructure/AttributeAPI/tests/ESMF_AttPackSci=
CompUTest.F90
PASS: mvapich2/O: src/Superstructure/AttributeAPI/tests/ESMF_AttPackSta=
teUTest.F90
PASS: mvapich2/O: src/Superstructure/AttributeAPI/tests/ESMF_AttReadCpl=
CompUTest.F90
PASS: mvapich2/O: src/Superstructure/AttributeAPI/tests/ESMF_AttReadFie=
ldUTest.F90
PASS: mvapich2/O: src/Superstructure/AttributeAPI/tests/ESMF_AttReadGri=
dCompUTest.F90
PASS: mvapich2/O: src/Superstructure/AttributeAPI/tests/ESMF_AttributeA=
BundleUTest.F90
PASS: mvapich2/O: src/Superstructure/AttributeAPI/tests/ESMF_AttributeA=
rrayUTest.F90
PASS: mvapich2/O: src/Superstructure/AttributeAPI/tests/ESMF_AttributeA=
utoLinkUTest.F90
PASS: mvapich2/O: src/Superstructure/AttributeAPI/tests/ESMF_AttributeC=
plCompUTest.F90
PASS: mvapich2/O: src/Superstructure/AttributeAPI/tests/ESMF_AttributeD=
istGridUTest.F90
PASS: mvapich2/O: src/Superstructure/AttributeAPI/tests/ESMF_AttributeF=
BundleUTest.F90
PASS: mvapich2/O: src/Superstructure/AttributeAPI/tests/ESMF_AttributeF=
ieldUTest.F90
PASS: mvapich2/O: src/Superstructure/AttributeAPI/tests/ESMF_AttributeG=
ridCompUTest.F90
PASS: mvapich2/O: src/Superstructure/AttributeAPI/tests/ESMF_AttributeG=
ridUTest.F90
PASS: mvapich2/O: src/Superstructure/AttributeAPI/tests/ESMF_AttributeJ=
SONUTest.F90
PASS: mvapich2/O: src/Superstructure/AttributeAPI/tests/ESMF_AttributeL=
ocStreamUTest.F90
PASS: mvapich2/O: src/Superstructure/AttributeAPI/tests/ESMF_AttributeS=
ciCompUTest.F90
PASS: mvapich2/O: src/Superstructure/AttributeAPI/tests/ESMF_AttributeS=
tateUTest.F90
PASS: mvapich2/O: src/Superstructure/AttributeAPI/tests/ESMF_AttributeU=
pdateCIMRespPartyUTest.F90
PASS: mvapich2/O: src/Superstructure/AttributeAPI/tests/ESMF_AttributeU=
pdateClosedLoopTreesUTest.F90
PASS: mvapich2/O: src/Superstructure/AttributeAPI/tests/ESMF_AttributeU=
pdateComponentUTest.F90
PASS: mvapich2/O: src/Superstructure/AttributeAPI/tests/ESMF_AttributeU=
pdateContainerStressUTest.F90
PASS: mvapich2/O: src/Superstructure/AttributeAPI/tests/ESMF_AttributeU=
pdateMultiReconcileUTest.F90
PASS: mvapich2/O: src/Superstructure/AttributeAPI/tests/ESMF_AttributeU=
pdateReconcileUTest.F90
PASS: mvapich2/O: src/Superstructure/AttributeAPI/tests/ESMF_AttributeU=
pdateRemoveOnlyUTest.F90
PASS: mvapich2/O: src/Superstructure/AttributeAPI/tests/ESMF_AttributeU=
pdateUTest.F90
PASS: mvapich2/O: src/Superstructure/AttributeAPI/tests/ESMF_AttributeW=
riteInternalUTest.F90
PASS: mvapich2/O: src/Superstructure/AttributeAPI/tests/ESMF_AttributeX=
MLUTest.F90
PASS: mvapich2/O: src/Superstructure/Component/tests/ESMC_ComponentUTes=
t.C
PASS: mvapich2/O: src/Superstructure/Component/tests/ESMF_CompSetServUT=
est.F90
PASS: mvapich2/O: src/Superstructure/Component/tests/ESMF_CompTunnelUTe=
st.F90
PASS: mvapich2/O: src/Superstructure/Component/tests/ESMF_ComponentUTes=
t.F90
PASS: mvapich2/O: src/Superstructure/Component/tests/ESMF_CplCompCreate=
UTest.F90
PASS: mvapich2/O: src/Superstructure/Component/tests/ESMF_GridCompCreat=
eUTest.F90
PASS: mvapich2/O: src/Superstructure/Component/tests/ESMF_SciCompCreate=
UTest.F90
PASS: mvapich2/O: src/Superstructure/Component/tests/ESMF_StdCompMethod=
sUTest.F90
PASS: mvapich2/O: src/Superstructure/ESMFMod/tests/ESMF_FrameworkUTest.=
F90
PASS: mvapich2/O: src/Superstructure/IOAPI/tests/ESMF_IOCompUTest.F90
PASS: mvapich2/O: src/Superstructure/PreESMFMod/tests/ESMF_FileRegridUT=
est.F90
PASS: mvapich2/O: src/Superstructure/PreESMFMod/tests/ESMF_RegridWeight=
GenUTest.F90
PASS: mvapich2/O: src/Superstructure/State/tests/ESMC_StateUTest.C
PASS: mvapich2/O: src/Superstructure/State/tests/ESMF_StateCreateUTest.=
F90
PASS: mvapich2/O: src/Superstructure/State/tests/ESMF_StateReadWriteUTe=
st.F90
PASS: mvapich2/O: src/Superstructure/State/tests/ESMF_StateReconcileUTe=
st.F90
PASS: mvapich2/O: src/Superstructure/State/tests/ESMF_StateUTest.F90
PASS: mvapich2/O: src/addon/NUOPC/tests/ESMF_NUOPC_UTest.F90
PASS: mvapich2/O: src/epilogue/tests/ESMCI_TestUTest.C
PASS: mvapich2/O: src/epilogue/tests/ESMC_TestUTest.C
PASS: mvapich2/O: src/epilogue/tests/ESMF_TestUTest.F90
PASS: mvapich2/O: src/prologue/tests/ESMCI_ExceptionsUTest.C
PASS: mvapich2/O: src/prologue/tests/ESMCI_FeatureUTest.C
PASS: mvapich2/O: src/prologue/tests/ESMF_F90ArrayPtrUTest.F90
PASS: mvapich2/O: src/prologue/tests/ESMF_FeatureUTest.F90
PASS: mvapich2/O: src/prologue/tests/ESMF_LAPACKUTest.F90
PASS: mvapich2/O: src/prologue/tests/ESMF_StringUTest.F90
PASS: mvapich2/O: src/prologue/tests/ESMF_WordsizeUTest.F90


The following test harness unit tests pass:
PASS: mvapich2/O: ESMF_array_default_NP4UTest
PASS: mvapich2/O: ESMF_field_default_NP4UTest


The log and stdout files for the unit tests can be found at:
/lcrc/project/ESMF/scripts_dirs/daily_builds/intel_bebop/esmf/test/test=
O/Linux.intel.64.mvapich2.default


Found 9075 exhaustive multi-processor unit tests, 9075 passed and 0 fai=
led.



_______________________________________________________________________=
________________________


Mon Mar 16 09:28:12 CDT 2020 on beboplogin2=20

ESMF Checkout Source: https://github.com/esmf-org/esmf

Compiler and configuration information:
=20
--------------------------------------------------------------=20

Currently Loaded Modules:
  1) intel/17.0.3-gbgtimn
  2) mpich/3.2-5koqqym

=20

=20
Repository:
origin=09https://github.com/esmf-org/esmf (fetch)
origin=09https://github.com/esmf-org/esmf (push)
=20
ESMF_8_1_0_beta_snapshot_11
=20
=20
=20
--------------------------------------------------------------
ESMF_VERSION_STRING:    8.1.0 beta snapshot
ESMF_8_1_0_beta_snapshot_11
--------------------------------------------------------------
# On branch master
# Untracked files:
#   (use "git add <file>..." to include in what will be committed)
#
#=09queue_results
#=09src/installcheck/esmc_application
#=09src/installcheck/esmc_application.o
#=09src/installcheck/esmf_application
#=09src/installcheck/esmf_application.o
#=09tmp
nothing added to commit but untracked files present (use "git add" to t=
rack)
--------------------------------------------------------------
=20
--------------------------------------------------------------
Make version:
GNU Make 3.82
Built for x86_64-redhat-linux-gnu
Copyright (C) 2010  Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl=
.html>
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.

--------------------------------------------------------------
Fortran Compiler version:
mpifort for MPICH version 3.2
Intel(R) Fortran Intel(R) 64 Compiler for applications running on Intel=
(R) 64, Version 17.0.3.191 Build 20170404
Copyright (C) 1985-2017 Intel Corporation.  All rights reserved.

ifort version 17.0.3

--------------------------------------------------------------
C++ Compiler version:
mpicxx for MPICH version 3.2
Intel(R) C++ Intel(R) 64 Compiler for applications running on Intel(R) =
64, Version 17.0.3.191 Build 20170404
Copyright (C) 1985-2017 Intel Corporation.  All rights reserved.

icpc version 17.0.3 (gcc version 4.8.5 compatibility)

--------------------------------------------------------------
Preprocessor version:
gcc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-36)
Copyright (C) 2015 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is=
 NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURP=
OSE.

=20
--------------------------------------------------------------
 * User set ESMF environment variables *
ESMF_ABI=3D64
ESMF_BOPT=3Dg
ESMF_COMM=3Dmpich3
ESMF_COMPILER=3Dintel
ESMF_DIR=3D/lcrc/project/ESMF/scripts_dirs/daily_builds/intel_bebop/esm=
f
ESMF_INSTALL_PREFIX=3D/lcrc/project/ESMF/scripts_dirs/daily_builds/inte=
l_bebop/esmf/../install_dir
ESMF_MPIRUN=3D/lcrc/project/ESMF/scripts_dirs/daily_builds/intel_bebop/=
esmf/scripts/mpirun.srun
ESMF_OS=3DLinux
ESMF_PROJ4=3Dexternal
ESMF_PROJ4_INCLUDE=3D/home/svasquez/proj4/include
ESMF_PROJ4_LIBPATH=3D/home/svasquez/proj4/lib
ESMF_SITE=3Ddefault
ESMF_TESTCOMPTUNNEL=3DOFF
ESMF_TESTEXHAUSTIVE=3DON
ESMF_TESTHARNESS_ARRAY=3DRUN_ESMF_TestHarnessArray_default
ESMF_TESTHARNESS_FIELD=3DRUN_ESMF_TestHarnessField_default
ESMF_TESTMPMD=3DOFF
ESMF_TESTWITHTHREADS=3DOFF
=20
--------------------------------------------------------------
 * ESMF environment variables *
ESMF_DIR: /lcrc/project/ESMF/scripts_dirs/daily_builds/intel_bebop/esmf
ESMF_OS:                Linux
ESMF_MACHINE:           x86_64
ESMF_ABI:               64
ESMF_COMPILER:          intel
ESMF_BOPT:              g
ESMF_COMM:              mpich3
ESMF_SITE:              default
ESMF_PTHREADS:          ON
ESMF_OPENMP:            ON
ESMF_OPENACC:           OFF
ESMF_CXXSTD:            11
ESMF_ARRAY_LITE:        FALSE
ESMF_NO_INTEGER_1_BYTE: TRUE
ESMF_NO_INTEGER_2_BYTE: TRUE
ESMF_FORTRANSYMBOLS:    default
ESMF_MAPPER_BUILD:      OFF
ESMF_AUTO_LIB_BUILD:    ON
ESMF_DEFER_LIB_BUILD:   ON
ESMF_SHARED_LIB_BUILD:  ON
ESMF_TRACE_LIB_BUILD:   ON
ESMF_TESTEXHAUSTIVE:    ON
ESMF_TESTCOMPTUNNEL:    OFF
ESMF_TESTWITHTHREADS:   OFF
ESMF_TESTMPMD:          OFF
ESMF_TESTSHAREDOBJ:     OFF
ESMF_TESTFORCEOPENMP:   OFF
ESMF_TESTFORCEOPENACC:  OFF
ESMF_TESTHARNESS_ARRAY: RUN_ESMF_TestHarnessArray_default
ESMF_TESTHARNESS_FIELD: RUN_ESMF_TestHarnessField_default
ESMF_MPIRUN:            /lcrc/project/ESMF/scripts_dirs/daily_builds/in=
tel_bebop/esmf/scripts/mpirun.srun
=20
--------------------------------------------------------------
 * ESMF environment variables pointing to 3rd party software *
ESMF_MOAB:               internal
ESMF_LAPACK:             internal
ESMF_ACC_SOFTWARE_STACK: none
ESMF_YAMLCPP:            internal
ESMF_PIO:                internal
ESMF_PROJ4:                external
ESMF_PROJ4_INCLUDE:        /home/svasquez/proj4/include
ESMF_PROJ4_LIBS:           -lproj
ESMF_PROJ4_LIBPATH:        /home/svasquez/proj4/lib
=20
--------------------------------------------------------------
 * ESMF environment variables for final installation *
ESMF_INSTALL_PREFIX:    /lcrc/project/ESMF/scripts_dirs/daily_builds/in=
tel_bebop/esmf/../install_dir
ESMF_INSTALL_HEADERDIR: include
ESMF_INSTALL_MODDIR:    mod/modg/Linux.intel.64.mpich3.default
ESMF_INSTALL_LIBDIR:    lib/libg/Linux.intel.64.mpich3.default
ESMF_INSTALL_BINDIR:    bin/bing/Linux.intel.64.mpich3.default
ESMF_INSTALL_DOCDIR:    doc
=20
--------------------------------------------------------------
 * ESMF Benchmark directory and parameters *
ESMF_BENCHMARK_PREFIX:         ./DEFAULTBENCHMARKDIR
ESMF_BENCHMARK_TOLERANCE:      20%
ESMF_BENCHMARK_THRESHOLD_MSEC: 500
=20
--------------------------------------------------------------
 * Other relevant environment variables *
PATH:    /blues/gpfs/home/software/spack-0.10.1/opt/spack/linux-centos7=
-x86_64/intel-17.0.3/mpich-3.2-5koqqymkjuonxuxqcp6353jxy4jabaqg/bin:/bl=
ues/gpfs/home/software/spack-0.10.1/opt/spack/linux-centos7-x86_64/gcc-=
4.8.5/intel-17.0.3-gbgtimncxmczihdqphudp4l3gye5fqmq/bin:/home/svasquez/=
bin:/usr/bin:/bin:/usr/local/sbin:/usr/sbin:/soft/lcrc/bebop/bin:/soft/=
lcrc/bebop/bin:/soft/lcrc/bebop/bin
LD_LIBRARY_PATH: /blues/gpfs/home/software/spack-0.10.1/opt/spack/linux=
-centos7-x86_64/intel-17.0.3/mpich-3.2-5koqqymkjuonxuxqcp6353jxy4jabaqg=
/lib:/blues/gpfs/home/software/spack-0.10.1/opt/spack/linux-centos7-x86=
_64/gcc-4.8.5/intel-17.0.3-gbgtimncxmczihdqphudp4l3gye5fqmq/tbb/lib/int=
el64/gcc4.4:/blues/gpfs/home/software/spack-0.10.1/opt/spack/linux-cent=
os7-x86_64/gcc-4.8.5/intel-17.0.3-gbgtimncxmczihdqphudp4l3gye5fqmq/lib/=
intel64
=20
--------------------------------------------------------------
 * Compilers, Linkers, Flags, and Libraries *
Location of the preprocessor:      /usr/bin/gcc
Location of the Fortran compiler:  /blues/gpfs/home/software/spack-0.10=
.1/opt/spack/linux-centos7-x86_64/intel-17.0.3/mpich-3.2-5koqqymkjuonxu=
xqcp6353jxy4jabaqg/bin/mpif90
Location of the Fortran linker:    /blues/gpfs/home/software/spack-0.10=
.1/opt/spack/linux-centos7-x86_64/intel-17.0.3/mpich-3.2-5koqqymkjuonxu=
xqcp6353jxy4jabaqg/bin/mpif90
Location of the C++ compiler:      /blues/gpfs/home/software/spack-0.10=
.1/opt/spack/linux-centos7-x86_64/intel-17.0.3/mpich-3.2-5koqqymkjuonxu=
xqcp6353jxy4jabaqg/bin/mpicxx
Location of the C++ linker:        /blues/gpfs/home/software/spack-0.10=
.1/opt/spack/linux-centos7-x86_64/intel-17.0.3/mpich-3.2-5koqqymkjuonxu=
xqcp6353jxy4jabaqg/bin/mpicxx

Fortran compiler flags:
ESMF_F90COMPILER: mpif90
ESMF_F90COMPILEOPTS: -g -traceback -check arg_temp_created,bounds,forma=
t,output_conversion,stack,uninit -fPIC -assume realloc_lhs -m64 -mcmode=
l=3Dsmall -threads  -qopenmp
ESMF_F90COMPILEPATHS: -I/lcrc/project/ESMF/scripts_dirs/daily_builds/in=
tel_bebop/esmf/mod/modg/Linux.intel.64.mpich3.default -I/lcrc/project/E=
SMF/scripts_dirs/daily_builds/intel_bebop/esmf/src/include -I/home/svas=
quez/proj4/include
ESMF_F90COMPILECPPFLAGS: -DESMF_NO_INTEGER_1_BYTE -DESMF_NO_INTEGER_2_B=
YTE -DESMFVERSIONGIT=3D'ESMF_8_1_0_beta_snapshot_11' -DESMF_MOAB=3D1 -D=
ESMF_LAPACK=3D1 -DESMF_LAPACK_INTERNAL=3D1 -DESMF_NO_ACC_SOFTWARE_STACK=
=3D1 -DESMF_YAMLCPP=3D1 -DESMF_YAML=3D1 -DESMF_PIO=3D1 -DESMF_MPIIO -DE=
SMF_PROJ4=3D1 -DESMF_NO_OPENACC -DESMF_TESTEXHAUSTIVE -DESMF_BOPT_g -DS=
x86_64_small=3D1 -DESMF_OS_Linux=3D1 -DESMF_COMM=3Dmpich3 -DESMF_DIR=3D=
/lcrc/project/ESMF/scripts_dirs/daily_builds/intel_bebop/esmf
ESMF_F90COMPILEFREECPP:=20
ESMF_F90COMPILEFREENOCPP:=20
ESMF_F90COMPILEFIXCPP:=20
ESMF_F90COMPILEFIXNOCPP:=20

Fortran linker flags:
ESMF_F90LINKOPTS:   -m64 -mcmodel=3Dsmall -threads -Wl,--no-as-needed  =
-qopenmp
ESMF_F90LINKPATHS: -L/lcrc/project/ESMF/scripts_dirs/daily_builds/intel=
_bebop/esmf/lib/libg/Linux.intel.64.mpich3.default -L/home/svasquez/pro=
j4/lib=20
ESMF_F90LINKRPATHS: -Wl,-rpath,/lcrc/project/ESMF/scripts_dirs/daily_bu=
ilds/intel_bebop/esmf/lib/libg/Linux.intel.64.mpich3.default  -Wl,-rpat=
h,/home/svasquez/proj4/lib
ESMF_F90LINKLIBS:  -cxxlib -lrt -ldl -lproj
ESMF_F90ESMFLINKLIBS: -lesmf  -cxxlib -lrt -ldl -lproj

C++ compiler flags:
ESMF_CXXCOMPILER: mpicxx
ESMF_CXXCOMPILEOPTS: -std=3Dc++11 -g -traceback -Wcheck -fPIC -m64 -mcm=
odel=3Dsmall -pthread  -qopenmp
ESMF_CXXCOMPILEPATHS:  -I/lcrc/project/ESMF/scripts_dirs/daily_builds/i=
ntel_bebop/esmf/src/include  -I/home/svasquez/proj4/include -I/lcrc/pro=
ject/ESMF/scripts_dirs/daily_builds/intel_bebop/esmf/src/prologue/yaml-=
cpp/include
ESMF_CXXCOMPILECPPFLAGS: -DESMF_NO_INTEGER_1_BYTE -DESMF_NO_INTEGER_2_B=
YTE -DESMFVERSIONGIT=3D'ESMF_8_1_0_beta_snapshot_11' -DESMF_MOAB=3D1 -D=
ESMF_LAPACK=3D1 -DESMF_LAPACK_INTERNAL=3D1 -DESMF_NO_ACC_SOFTWARE_STACK=
=3D1 -DESMF_YAMLCPP=3D1 -DESMF_YAML=3D1 -DESMF_PIO=3D1 -DESMF_MPIIO -DE=
SMF_PROJ4=3D1 -DESMF_NO_OPENACC -DESMF_TESTEXHAUSTIVE -DESMF_BOPT_g -DS=
x86_64_small=3D1 -DESMF_OS_Linux=3D1 -DESMF_COMM=3Dmpich3 -DESMF_DIR=3D=
/lcrc/project/ESMF/scripts_dirs/daily_builds/intel_bebop/esmf -D__SDIR_=
_=3D'' -DESMF_CXXSTD=3D11

C++ linker flags:
ESMF_CXXLINKOPTS:   -m64 -mcmodel=3Dsmall -pthread -Wl,--no-as-needed  =
-qopenmp
ESMF_CXXLINKPATHS: -L/lcrc/project/ESMF/scripts_dirs/daily_builds/intel=
_bebop/esmf/lib/libg/Linux.intel.64.mpich3.default -L/home/svasquez/pro=
j4/lib -L/blues/gpfs/home/software/spack-0.10.1/opt/spack/linux-centos7=
-x86_64/gcc-4.8.5/intel-17.0.3-gbgtimncxmczihdqphudp4l3gye5fqmq/compile=
rs_and_libraries_2017.3.191/linux/compiler/lib/intel64_lin/
ESMF_CXXLINKRPATHS: -Wl,-rpath,/lcrc/project/ESMF/scripts_dirs/daily_bu=
ilds/intel_bebop/esmf/lib/libg/Linux.intel.64.mpich3.default  -Wl,-rpat=
h,/home/svasquez/proj4/lib -Wl,-rpath,/blues/gpfs/home/software/spack-0=
.10.1/opt/spack/linux-centos7-x86_64/gcc-4.8.5/intel-17.0.3-gbgtimncxmc=
zihdqphudp4l3gye5fqmq/compilers_and_libraries_2017.3.191/linux/compiler=
/lib/intel64_lin/
ESMF_CXXLINKLIBS:  -lmpifort -lifport -lifcoremt -limf -lsvml -lm -lipg=
o -liomp5 -lintlc -lpthread -lsvml -ldl -lgcc -lgcc_s -lirc_s -ldl -lrt=
 -ldl -lproj
ESMF_CXXESMFLINKLIBS: -lesmf  -lmpifort -lifport -lifcoremt -limf -lsvm=
l -lm -lipgo -liomp5 -lintlc -lpthread -lsvml -ldl -lgcc -lgcc_s -lirc_=
s -ldl -lrt -ldl -lproj

Shared library build:
ESMF_SL_LIBS_TO_MAKE: libesmf
ESMF_SL_SUFFIX:       so
ESMF_SL_LIBLINKER:    mpicxx
ESMF_SL_LIBOPTS:       -pthread -shared  -qopenmp
ESMF_SL_LIBLIBS:     =20

ESMF Tracing linker options:
ESMF_TRACE_LDPRELOAD=3D/lcrc/project/ESMF/scripts_dirs/daily_builds/int=
el_bebop/esmf/lib/libg/Linux.intel.64.mpich3.default/libesmftrace_prelo=
ad.so
ESMF_TRACE_STATICLINKOPTS=3D-static -Wl,--wrap=3Dc_esmftrace_notify_wra=
ppers -Wl,--wrap=3Dc_esmftrace_isinitialized -Wl,--wrap=3Dwrite -Wl,--w=
rap=3Dwritev -Wl,--wrap=3Dpwrite -Wl,--wrap=3Dread -Wl,--wrap=3Dopen -W=
l,--wrap=3DMPI_Allgather -Wl,--wrap=3DMPI_Allgatherv -Wl,--wrap=3DMPI_A=
llreduce -Wl,--wrap=3DMPI_Alltoall -Wl,--wrap=3DMPI_Alltoallv -Wl,--wra=
p=3DMPI_Alltoallw -Wl,--wrap=3DMPI_Barrier -Wl,--wrap=3DMPI_Bcast -Wl,-=
-wrap=3DMPI_Gather -Wl,--wrap=3DMPI_Gatherv -Wl,--wrap=3DMPI_Recv -Wl,-=
-wrap=3DMPI_Reduce -Wl,--wrap=3DMPI_Scatter -Wl,--wrap=3DMPI_Send -Wl,-=
-wrap=3DMPI_Sendrecv -Wl,--wrap=3DMPI_Wait -Wl,--wrap=3DMPI_Waitall -Wl=
,--wrap=3DMPI_Waitany -Wl,--wrap=3DMPI_Waitsome -Wl,--wrap=3Dmpi_allgat=
her_ -Wl,--wrap=3Dmpi_allgather__ -Wl,--wrap=3Dmpi_allgatherv_ -Wl,--wr=
ap=3Dmpi_allgatherv__ -Wl,--wrap=3Dmpi_allreduce_ -Wl,--wrap=3Dmpi_allr=
educe__ -Wl,--wrap=3Dmpi_alltoall_ -Wl,--wrap=3Dmpi_alltoall__ -Wl,--wr=
ap=3Dmpi_alltoallv_ -Wl,--wrap=3Dmpi_alltoallv__ -Wl,--wrap=3Dmpi_allto=
allw_ -Wl,--wrap=3Dmpi_alltoallw__ -Wl,--wrap=3Dmpi_barrier_ -Wl,--wrap=
=3Dmpi_barrier__ -Wl,--wrap=3Dmpi_bcast_ -Wl,--wrap=3Dmpi_bcast__ -Wl,-=
-wrap=3Dmpi_exscan_ -Wl,--wrap=3Dmpi_exscan__ -Wl,--wrap=3Dmpi_gather_ =
-Wl,--wrap=3Dmpi_gather__ -Wl,--wrap=3Dmpi_gatherv_ -Wl,--wrap=3Dmpi_ga=
therv__ -Wl,--wrap=3Dmpi_recv_ -Wl,--wrap=3Dmpi_recv__ -Wl,--wrap=3Dmpi=
_reduce_ -Wl,--wrap=3Dmpi_reduce__ -Wl,--wrap=3Dmpi_reduce_scatter_ -Wl=
,--wrap=3Dmpi_reduce_scatter__ -Wl,--wrap=3Dmpi_scatter_ -Wl,--wrap=3Dm=
pi_scatter__ -Wl,--wrap=3Dmpi_scatterv_ -Wl,--wrap=3Dmpi_scatterv__ -Wl=
,--wrap=3Dmpi_scan_ -Wl,--wrap=3Dmpi_scan__ -Wl,--wrap=3Dmpi_send_ -Wl,=
--wrap=3Dmpi_send__ -Wl,--wrap=3Dmpi_wait_ -Wl,--wrap=3Dmpi_wait__ -Wl,=
--wrap=3Dmpi_waitall_ -Wl,--wrap=3Dmpi_waitall__ -Wl,--wrap=3Dmpi_waita=
ny_ -Wl,--wrap=3Dmpi_waitany__
ESMF_TRACE_STATICLINKLIBS=3D-lesmftrace_static


--------------------------------------------------------------
Compiling on Mon Mar 16 09:28:34 CDT 2020 on beboplogin2
Machine characteristics: Linux beboplogin2 3.10.0-957.21.3.el7.x86_64 #=
1 SMP Tue Jun 18 16:35:19 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
=20
Mon Mar 16 09:57:30 CDT 2020 library build -j16 ...........PASS
Mon Mar 16 09:58:43 CDT 2020 library install -j4 ..........PASS
Mon Mar 16 09:58:48 CDT 2020 library installcheck -j4 .....PASS
Mon Mar 16 10:04:23 CDT 2020 quickstart build -j4 .........PASS

|------------------------ APPs TESTS --------------------------|
Mon Mar 16 10:04:58 CDT 2020 apps build -j4 ...............PASS

|--------------------------------------------------------------|
Mon Mar 16 10:05:32 CDT 2020 ESMF_Regrid --help ...........PASS
The following is the output of ESMF_Regrid --help

 Usage: ESMF_Regrid
                       --source|-s src_grid_filename
                       --destination|-d dst_grid_filename
                       --src_var varname1[,varname2,...]
                       --dst_var  varname1[,varname2,...]
                       [--srcdatafile]
                       [--dstdatafile]
                       [--tilefile_path tile_file_path]
                       [--dst_loc center|corner]
                       [--method|-m bilinear|patch|neareststod|nearestd=
tos|conse
 rve|conserve2nd]
                       [--pole|-p all|none|teeth|<N>]
                       [--ignore_unmapped|-i]
                       [--ignore_degenerate]
                       [-r]
                       [--src_regional]
                       [--dst_regional]
                       [--check]
                       [--no_log]
                       [--help]
                       [--version]
                       [-V]
 where
 --source or -s - a required argument specifying the source grid file
               name
 --destination or -d - a required argument specifying the destination g=
rid
               file name
 --src_var  - a required argument specifying the variable names to be r=
egridded
               in the source grid file.  If more than one, separated th=
em with
               comma.
 --dst_var  - a required argument specifying the destination variable n=
ame in
               the destination grid file.  If more than one, separated =
them with
               comma.  The number of dst_vars has to be the same as the=
 number
               of src_var
 --srcdatafile - If the source grid is of type MOSAIC, the data is stor=
ed=20
               in separated files, one per tile. srcdatafile is the pre=
fix of
               the source data file.  The filename is srcdatafile.tilen=
ame.nc,
               where tilename is the tile name defined in the source gr=
id file
 --dstdatafile - If the destination grid is of type MOSAIC, the data is=
 stored
               in separated files, one per tile. dstdatafile is the pre=
fix of
               the destination data file.  The filename is srcdatafile.=
tilename.
 nc,
                where tilename is the tile name defined in the destinat=
ion grid=20
 file
 --tilefile_path - The alternative file path for the tile files and mos=
aic data=20
 files
               when either srcFile or dstFile is a GRIDSPEC MOSAIC grid=
.  The pa
 th
               can be either relative or absolute.  If it is relative, =
it is
               relative to the working directory.  When specified, the =
gridlocat
 ion
               variable defined in the Mosaic file will be ignored.
 --method or -m - an optional argument specifying which interpolation m=
ethod is
               used.  The default method is bilinear
 --pole or -p - an optional argument indicating what to do with the pol=
e.
               The default value is all
 --ignore_unmapped or -i - ignore unmapped destination points. If not s=
pecified,
               the default is to stop with an error.
 --ignore_degenerate - ignore degenerate cells in the input grids. If n=
ot specif
 ied,
               the default is to stop with an error.
 -r          - an optional argument specifying the source and destinati=
on grids
               are regional grids.  Without this argument, the grids ar=
e assumed
               to be global. This argument only applies to the GRIDSPEC=
 file
 --src_regional   - an optional argument specifying the source grid is =
regional.
               Without this argument, the src grids is assumed to be gl=
obal. Thi
 s=20
               argument only applies to the GRIDSPEC file
 --dst_regional   - an optional argument specifying the destination gri=
d is regi
 onal
               Without this argument, the dst grids is assumed to be gl=
obal.
               This argument only applies to the GRIDSPEC file
 --check    - Check the regridded fields by comparing the values with
              a synthetic field calculated based on its coordinates.=20
              The mean relative error between the destination field=20
              and synthetic field is computed.  The synthetic value is =
calculate
 d as=20
              data(i,j,k,l)=3D2.0+(k-1)+2*(l-1)+cos(lat(i,j))**2*cos(2*=
lon(i,j)),=20
 assuming
              it is a 2D grid=20
 --no_log    - Turn off the ESMF error log.
 --help     - Print this help message and exit.
 --version  - Print ESMF version and license information and exit.
 -V        - Print ESMF version number and exit.
=20
 For questions, comments, or feature requests please send email to:
 esmf_support@cgd.ucar.edu
=20
 Visit http://www.earthsystemmodeling.org/ to find out more about the
 Earth System Modeling Framework.
=20



|--------------------------------------------------------------|
Mon Mar 16 10:05:33 CDT 2020 ESMF_Regrid --version ........PASS
The following is the output of ESMF_Regrid --version

   ESMF_VERSION_STRING:       8.1.0 beta snapshot
   ESMF_VERSION_MAJOR:                   8
   ESMF_VERSION_MINOR:                   1
   ESMF_VERSION_REVISION:                0
   ESMF_VERSION_PATCHLEVEL:              0
   ESMF_VERSION_PUBLIC:        F
   ESMF_VERSION_BETASNAPSHOT:  T
=20
 Earth System Modeling Framework
=20
 Copyright (c) 2002-2020 University Corporation for Atmospheric Researc=
h,
 Massachusetts Institute of Technology, Geophysical Fluid Dynamics Labo=
ratory,
 University of Michigan, National Centers for Environmental Prediction,
 Los Alamos National Laboratory, Argonne National Laboratory,
 NASA Goddard Space Flight Center.
 All rights reserved.
=20
 Permission is hereby granted, free of charge, to any person obtaining =
a copy
 of this software and associated documentation files (the 'Software'), =
to
 deal with the Software without restriction, including without limitati=
on the
 rights to use, copy, modify, merge, publish, distribute, sublicense, a=
nd/or
 sell copies of the Software, and to permit persons to whom the Softwar=
e is
 furnished to do so, subject to the following conditions:
    1. Redistributions of source code must retain the above copyright n=
otice,
       this list of conditions and the following disclaimers.
    2. Redistributions in binary form must reproduce the above copyrigh=
t
       notice, this list of conditions and the following disclaimers in=
 the
       documentation and/or other materials provided with the distribut=
ion.
    3. Neither the names of the organizations developing this software,=
 nor
       the names of its contributors may be used to endorse or promote =
products
       derived from this Software without specific prior written permis=
sion.
=20
 THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRES=
S OR
 IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILIT=
Y,
 FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHAL=
L THE
 CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR =
OTHER
 LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISIN=
G
 FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DE=
ALINGS
 WITH THE SOFTWARE.



|--------------------------------------------------------------|
Mon Mar 16 10:05:34 CDT 2020 ESMF_Regrid -V ...............PASS
The following is the output of ESMF_Regrid -V

   ESMF_VERSION_STRING:       8.1.0 beta snapshot



|--------------------------------------------------------------|
Mon Mar 16 10:05:34 CDT 2020 ESMF_Info --help .............PASS
The following is the output of ESMF_Info --help=20

 ESMF_Info: Print information about the ESMF installation.
 Options:
   --help        Display this information and exit.
   --version     Display ESMF version and license information and exit.
   -V            Display ESMF version string and exit.
=20



|--------------------------------------------------------------|
Mon Mar 16 10:05:35 CDT 2020 ESMF_Info --version ..........PASS
The following is the output of ESMF_Info --version=20

   ESMF_VERSION_STRING:       8.1.0 beta snapshot
   ESMF_VERSION_MAJOR:                   8
   ESMF_VERSION_MINOR:                   1
   ESMF_VERSION_REVISION:                0
   ESMF_VERSION_PATCHLEVEL:              0
   ESMF_VERSION_PUBLIC:        F
   ESMF_VERSION_BETASNAPSHOT:  T
=20
 Earth System Modeling Framework
=20
 Copyright (c) 2002-2020 University Corporation for Atmospheric Researc=
h,
 Massachusetts Institute of Technology, Geophysical Fluid Dynamics Labo=
ratory,
 University of Michigan, National Centers for Environmental Prediction,
 Los Alamos National Laboratory, Argonne National Laboratory,
 NASA Goddard Space Flight Center.
 All rights reserved.
=20
 Permission is hereby granted, free of charge, to any person obtaining =
a copy
 of this software and associated documentation files (the 'Software'), =
to
 deal with the Software without restriction, including without limitati=
on the
 rights to use, copy, modify, merge, publish, distribute, sublicense, a=
nd/or
 sell copies of the Software, and to permit persons to whom the Softwar=
e is
 furnished to do so, subject to the following conditions:
    1. Redistributions of source code must retain the above copyright n=
otice,
       this list of conditions and the following disclaimers.
    2. Redistributions in binary form must reproduce the above copyrigh=
t
       notice, this list of conditions and the following disclaimers in=
 the
       documentation and/or other materials provided with the distribut=
ion.
    3. Neither the names of the organizations developing this software,=
 nor
       the names of its contributors may be used to endorse or promote =
products
       derived from this Software without specific prior written permis=
sion.
=20
 THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRES=
S OR
 IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILIT=
Y,
 FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHAL=
L THE
 CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR =
OTHER
 LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISIN=
G
 FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DE=
ALINGS
 WITH THE SOFTWARE.



|--------------------------------------------------------------|
Mon Mar 16 10:05:36 CDT 2020 ESMF_Info -V .................PASS
The following is the output of ESMF_Info -V=20

   ESMF_VERSION_STRING:       8.1.0 beta snapshot



|--------------------------------------------------------------|
Mon Mar 16 10:05:37 CDT 2020 ESMF_InfoC --help ............PASS
The following is the output of ESMF_InfoC --help

ESMF_InfoC: Print information about the ESMF installation.
Options:
  --help        Display this information and exit.
  --version     Display ESMF version and license information and exit.
  -V            Display ESMF version string and exit.




|--------------------------------------------------------------|
Mon Mar 16 10:05:37 CDT 2020 ESMF_InfoC --version .........PASS
The following is the output of ESMF_InfoC --version

   ESMF_VERSION_STRING:       8.1.0 beta snapshot
   ESMF_VERSION_MAJOR:                   8
   ESMF_VERSION_MINOR:                   1
   ESMF_VERSION_REVISION:                0
   ESMF_VERSION_PATCHLEVEL:              0
   ESMF_VERSION_PUBLIC:        F
   ESMF_VERSION_BETASNAPSHOT:  T
=20
 Earth System Modeling Framework
=20
 Copyright (c) 2002-2020 University Corporation for Atmospheric Researc=
h,
 Massachusetts Institute of Technology, Geophysical Fluid Dynamics Labo=
ratory,
 University of Michigan, National Centers for Environmental Prediction,
 Los Alamos National Laboratory, Argonne National Laboratory,
 NASA Goddard Space Flight Center.
 All rights reserved.
=20
 Permission is hereby granted, free of charge, to any person obtaining =
a copy
 of this software and associated documentation files (the 'Software'), =
to
 deal with the Software without restriction, including without limitati=
on the
 rights to use, copy, modify, merge, publish, distribute, sublicense, a=
nd/or
 sell copies of the Software, and to permit persons to whom the Softwar=
e is
 furnished to do so, subject to the following conditions:
    1. Redistributions of source code must retain the above copyright n=
otice,
       this list of conditions and the following disclaimers.
    2. Redistributions in binary form must reproduce the above copyrigh=
t
       notice, this list of conditions and the following disclaimers in=
 the
       documentation and/or other materials provided with the distribut=
ion.
    3. Neither the names of the organizations developing this software,=
 nor
       the names of its contributors may be used to endorse or promote =
products
       derived from this Software without specific prior written permis=
sion.
=20
 THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRES=
S OR
 IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILIT=
Y,
 FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHAL=
L THE
 CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR =
OTHER
 LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISIN=
G
 FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DE=
ALINGS
 WITH THE SOFTWARE.



|--------------------------------------------------------------|
Mon Mar 16 10:05:38 CDT 2020 ESMF_InfoC -V ................PASS
The following is the output of ESMF_InfoC -V

   ESMF_VERSION_STRING:       8.1.0 beta snapshot



|--------------------------------------------------------------|
Mon Mar 16 10:05:39 CDT 2020 ESMF_RegridWeightGen --help ..PASS
The following is the output of ESMF_RegridWeightGen --help

 Usage: ESMF_RegridWeightGen --source|-s src_grid_filename
                            --destination|-d dst_grid_filename
                       --weight|-w out_weight_file=20
                       [--method|-m bilinear|patch|neareststod|nearestd=
tos|conse
 rve|conserve2nd]
                       [--pole|-p all|none|teeth|<N>]
                       [--line_type|-l cartesian|greatcircle]
                       [--norm_type dstarea|fracarea]
                       [--extrap_method none|neareststod|nearestidavg|c=
reep]
                       [--extrap_num_src_pnts <N>]
                       [--extrap_dist_exponent <P>]
                       [--extrap_num_levels <L>]
                       [--ignore_unmapped|-i]
                       [--ignore_degenerate]
                       [-r]
                       [--src_regional]
                       [--dst_regional]
                       [--64bit_offset]
                       [--netcdf4]
                       [--weight_only]
                       [--src_missingvalue src_var_name]
                       [--dst_missingvalue dst_var_name]
                       [--src_coordinates lon_var_name,lat_var_name]
                       [--dst_coordinates lon_var_name,lat_var_name]
                       [--user_areas]
                       [--src_loc center|corner]
                       [--dst_loc center|corner]
                       [--tilefile_path tile_file_path]
                       [--no_log]
                       [--check]
                       [--help]
                       [--version]
                       [-V]
 where
 --source or -s - a required argument specifying the source grid file
                  name
 --destination or -d - a required argument specifying the destination g=
rid
                       file name
 --weight or -w - a required argument specifying the output regridding =
weight
                  file name
 --method or -m - an optional argument specifying which interpolation m=
ethod is
                  used.  The default method is bilinear.
 --pole or -p - an optional argument indicating what to do with the pol=
e.
                  The default value is all.
 --line_type or -l - an optional argument indicating the type of path
                      lines (e.g. cell edges) follow on a spherical
                     surface. The default value depends on the regrid
                     method. For non-conservative methods the default i=
s
                     cartesian. For conservative methods the default is=
 greatcir
 cle.
 --norm_type - an optional argument indicating the type of normalizatio=
n to
               do when generating conserative weights. The default valu=
e is dsta
 rea.
 --extrap_method - an optional argument specifying which extrapolation =
method is
                  used.  The default method is none.
 --extrap_num_src_pnts - an optional argument specifying how many sourc=
e points=20
 should
                 be used when the extrapolation method is nearestidavg.=
 The defa
 ult is 8.
 --extrap_dist_exponent - an optional argument specifying the exponent =
that the=20
 distance should
                 be raised to when the extrapolation method is nearesti=
davg. The
  default is 2.0.
 --extrap_num_levels - an optional argument specifying how many levels =
should
                 be filled for level based extrapolation methods (e.g. =
creep).
 --ignore_unmapped or -i - ignore unmapped destination points. If not s=
pecified,
                           the default is to stop with an error.
 --ignore_degenerate - ignore degenerate cells in the input grids. If n=
ot specif
 ied,
                           the default is to stop with an error.
 -r         - an optional argument specifying the source and destinatio=
n grids
              are regional grids.  Without this argument, the grids are=
 assumed
              to be global
 --src_regional   - an optional argument specifying the source grid is =
regional.
              Without this argument, the src grids is assumed to be glo=
bal.
 --dst_regional   - an optional argument specifying the destination gri=
d is regi
 onal
              Without this argument, the dst grids is assumed to be glo=
bal.
 --64bit_offset  - an optional argument specifying the output weight fi=
le is in
              NetCDF 64-bit offset format.  This option only works with=
 NetCDF l
 ibrary
              version 3.6 and above
 --netcdf4  - an optional argument specifying the output weight file is=
 in
              the NetCDF4 format. This option only works with NetCDF li=
brary
              version 4.1 and above
 --weight_only  - an Optional argument specifying the output weight fil=
e only co
 ntains
              the weights and the source and destination grid's indices=
.
 --src_missingvalue  - an optional argument used when the src file type=
 is GRIDS
 PEC
              or UGRID. It defines the variable name whose 'missing_val=
ue' or
              '_FillValue' attribute will be used to construct the mask=
 for the=20
 source
              grid. Without this argument,a GRIDSPEC file or a UGRID fi=
le is not
  masked.
 --dst_missingvalue  - an optional argument used when the destination f=
ile type=20
 is
              GRIDSPEC or UGRID. It defines the variable name whose 'mi=
ssing_val
 ue' or
              '_FillValue' attribute will be used to construct the mask=
 for the=20
 destination
              grid. Without this argument,a GRIDSPEC file or a UGRID fi=
le is not
  masked.
 --src_coordinates  - an optional argument used when the source grid ty=
pe is GRI
 DSPEC.
              It defines the longitude and latitude variable names sepa=
rated by=20
 comma,
              in case there are multiple coordinate variables defined i=
n the fil
 e
 --dst_coordinates  - an optional argument used when the destination gr=
id type i
 s GRIDSPEC.
              It defines the longitude and latitude variable names sepa=
rated by=20
 comma,
              in case there are multiple coordinate variables defined i=
n the fil
 e
 --user_areas  - an optional argument specifying that the conservation =
is adjust
 ed to
              hold for the user areas provided in the grid files.  If n=
ot specif
 ied,
              then the conservation will hold for the ESMF calculated (=
great cir
 cle)
              areas.  Whichever areas the conservation holds for are ou=
tput to t
 he
              weight file.
 --src_loc   - an optional argument specifying which location is used t=
o do the=20
 regridding
             The location can be either 'center' or 'corner'.  Currentl=
y, this a
 rgument
             is only required when the source grid file is an unstructu=
red grid=20
 defined
             in UGRID or ESMF format and the regridding method is non-c=
onservati
 ve. For =20
             all other cases, the default location is 'center'.
 --dst_loc   - an optional argument specifying which location is used t=
o do the=20
 regridding
             The location can be either 'center' or 'corner'.  Currentl=
y, this a
 rgument
             is 'center'.  Currently, this argument will only be used w=
hen the
             is only required when the destination grid file is an unst=
ructured=20
 grid defined
             in UGRID or ESMF format and the regridding method is non-c=
onservati
 ve. For =20
             all other cases, the default location is 'center'.
 --tilefile_path - the alternative file path for the tile files when th=
e grid fi
 le type is
             MOSAIC.
 --no_log    - Turn off the ESMF logs.
 --check    - Check that the generated weights produce reasonable regri=
dded fiel
 ds.  This
              is done by calling ESMF_FieldRegrid() on an analytic sour=
ce field=20
 using the weights
              generated by this application.  The mean relative error b=
etween th
 e destination
              and analytic field is computed, as well as the relative e=
rror betw
 een the mass
              of the source and destination fields in the conservative =
case.
 --help     - Print this help message and exit.
 --version  - Print ESMF version and license information and exit.
 -V        - Print ESMF version number and exit.
=20
 For questions, comments, or feature requests please send email to:
 esmf_support@cgd.ucar.edu
=20
 Visit http://www.earthsystemmodeling.org/ to find out more about the
 Earth System Modeling Framework.
=20



|--------------------------------------------------------------|
Mon Mar 16 10:05:39 CDT 2020 ESMF_RegridWeightGen --version PASS
The following is the output of ESMF_RegridWeightGen --version

   ESMF_VERSION_STRING:       8.1.0 beta snapshot
   ESMF_VERSION_MAJOR:                   8
   ESMF_VERSION_MINOR:                   1
   ESMF_VERSION_REVISION:                0
   ESMF_VERSION_PATCHLEVEL:              0
   ESMF_VERSION_PUBLIC:        F
   ESMF_VERSION_BETASNAPSHOT:  T
=20
 Earth System Modeling Framework
=20
 Copyright (c) 2002-2020 University Corporation for Atmospheric Researc=
h,
 Massachusetts Institute of Technology, Geophysical Fluid Dynamics Labo=
ratory,
 University of Michigan, National Centers for Environmental Prediction,
 Los Alamos National Laboratory, Argonne National Laboratory,
 NASA Goddard Space Flight Center.
 All rights reserved.
=20
 Permission is hereby granted, free of charge, to any person obtaining =
a copy
 of this software and associated documentation files (the 'Software'), =
to
 deal with the Software without restriction, including without limitati=
on the
 rights to use, copy, modify, merge, publish, distribute, sublicense, a=
nd/or
 sell copies of the Software, and to permit persons to whom the Softwar=
e is
 furnished to do so, subject to the following conditions:
    1. Redistributions of source code must retain the above copyright n=
otice,
       this list of conditions and the following disclaimers.
    2. Redistributions in binary form must reproduce the above copyrigh=
t
       notice, this list of conditions and the following disclaimers in=
 the
       documentation and/or other materials provided with the distribut=
ion.
    3. Neither the names of the organizations developing this software,=
 nor
       the names of its contributors may be used to endorse or promote =
products
       derived from this Software without specific prior written permis=
sion.
=20
 THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRES=
S OR
 IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILIT=
Y,
 FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHAL=
L THE
 CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR =
OTHER
 LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISIN=
G
 FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DE=
ALINGS
 WITH THE SOFTWARE.



|--------------------------------------------------------------|
Mon Mar 16 10:05:40 CDT 2020 ESMF_RegridWeightGen -V ......PASS
The following is the output of ESMF_RegridWeightGen -V

   ESMF_VERSION_STRING:       8.1.0 beta snapshot



|--------------------------------------------------------------|
Mon Mar 16 10:05:41 CDT 2020 ESMF_Scrip2Unstruct --help ...PASS
The following is the output of ESMF_Scrip2Unstruct --help

ESMF_Scrip2Unstruct: Convert an unstructured grid file in SCRIP format =
into either a ESMF unstructured file or a UGRID file format.
Usage: ESMF_Scrip2Unstruct [--help] [--version] [-V] inputfile outputfi=
le dualflag [fileformat]
    [--help]        Display this information and exit.
    [--version]     Display ESMF version and license information and ex=
it.
    [-V]            Display ESMF version string and exit.
    inputfile       input grid filename=20
    outputfile      output filename=20
    dualflag        1 to generate a dual mesh, 0 for non-dual mesh
    [fileformat]    Either ESMF or UGRID, the default is ESMF




|--------------------------------------------------------------|
Mon Mar 16 10:05:42 CDT 2020 ESMF_Scrip2Unstruct --version PASS
The following is the output of ESMF_Scrip2Unstruct --version

   ESMF_VERSION_STRING:       8.1.0 beta snapshot
   ESMF_VERSION_MAJOR:                   8
   ESMF_VERSION_MINOR:                   1
   ESMF_VERSION_REVISION:                0
   ESMF_VERSION_PATCHLEVEL:              0
   ESMF_VERSION_PUBLIC:        F
   ESMF_VERSION_BETASNAPSHOT:  T
=20
 Earth System Modeling Framework
=20
 Copyright (c) 2002-2020 University Corporation for Atmospheric Researc=
h,
 Massachusetts Institute of Technology, Geophysical Fluid Dynamics Labo=
ratory,
 University of Michigan, National Centers for Environmental Prediction,
 Los Alamos National Laboratory, Argonne National Laboratory,
 NASA Goddard Space Flight Center.
 All rights reserved.
=20
 Permission is hereby granted, free of charge, to any person obtaining =
a copy
 of this software and associated documentation files (the 'Software'), =
to
 deal with the Software without restriction, including without limitati=
on the
 rights to use, copy, modify, merge, publish, distribute, sublicense, a=
nd/or
 sell copies of the Software, and to permit persons to whom the Softwar=
e is
 furnished to do so, subject to the following conditions:
    1. Redistributions of source code must retain the above copyright n=
otice,
       this list of conditions and the following disclaimers.
    2. Redistributions in binary form must reproduce the above copyrigh=
t
       notice, this list of conditions and the following disclaimers in=
 the
       documentation and/or other materials provided with the distribut=
ion.
    3. Neither the names of the organizations developing this software,=
 nor
       the names of its contributors may be used to endorse or promote =
products
       derived from this Software without specific prior written permis=
sion.
=20
 THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRES=
S OR
 IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILIT=
Y,
 FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHAL=
L THE
 CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR =
OTHER
 LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISIN=
G
 FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DE=
ALINGS
 WITH THE SOFTWARE.



|--------------------------------------------------------------|
Mon Mar 16 10:05:42 CDT 2020 ESMF_Scrip2Unstruct -V .......PASS
The following is the output of ESMF_Scrip2Unstruct -V

   ESMF_VERSION_STRING:       8.1.0 beta snapshot



|--------------------------------------------------------------|
Mon Mar 16 10:05:45 CDT 2020 ESMF_WebServController --help PASS
The following is the output of ESMF_WebServController --help

ESMF_WebServController: Run a Process Controller that provides access t=
o an ESMF Web Service enabled Component.
Usage: ESMF_WebServController [--help] [--version] [-V] procCtrlPort re=
gistrarHost registrarPort
    [--help]        Display this information and exit.
    [--version]     Display ESMF version and license information and ex=
it.
    [-V]            Display ESMF version string and exit.
    procCtrlPort    Port num for Process Controller listener.
    registrarHost   Host name on which Registrar is running.
    registrarPort   Port num on which Registrar is listening.
    runScriptDir    Directory containing run script.
    runScriptFile   File name of run script.




|--------------------------------------------------------------|
Mon Mar 16 10:05:45 CDT 2020 ESMF_WebServController --version PASS
The following is the output of ESMF_WebServController --version

   ESMF_VERSION_STRING:       8.1.0 beta snapshot
   ESMF_VERSION_MAJOR:                   8
   ESMF_VERSION_MINOR:                   1
   ESMF_VERSION_REVISION:                0
   ESMF_VERSION_PATCHLEVEL:              0
   ESMF_VERSION_PUBLIC:        F
   ESMF_VERSION_BETASNAPSHOT:  T
=20
 Earth System Modeling Framework
=20
 Copyright (c) 2002-2020 University Corporation for Atmospheric Researc=
h,
 Massachusetts Institute of Technology, Geophysical Fluid Dynamics Labo=
ratory,
 University of Michigan, National Centers for Environmental Prediction,
 Los Alamos National Laboratory, Argonne National Laboratory,
 NASA Goddard Space Flight Center.
 All rights reserved.
=20
 Permission is hereby granted, free of charge, to any person obtaining =
a copy
 of this software and associated documentation files (the 'Software'), =
to
 deal with the Software without restriction, including without limitati=
on the
 rights to use, copy, modify, merge, publish, distribute, sublicense, a=
nd/or
 sell copies of the Software, and to permit persons to whom the Softwar=
e is
 furnished to do so, subject to the following conditions:
    1. Redistributions of source code must retain the above copyright n=
otice,
       this list of conditions and the following disclaimers.
    2. Redistributions in binary form must reproduce the above copyrigh=
t
       notice, this list of conditions and the following disclaimers in=
 the
       documentation and/or other materials provided with the distribut=
ion.
    3. Neither the names of the organizations developing this software,=
 nor
       the names of its contributors may be used to endorse or promote =
products
       derived from this Software without specific prior written permis=
sion.
=20
 THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRES=
S OR
 IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILIT=
Y,
 FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHAL=
L THE
 CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR =
OTHER
 LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISIN=
G
 FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DE=
ALINGS
 WITH THE SOFTWARE.



|--------------------------------------------------------------|
Mon Mar 16 10:05:45 CDT 2020 ESMF_WebServController -V ....PASS
The following is the output of ESMF_WebServController -V

   ESMF_VERSION_STRING:       8.1.0 beta snapshot




Ran 18 applications tests, 18 passed and 0 failed.

|----------------------- SYSTEM TESTS -------------------------|
Mon Mar 16 10:10:53 CDT 2020 build_system_tests -j4 .......PASS
Mon Mar 16 10:14:18 CDT 2020 run_system_tests .............PASS


The following system tests passed:


PASS: mpich3/g: src/system_tests/ESMF_ArrayBundleRedist/ESMF_ArrayBundl=
eRedistSTest.F90
PASS: mpich3/g: src/system_tests/ESMF_ArrayBundleSparseMatMul/ESMF_Arra=
yBundleSparseMatMulSTest.F90
PASS: mpich3/g: src/system_tests/ESMF_ArrayRedist/ESMF_ArrayRedistSTest=
.F90
PASS: mpich3/g: src/system_tests/ESMF_ArrayRedist3D/ESMF_ArrayRedist3DS=
Test.F90
PASS: mpich3/g: src/system_tests/ESMF_ArrayRedistOpenACC/ESMF_ArrayRedi=
stOpenACCSTest.F90
PASS: mpich3/g: src/system_tests/ESMF_ArrayRedistOpenMP/ESMF_ArrayRedis=
tOpenMPSTest.F90
PASS: mpich3/g: src/system_tests/ESMF_ArrayScatterGather/ESMF_ArrayScat=
terGatherSTest.F90
PASS: mpich3/g: src/system_tests/ESMF_ArraySharedDeSSI/ESMF_ArrayShared=
DeSSISTest.F90
PASS: mpich3/g: src/system_tests/ESMF_ArraySparseMatMul/ESMF_ArraySpars=
eMatMulSTest.F90
PASS: mpich3/g: src/system_tests/ESMF_Attribute/ESMF_AttributeSTest.F90
PASS: mpich3/g: src/system_tests/ESMF_AttributeCIM/ESMF_AttributeCIMSTe=
st.F90
PASS: mpich3/g: src/system_tests/ESMF_CompCreate/ESMF_CompCreateSTest.F=
90
PASS: mpich3/g: src/system_tests/ESMF_CompFortranAndC/ESMF_CompFortranA=
ndCSTest.F90
PASS: mpich3/g: src/system_tests/ESMF_ComplianceChecker/ESMF_Compliance=
CheckerSTest.F90
PASS: mpich3/g: src/system_tests/ESMF_ConcurrentComponent/ESMF_Concurre=
ntCompSTest.F90
PASS: mpich3/g: src/system_tests/ESMF_ConcurrentEnsemble/ESMF_Concurren=
tEnsembleSTest.F90
PASS: mpich3/g: src/system_tests/ESMF_DirectCoupling/ESMF_DirectCouplin=
gSTest.F90
PASS: mpich3/g: src/system_tests/ESMF_FieldBundleLSRedistArb2Arb/ESMF_F=
ieldBundleLSRedistArb2ArbSTest.F90
PASS: mpich3/g: src/system_tests/ESMF_FieldBundleLSRedistArb2ArbUngrdDi=
m/ESMF_FieldBundleLSRedistArb2ArbUngrdDimSTest.F90
PASS: mpich3/g: src/system_tests/ESMF_FieldBundleRedistArb2Arb/ESMF_Fie=
ldBundleRedistArb2ArbSTest.F90
PASS: mpich3/g: src/system_tests/ESMF_FieldBundleRedistBlk2Arb/ESMF_Fie=
ldBundleRedistBlk2ArbSTest.F90
PASS: mpich3/g: src/system_tests/ESMF_FieldBundleRedistBlk2Blk/ESMF_Fie=
ldBundleRedistBlk2BlkSTest.F90
PASS: mpich3/g: src/system_tests/ESMF_FieldBundleSMM/ESMF_FieldBundleSM=
MSTest.F90
PASS: mpich3/g: src/system_tests/ESMF_FieldBundleSMMPacked/ESMF_FieldBu=
ndleSMMPackedSTest.F90
PASS: mpich3/g: src/system_tests/ESMF_FieldConcurrentComp/ESMF_FieldCon=
CompSTest.F90
PASS: mpich3/g: src/system_tests/ESMF_FieldLSRedistArb2Arb/ESMF_FieldLS=
RedistArb2ArbSTest.F90
PASS: mpich3/g: src/system_tests/ESMF_FieldLSRedistArb2ArbUngrdDim/ESMF=
_FieldLSRedistArb2ArbUngrdDimSTest.F90
PASS: mpich3/g: src/system_tests/ESMF_FieldLSSMM/ESMF_FieldLSSMMSTest.F=
90
PASS: mpich3/g: src/system_tests/ESMF_FieldMeshSMM/ESMF_FieldMeshSMMSTe=
st.F90
PASS: mpich3/g: src/system_tests/ESMF_FieldRedist/ESMF_FieldRedistSTest=
.F90
PASS: mpich3/g: src/system_tests/ESMF_FieldRedistArb2Arb/ESMF_FieldRedi=
stArb2ArbSTest.F90
PASS: mpich3/g: src/system_tests/ESMF_FieldRedistBlk2Arb/ESMF_FieldRedi=
stBlk2ArbSTest.F90
PASS: mpich3/g: src/system_tests/ESMF_FieldRedistBlk2Blk/ESMF_FieldRedi=
stBlk2BlkSTest.F90
PASS: mpich3/g: src/system_tests/ESMF_FieldRegrid/ESMF_FieldRegridSTest=
.F90
PASS: mpich3/g: src/system_tests/ESMF_FieldRegridDisjoint/ESMF_FieldReg=
ridDisjointSTest.F90
PASS: mpich3/g: src/system_tests/ESMF_FieldRegridMesh/ESMF_FieldRegridM=
eshSTest.F90
PASS: mpich3/g: src/system_tests/ESMF_FieldRegridMeshToMesh/ESMF_FieldR=
egridMeshToMeshSTest.F90
PASS: mpich3/g: src/system_tests/ESMF_FieldRegridOverlap/ESMF_FieldRegr=
idOverlapSTest.F90
PASS: mpich3/g: src/system_tests/ESMF_FieldSparseMatMul/ESMF_FieldSpars=
eMatMulSTest.F90
PASS: mpich3/g: src/system_tests/ESMF_RecursiveComponent/ESMF_Recursive=
ComponentSTest.F90
PASS: mpich3/g: src/system_tests/ESMF_SequentialEnsemble/ESMF_Sequentia=
lEnsembleSTest.F90
PASS: mpich3/g: src/system_tests/ESMF_Trace/ESMF_TraceSTest.F90
PASS: mpich3/g: src/system_tests/ESMF_TransferGrid/ESMF_TransferGridSTe=
st.F90
PASS: mpich3/g: src/system_tests/ESMF_TransferMesh/ESMF_TransferMeshSTe=
st.F90
PASS: mpich3/g: src/system_tests/ESMF_XGridConcurrent/ESMF_XGridConcurr=
entSTest.F90
PASS: mpich3/g: src/system_tests/ESMF_XGridSerial/ESMF_XGridSerialSTest=
.F90




The stdout files for the system_tests can be found at:
/lcrc/project/ESMF/scripts_dirs/daily_builds/intel_bebop/esmf/test/test=
g/Linux.intel.64.mpich3.default


Found 46 multi-processor system tests, 46 passed and 0 failed.



|------------------------- EXAMPLES ---------------------------|
Mon Mar 16 10:23:29 CDT 2020 build_examples -j4 ...........PASS
Mon Mar 16 10:34:18 CDT 2020 run_examples .................PASS


The following examples passed:


PASS: mpich3/g: src/Infrastructure/Array/examples/ESMF_ArrayArbHaloEx.F=
90
PASS: mpich3/g: src/Infrastructure/Array/examples/ESMF_ArrayCommNBEx.F9=
0
PASS: mpich3/g: src/Infrastructure/Array/examples/ESMF_ArrayEx.F90
PASS: mpich3/g: src/Infrastructure/Array/examples/ESMF_ArrayFarrayEx.F9=
0
PASS: mpich3/g: src/Infrastructure/Array/examples/ESMF_ArrayFarrayHaloE=
x.F90
PASS: mpich3/g: src/Infrastructure/Array/examples/ESMF_ArrayHaloEx.F90
PASS: mpich3/g: src/Infrastructure/Array/examples/ESMF_ArrayLarrayEx.F9=
0
PASS: mpich3/g: src/Infrastructure/Array/examples/ESMF_ArrayRedistEx.F9=
0
PASS: mpich3/g: src/Infrastructure/Array/examples/ESMF_ArrayScatterGath=
erArbEx.F90
PASS: mpich3/g: src/Infrastructure/Array/examples/ESMF_ArrayScatterGath=
erEx.F90
PASS: mpich3/g: src/Infrastructure/Array/examples/ESMF_ArraySparseMatMu=
lEx.F90
PASS: mpich3/g: src/Infrastructure/ArrayBundle/examples/ESMF_ArrayBundl=
eEx.F90
PASS: mpich3/g: src/Infrastructure/ArrayBundle/examples/ESMF_ArrayBundl=
eHaloEx.F90
PASS: mpich3/g: src/Infrastructure/ArraySpec/examples/ESMF_ArraySpecEx.=
F90
PASS: mpich3/g: src/Infrastructure/Config/examples/ESMF_ConfigOverviewE=
x.F90
PASS: mpich3/g: src/Infrastructure/DELayout/examples/ESMF_DELayoutEx.F9=
0
PASS: mpich3/g: src/Infrastructure/DistGrid/examples/ESMF_DistGridEx.F9=
0
PASS: mpich3/g: src/Infrastructure/Field/examples/ESMF_FieldArbGridEx.F=
90
PASS: mpich3/g: src/Infrastructure/Field/examples/ESMF_FieldCommEx.F90
PASS: mpich3/g: src/Infrastructure/Field/examples/ESMF_FieldCreateEx.F9=
0
PASS: mpich3/g: src/Infrastructure/Field/examples/ESMF_FieldEx.F90
PASS: mpich3/g: src/Infrastructure/Field/examples/ESMF_FieldHaloEx.F90
PASS: mpich3/g: src/Infrastructure/Field/examples/ESMF_FieldMeshRegridE=
x.F90
PASS: mpich3/g: src/Infrastructure/Field/examples/ESMF_FieldRedistEx.F9=
0
PASS: mpich3/g: src/Infrastructure/Field/examples/ESMF_FieldRegridEx.F9=
0
PASS: mpich3/g: src/Infrastructure/Field/examples/ESMF_FieldRegridMaskE=
x.F90
PASS: mpich3/g: src/Infrastructure/Field/examples/ESMF_FieldRepDimEx.F9=
0
PASS: mpich3/g: src/Infrastructure/Field/examples/ESMF_FieldSMMEx.F90
PASS: mpich3/g: src/Infrastructure/Field/examples/ESMF_FieldSphereRegri=
dEx.F90
PASS: mpich3/g: src/Infrastructure/FieldBundle/examples/ESMF_FieldBundl=
eCreateEx.F90
PASS: mpich3/g: src/Infrastructure/FieldBundle/examples/ESMF_FieldBundl=
eHaloEx.F90
PASS: mpich3/g: src/Infrastructure/FieldBundle/examples/ESMF_FieldBundl=
eRedistEx.F90
PASS: mpich3/g: src/Infrastructure/FieldBundle/examples/ESMF_FieldBundl=
eSMMEx.F90
PASS: mpich3/g: src/Infrastructure/Grid/examples/ESMF_GridCreateRegFrom=
DGEx.F90
PASS: mpich3/g: src/Infrastructure/Grid/examples/ESMF_GridUsageEx.F90
PASS: mpich3/g: src/Infrastructure/LocStream/examples/ESMF_LocStreamEx.=
F90
PASS: mpich3/g: src/Infrastructure/LogErr/examples/ESMF_LogErrEx.F90
PASS: mpich3/g: src/Infrastructure/Mesh/examples/ESMF_MeshEx.F90
PASS: mpich3/g: src/Infrastructure/Route/examples/ESMF_RHandleBitForBit=
Ex.F90
PASS: mpich3/g: src/Infrastructure/Route/examples/ESMF_RHandleDynamicMa=
skingEx.F90
PASS: mpich3/g: src/Infrastructure/Route/examples/ESMF_RHandleFromFileE=
x.F90
PASS: mpich3/g: src/Infrastructure/Route/examples/ESMF_RHandleFromRHand=
leEx.F90
PASS: mpich3/g: src/Infrastructure/Route/examples/ESMF_RHandleReusabili=
tyEx.F90
PASS: mpich3/g: src/Infrastructure/TimeMgr/examples/ESMF_AlarmEx.F90
PASS: mpich3/g: src/Infrastructure/TimeMgr/examples/ESMF_CalendarEx.F90
PASS: mpich3/g: src/Infrastructure/TimeMgr/examples/ESMF_ClockEx.F90
PASS: mpich3/g: src/Infrastructure/TimeMgr/examples/ESMF_TimeEx.F90
PASS: mpich3/g: src/Infrastructure/TimeMgr/examples/ESMF_TimeIntervalEx=
.F90
PASS: mpich3/g: src/Infrastructure/Trace/examples/ESMF_TraceEx.F90
PASS: mpich3/g: src/Infrastructure/Trace/examples/ESMF_TraceUserEx.F90
PASS: mpich3/g: src/Infrastructure/VM/examples/ESMF_VMAllFullReduceEx.F=
90
PASS: mpich3/g: src/Infrastructure/VM/examples/ESMF_VMComponentEx.F90
PASS: mpich3/g: src/Infrastructure/VM/examples/ESMF_VMDefaultBasicsEx.F=
90
PASS: mpich3/g: src/Infrastructure/VM/examples/ESMF_VMGetMPICommunicato=
rEx.F90
PASS: mpich3/g: src/Infrastructure/VM/examples/ESMF_VMHigherRankDataEx.=
F90
PASS: mpich3/g: src/Infrastructure/VM/examples/ESMF_VMScatterVMGatherEx=
.F90
PASS: mpich3/g: src/Infrastructure/VM/examples/ESMF_VMSendVMRecvEx.F90
PASS: mpich3/g: src/Infrastructure/VM/examples/ESMF_VMUserMpiCommEx.F90
PASS: mpich3/g: src/Infrastructure/VM/examples/ESMF_VMUserMpiCommMultiE=
x.F90
PASS: mpich3/g: src/Infrastructure/VM/examples/ESMF_VMUserMpiEx.F90
PASS: mpich3/g: src/Infrastructure/XGrid/examples/ESMF_XGridEx.F90
PASS: mpich3/g: src/Infrastructure/XGrid/examples/ESMF_XGridSparseMatEx=
.F90
PASS: mpich3/g: src/Superstructure/AttachMethods/examples/ESMF_AttachMe=
thodsEx.F90
PASS: mpich3/g: src/Superstructure/AttributeAPI/examples/ESMF_AttReadCu=
stCplCompEx.F90
PASS: mpich3/g: src/Superstructure/AttributeAPI/examples/ESMF_AttReadFi=
eldEx.F90
PASS: mpich3/g: src/Superstructure/AttributeAPI/examples/ESMF_AttReadGr=
idCompEx.F90
PASS: mpich3/g: src/Superstructure/AttributeAPI/examples/ESMF_Attribute=
CIMEx.F90
PASS: mpich3/g: src/Superstructure/AttributeAPI/examples/ESMF_Attribute=
CustPackEx.F90
PASS: mpich3/g: src/Superstructure/AttributeAPI/examples/ESMF_Attribute=
Ex.F90
PASS: mpich3/g: src/Superstructure/AttributeAPI/examples/ESMF_Attribute=
InternalInfoEx.F90
PASS: mpich3/g: src/Superstructure/AttributeAPI/examples/ESMF_Attribute=
PackageEx.F90
PASS: mpich3/g: src/Superstructure/AttributeAPI/examples/ESMF_Attribute=
UpdateEx.F90
PASS: mpich3/g: src/Superstructure/Component/examples/ESMF_AppMainEx.F9=
0
PASS: mpich3/g: src/Superstructure/Component/examples/ESMF_CompTunnelEx=
.F90
PASS: mpich3/g: src/Superstructure/Component/examples/ESMF_CplEx.F90
PASS: mpich3/g: src/Superstructure/Component/examples/ESMF_GCompEx.F90
PASS: mpich3/g: src/Superstructure/Component/examples/ESMF_InternalStat=
eEx.F90
PASS: mpich3/g: src/Superstructure/Component/examples/ESMF_InternalStat=
eModEx.F90
PASS: mpich3/g: src/Superstructure/Component/examples/ESMF_SCompEx.F90
PASS: mpich3/g: src/Superstructure/State/examples/ESMF_StateEx.F90
PASS: mpich3/g: src/Superstructure/State/examples/ESMF_StateReadWriteEx=
.F90
PASS: mpich3/g: src/Superstructure/State/examples/ESMF_StateReconcileEx=
.F90
PASS: mpich3/g: src/Superstructure/WebServices/examples/ESMF_WebService=
sEx.F90
PASS: mpich3/g: src/addon/NUOPC/examples/ESMF_NUOPCAtmModelEx.F90
PASS: mpich3/g: src/addon/NUOPC/examples/ESMF_NUOPCBasicModelEx.F90




The stdout files for the examples can be found at:
/lcrc/project/ESMF/scripts_dirs/daily_builds/intel_bebop/esmf/examples/=
examplesg/Linux.intel.64.mpich3.default


Found 85 multi-processor examples, 85 passed and 0 failed.



|-------------------- EXHAUSTIVE UNIT TESTS -------------------|
Mon Mar 16 10:51:38 CDT 2020 build_unit_tests -j4 .........PASS
Mon Mar 16 11:09:52 CDT 2020 run_unit_tests ...............PASS




The unit tests in the following files all pass:

PASS: mpich3/g: src/Infrastructure/Array/tests/ESMC_ArrayUTest.C
PASS: mpich3/g: src/Infrastructure/Array/tests/ESMF_ArrayArbIdxSMMUTest=
.F90
PASS: mpich3/g: src/Infrastructure/Array/tests/ESMF_ArrayCreateGetUTest=
.F90
PASS: mpich3/g: src/Infrastructure/Array/tests/ESMF_ArrayDataUTest.F90
PASS: mpich3/g: src/Infrastructure/Array/tests/ESMF_ArrayGatherUTest.F9=
0
PASS: mpich3/g: src/Infrastructure/Array/tests/ESMF_ArrayHaloUTest.F90
PASS: mpich3/g: src/Infrastructure/Array/tests/ESMF_ArrayIOUTest.F90
PASS: mpich3/g: src/Infrastructure/Array/tests/ESMF_ArrayRedistPerfUTes=
t.F90
PASS: mpich3/g: src/Infrastructure/Array/tests/ESMF_ArrayRedistUTest.F9=
0
PASS: mpich3/g: src/Infrastructure/Array/tests/ESMF_ArraySMMFromFileUTe=
st.F90
PASS: mpich3/g: src/Infrastructure/Array/tests/ESMF_ArraySMMUTest.F90
PASS: mpich3/g: src/Infrastructure/Array/tests/ESMF_ArrayScatterUTest.F=
90
PASS: mpich3/g: src/Infrastructure/ArrayBundle/tests/ESMF_ArrayBundleCr=
eateUTest.F90
PASS: mpich3/g: src/Infrastructure/ArrayBundle/tests/ESMF_ArrayBundleIO=
UTest.F90
PASS: mpich3/g: src/Infrastructure/ArrayBundle/tests/ESMF_ArrayBundleRe=
distUTest.F90
PASS: mpich3/g: src/Infrastructure/ArraySpec/tests/ESMC_ArraySpecUTest.=
C
PASS: mpich3/g: src/Infrastructure/ArraySpec/tests/ESMF_ArraySpecUTest.=
F90
PASS: mpich3/g: src/Infrastructure/Base/tests/ESMC_BaseUTest.C
PASS: mpich3/g: src/Infrastructure/Base/tests/ESMF_BaseUTest.F90
PASS: mpich3/g: src/Infrastructure/Config/tests/ESMC_ConfigUTest.C
PASS: mpich3/g: src/Infrastructure/Config/tests/ESMF_ConfigUTest.F90
PASS: mpich3/g: src/Infrastructure/Container/tests/ESMF_ContainerUTest.=
F90
PASS: mpich3/g: src/Infrastructure/DELayout/tests/ESMF_DELayoutUTest.F9=
0
PASS: mpich3/g: src/Infrastructure/DELayout/tests/ESMF_DELayoutWorkQueu=
eUTest.F90
PASS: mpich3/g: src/Infrastructure/DistGrid/tests/ESMC_DistGridUTest.C
PASS: mpich3/g: src/Infrastructure/DistGrid/tests/ESMF_DistGridCreateGe=
tUTest.F90
PASS: mpich3/g: src/Infrastructure/Field/tests/ESMC_FieldGridGridRegrid=
CsrvUTest.C
PASS: mpich3/g: src/Infrastructure/Field/tests/ESMC_FieldGridGridRegrid=
UTest.C
PASS: mpich3/g: src/Infrastructure/Field/tests/ESMC_FieldGridRegrid2UTe=
st.C
PASS: mpich3/g: src/Infrastructure/Field/tests/ESMC_FieldGridRegridCsrv=
2UTest.C
PASS: mpich3/g: src/Infrastructure/Field/tests/ESMC_FieldGridRegridCsrv=
UTest.C
PASS: mpich3/g: src/Infrastructure/Field/tests/ESMC_FieldGridRegridParU=
Test.C
PASS: mpich3/g: src/Infrastructure/Field/tests/ESMC_FieldGridRegridUTes=
t.C
PASS: mpich3/g: src/Infrastructure/Field/tests/ESMC_FieldRegridCsrvUTes=
t.C
PASS: mpich3/g: src/Infrastructure/Field/tests/ESMC_FieldRegridUTest.C
PASS: mpich3/g: src/Infrastructure/Field/tests/ESMC_FieldSMMFromFileUTe=
st.C
PASS: mpich3/g: src/Infrastructure/Field/tests/ESMC_FieldUTest.C
PASS: mpich3/g: src/Infrastructure/Field/tests/ESMF_FieldArbGridUTest.F=
90
PASS: mpich3/g: src/Infrastructure/Field/tests/ESMF_FieldCreateGetUTest=
.F90
PASS: mpich3/g: src/Infrastructure/Field/tests/ESMF_FieldGatherUTest.F9=
0
PASS: mpich3/g: src/Infrastructure/Field/tests/ESMF_FieldHaloUTest.F90
PASS: mpich3/g: src/Infrastructure/Field/tests/ESMF_FieldIOUTest.F90
PASS: mpich3/g: src/Infrastructure/Field/tests/ESMF_FieldLSSMMUTest.F90
PASS: mpich3/g: src/Infrastructure/Field/tests/ESMF_FieldRedistArbUTest=
.F90
PASS: mpich3/g: src/Infrastructure/Field/tests/ESMF_FieldRedistUTest.F9=
0
PASS: mpich3/g: src/Infrastructure/Field/tests/ESMF_FieldRegridCSUTest.=
F90
PASS: mpich3/g: src/Infrastructure/Field/tests/ESMF_FieldRegridCsrv2ndU=
Test.F90
PASS: mpich3/g: src/Infrastructure/Field/tests/ESMF_FieldRegridCsrvUTes=
t.F90
PASS: mpich3/g: src/Infrastructure/Field/tests/ESMF_FieldRegridUTest.F9=
0
PASS: mpich3/g: src/Infrastructure/Field/tests/ESMF_FieldRegridXGSMMUTe=
st.F90
PASS: mpich3/g: src/Infrastructure/Field/tests/ESMF_FieldRegridXGUTest.=
F90
PASS: mpich3/g: src/Infrastructure/Field/tests/ESMF_FieldSMMFromFileUTe=
st.F90
PASS: mpich3/g: src/Infrastructure/Field/tests/ESMF_FieldSMMUTest.F90
PASS: mpich3/g: src/Infrastructure/Field/tests/ESMF_FieldStressUTest.F9=
0
PASS: mpich3/g: src/Infrastructure/Field/tests/ESMF_FieldUTest.F90
PASS: mpich3/g: src/Infrastructure/FieldBundle/tests/ESMF_FieldBundleCr=
GetUTest.F90
PASS: mpich3/g: src/Infrastructure/FieldBundle/tests/ESMF_FieldBundleIO=
UTest.F90
PASS: mpich3/g: src/Infrastructure/FieldBundle/tests/ESMF_FieldBundleRe=
distUTest.F90
PASS: mpich3/g: src/Infrastructure/FieldBundle/tests/ESMF_FieldBundleRe=
gridUTest.F90
PASS: mpich3/g: src/Infrastructure/FieldBundle/tests/ESMF_FieldBundleSM=
MUTest.F90
PASS: mpich3/g: src/Infrastructure/FieldBundle/tests/ESMF_FieldBundleUT=
est.F90
PASS: mpich3/g: src/Infrastructure/Grid/tests/ESMC_GridUTest.C
PASS: mpich3/g: src/Infrastructure/Grid/tests/ESMF_GridArbitraryUTest.F=
90
PASS: mpich3/g: src/Infrastructure/Grid/tests/ESMF_GridCoordUTest.F90
PASS: mpich3/g: src/Infrastructure/Grid/tests/ESMF_GridCreateUTest.F90
PASS: mpich3/g: src/Infrastructure/Grid/tests/ESMF_GridItemUTest.F90
PASS: mpich3/g: src/Infrastructure/GridUtil/tests/ESMF_GridToMeshUTest.=
F90
PASS: mpich3/g: src/Infrastructure/IO/tests/ESMCI_IO_NetCDFUTest.C
PASS: mpich3/g: src/Infrastructure/IO/tests/ESMCI_IO_PIOUTest.C
PASS: mpich3/g: src/Infrastructure/IO/tests/ESMC_IO_InqUTest.C
PASS: mpich3/g: src/Infrastructure/IO/tests/ESMF_IOUTest.F90
PASS: mpich3/g: src/Infrastructure/IO/tests/ESMF_IO_PIOUTest.F90
PASS: mpich3/g: src/Infrastructure/IO/tests/ESMF_IO_YAMLUTest.F90
PASS: mpich3/g: src/Infrastructure/LocStream/tests/ESMC_LocStreamUTest.=
C
PASS: mpich3/g: src/Infrastructure/LocStream/tests/ESMF_LocStreamUTest.=
F90
PASS: mpich3/g: src/Infrastructure/LocalArray/tests/ESMF_LocalArrayData=
UTest.F90
PASS: mpich3/g: src/Infrastructure/LocalArray/tests/ESMF_LocalArrayUTes=
t.F90
PASS: mpich3/g: src/Infrastructure/LogErr/tests/ESMC_LogErrPerfUTest.C
PASS: mpich3/g: src/Infrastructure/LogErr/tests/ESMC_LogErrUTest.C
PASS: mpich3/g: src/Infrastructure/LogErr/tests/ESMF_LogErrPerfUTest.F9=
0
PASS: mpich3/g: src/Infrastructure/LogErr/tests/ESMF_LogErrUTest.F90
PASS: mpich3/g: src/Infrastructure/Mesh/tests/ESMC_MBMesh_BilinearParUT=
est.C
PASS: mpich3/g: src/Infrastructure/Mesh/tests/ESMC_MBMesh_BilinearSingl=
eElemUTest.C
PASS: mpich3/g: src/Infrastructure/Mesh/tests/ESMC_MBMesh_BilinearUTest=
.C
PASS: mpich3/g: src/Infrastructure/Mesh/tests/ESMC_MBMesh_CreateParUTes=
t.C
PASS: mpich3/g: src/Infrastructure/Mesh/tests/ESMC_MBMesh_CreateUTest.C
PASS: mpich3/g: src/Infrastructure/Mesh/tests/ESMC_MBMesh_SearchUTest.C
PASS: mpich3/g: src/Infrastructure/Mesh/tests/ESMC_MBMesh_SerializeUTes=
t.C
PASS: mpich3/g: src/Infrastructure/Mesh/tests/ESMC_MBMesh_UtilParUTest.=
C
PASS: mpich3/g: src/Infrastructure/Mesh/tests/ESMC_MBMesh_UtilUTest.C
PASS: mpich3/g: src/Infrastructure/Mesh/tests/ESMC_MeshMOABUTest.C
PASS: mpich3/g: src/Infrastructure/Mesh/tests/ESMC_MeshUTest.C
PASS: mpich3/g: src/Infrastructure/Mesh/tests/ESMC_MeshVTKUTest.C
PASS: mpich3/g: src/Infrastructure/Mesh/tests/ESMC_Proj4UTest.C
PASS: mpich3/g: src/Infrastructure/Mesh/tests/ESMF_MeshOpUTest.F90
PASS: mpich3/g: src/Infrastructure/Mesh/tests/ESMF_MeshUTest.F90
PASS: mpich3/g: src/Infrastructure/PointList/tests/ESMF_PointListUTest.=
F90
PASS: mpich3/g: src/Infrastructure/Route/tests/ESMF_RouteHandleAdvanced=
UTest.F90
PASS: mpich3/g: src/Infrastructure/Route/tests/ESMF_RouteHandleUTest.F9=
0
PASS: mpich3/g: src/Infrastructure/TimeMgr/tests/ESMC_CalendarUTest.C
PASS: mpich3/g: src/Infrastructure/TimeMgr/tests/ESMC_ClockUTest.C
PASS: mpich3/g: src/Infrastructure/TimeMgr/tests/ESMC_TimeIntervalUTest=
.C
PASS: mpich3/g: src/Infrastructure/TimeMgr/tests/ESMC_TimeUTest.C
PASS: mpich3/g: src/Infrastructure/TimeMgr/tests/ESMF_AlarmUTest.F90
PASS: mpich3/g: src/Infrastructure/TimeMgr/tests/ESMF_CalRangeUTest.F90
PASS: mpich3/g: src/Infrastructure/TimeMgr/tests/ESMF_CalendarUTest.F90
PASS: mpich3/g: src/Infrastructure/TimeMgr/tests/ESMF_ClockUTest.F90
PASS: mpich3/g: src/Infrastructure/TimeMgr/tests/ESMF_TimeIntervalUTest=
.F90
PASS: mpich3/g: src/Infrastructure/TimeMgr/tests/ESMF_TimeUTest.F90
PASS: mpich3/g: src/Infrastructure/Trace/tests/ESMC_TraceRegionUTest.C
PASS: mpich3/g: src/Infrastructure/Trace/tests/ESMF_ProfileUTest.F90
PASS: mpich3/g: src/Infrastructure/Trace/tests/ESMF_TraceClkMonoSyncUTe=
st.F90
PASS: mpich3/g: src/Infrastructure/Trace/tests/ESMF_TraceClkMonoUTest.F=
90
PASS: mpich3/g: src/Infrastructure/Trace/tests/ESMF_TraceIOUTest.F90
PASS: mpich3/g: src/Infrastructure/Trace/tests/ESMF_TraceMPIUTest.F90
PASS: mpich3/g: src/Infrastructure/Trace/tests/ESMF_TraceUTest.F90
PASS: mpich3/g: src/Infrastructure/Util/tests/ESMF_FortranWordsizeUTest=
.F90
PASS: mpich3/g: src/Infrastructure/Util/tests/ESMF_InitMacrosUTest.F90
PASS: mpich3/g: src/Infrastructure/Util/tests/ESMF_TypeKindGetUTest.F90
PASS: mpich3/g: src/Infrastructure/Util/tests/ESMF_UtilUTest.F90
PASS: mpich3/g: src/Infrastructure/VM/tests/ESMC_VMUTest.C
PASS: mpich3/g: src/Infrastructure/VM/tests/ESMF_VMAccUTest.F90
PASS: mpich3/g: src/Infrastructure/VM/tests/ESMF_VMAllGatherUTest.F90
PASS: mpich3/g: src/Infrastructure/VM/tests/ESMF_VMAllGatherVUTest.F90
PASS: mpich3/g: src/Infrastructure/VM/tests/ESMF_VMAllToAllUTest.F90
PASS: mpich3/g: src/Infrastructure/VM/tests/ESMF_VMAllToAllVUTest.F90
PASS: mpich3/g: src/Infrastructure/VM/tests/ESMF_VMBarrierUTest.F90
PASS: mpich3/g: src/Infrastructure/VM/tests/ESMF_VMBroadcastUTest.F90
PASS: mpich3/g: src/Infrastructure/VM/tests/ESMF_VMComponentUTest.F90
PASS: mpich3/g: src/Infrastructure/VM/tests/ESMF_VMGatherUTest.F90
PASS: mpich3/g: src/Infrastructure/VM/tests/ESMF_VMOpenMPUTest.F90
PASS: mpich3/g: src/Infrastructure/VM/tests/ESMF_VMScatterUTest.F90
PASS: mpich3/g: src/Infrastructure/VM/tests/ESMF_VMSendNbVMRecvNbUTest.=
F90
PASS: mpich3/g: src/Infrastructure/VM/tests/ESMF_VMSendRecvNbUTest.F90
PASS: mpich3/g: src/Infrastructure/VM/tests/ESMF_VMSendRecvUTest.F90
PASS: mpich3/g: src/Infrastructure/VM/tests/ESMF_VMSendVMRecvUTest.F90
PASS: mpich3/g: src/Infrastructure/VM/tests/ESMF_VMUTest.F90
PASS: mpich3/g: src/Infrastructure/VM/tests/ESMF_VMUserMpiInitUTest.F90
PASS: mpich3/g: src/Infrastructure/XGrid/tests/ESMC_XGridUTest.C
PASS: mpich3/g: src/Infrastructure/XGrid/tests/ESMF_XGridMaskingUTest.F=
90
PASS: mpich3/g: src/Infrastructure/XGrid/tests/ESMF_XGridUTest.F90
PASS: mpich3/g: src/Superstructure/AttributeAPI/tests/ESMF_AttInternalG=
ridUTest.F90
PASS: mpich3/g: src/Superstructure/AttributeAPI/tests/ESMF_AttPackABund=
leUTest.F90
PASS: mpich3/g: src/Superstructure/AttributeAPI/tests/ESMF_AttPackArray=
UTest.F90
PASS: mpich3/g: src/Superstructure/AttributeAPI/tests/ESMF_AttPackCplCo=
mpUTest.F90
PASS: mpich3/g: src/Superstructure/AttributeAPI/tests/ESMF_AttPackDistG=
ridUTest.F90
PASS: mpich3/g: src/Superstructure/AttributeAPI/tests/ESMF_AttPackFBund=
leUTest.F90
PASS: mpich3/g: src/Superstructure/AttributeAPI/tests/ESMF_AttPackField=
UTest.F90
PASS: mpich3/g: src/Superstructure/AttributeAPI/tests/ESMF_AttPackGridC=
ompUTest.F90
PASS: mpich3/g: src/Superstructure/AttributeAPI/tests/ESMF_AttPackGridU=
Test.F90
PASS: mpich3/g: src/Superstructure/AttributeAPI/tests/ESMF_AttPackLocSt=
reamUTest.F90
PASS: mpich3/g: src/Superstructure/AttributeAPI/tests/ESMF_AttPackSciCo=
mpUTest.F90
PASS: mpich3/g: src/Superstructure/AttributeAPI/tests/ESMF_AttPackState=
UTest.F90
PASS: mpich3/g: src/Superstructure/AttributeAPI/tests/ESMF_AttReadCplCo=
mpUTest.F90
PASS: mpich3/g: src/Superstructure/AttributeAPI/tests/ESMF_AttReadField=
UTest.F90
PASS: mpich3/g: src/Superstructure/AttributeAPI/tests/ESMF_AttReadGridC=
ompUTest.F90
PASS: mpich3/g: src/Superstructure/AttributeAPI/tests/ESMF_AttributeABu=
ndleUTest.F90
PASS: mpich3/g: src/Superstructure/AttributeAPI/tests/ESMF_AttributeArr=
ayUTest.F90
PASS: mpich3/g: src/Superstructure/AttributeAPI/tests/ESMF_AttributeAut=
oLinkUTest.F90
PASS: mpich3/g: src/Superstructure/AttributeAPI/tests/ESMF_AttributeCpl=
CompUTest.F90
PASS: mpich3/g: src/Superstructure/AttributeAPI/tests/ESMF_AttributeDis=
tGridUTest.F90
PASS: mpich3/g: src/Superstructure/AttributeAPI/tests/ESMF_AttributeFBu=
ndleUTest.F90
PASS: mpich3/g: src/Superstructure/AttributeAPI/tests/ESMF_AttributeFie=
ldUTest.F90
PASS: mpich3/g: src/Superstructure/AttributeAPI/tests/ESMF_AttributeGri=
dCompUTest.F90
PASS: mpich3/g: src/Superstructure/AttributeAPI/tests/ESMF_AttributeGri=
dUTest.F90
PASS: mpich3/g: src/Superstructure/AttributeAPI/tests/ESMF_AttributeJSO=
NUTest.F90
PASS: mpich3/g: src/Superstructure/AttributeAPI/tests/ESMF_AttributeLoc=
StreamUTest.F90
PASS: mpich3/g: src/Superstructure/AttributeAPI/tests/ESMF_AttributeSci=
CompUTest.F90
PASS: mpich3/g: src/Superstructure/AttributeAPI/tests/ESMF_AttributeSta=
teUTest.F90
PASS: mpich3/g: src/Superstructure/AttributeAPI/tests/ESMF_AttributeUpd=
ateCIMRespPartyUTest.F90
PASS: mpich3/g: src/Superstructure/AttributeAPI/tests/ESMF_AttributeUpd=
ateClosedLoopTreesUTest.F90
PASS: mpich3/g: src/Superstructure/AttributeAPI/tests/ESMF_AttributeUpd=
ateComponentUTest.F90
PASS: mpich3/g: src/Superstructure/AttributeAPI/tests/ESMF_AttributeUpd=
ateContainerStressUTest.F90
PASS: mpich3/g: src/Superstructure/AttributeAPI/tests/ESMF_AttributeUpd=
ateMultiReconcileUTest.F90
PASS: mpich3/g: src/Superstructure/AttributeAPI/tests/ESMF_AttributeUpd=
ateReconcileUTest.F90
PASS: mpich3/g: src/Superstructure/AttributeAPI/tests/ESMF_AttributeUpd=
ateRemoveOnlyUTest.F90
PASS: mpich3/g: src/Superstructure/AttributeAPI/tests/ESMF_AttributeUpd=
ateUTest.F90
PASS: mpich3/g: src/Superstructure/AttributeAPI/tests/ESMF_AttributeWri=
teInternalUTest.F90
PASS: mpich3/g: src/Superstructure/AttributeAPI/tests/ESMF_AttributeXML=
UTest.F90
PASS: mpich3/g: src/Superstructure/Component/tests/ESMC_ComponentUTest.=
C
PASS: mpich3/g: src/Superstructure/Component/tests/ESMF_CompSetServUTes=
t.F90
PASS: mpich3/g: src/Superstructure/Component/tests/ESMF_CompTunnelUTest=
.F90
PASS: mpich3/g: src/Superstructure/Component/tests/ESMF_ComponentUTest.=
F90
PASS: mpich3/g: src/Superstructure/Component/tests/ESMF_CplCompCreateUT=
est.F90
PASS: mpich3/g: src/Superstructure/Component/tests/ESMF_GridCompCreateU=
Test.F90
PASS: mpich3/g: src/Superstructure/Component/tests/ESMF_SciCompCreateUT=
est.F90
PASS: mpich3/g: src/Superstructure/Component/tests/ESMF_StdCompMethodsU=
Test.F90
PASS: mpich3/g: src/Superstructure/ESMFMod/tests/ESMF_FrameworkUTest.F9=
0
PASS: mpich3/g: src/Superstructure/IOAPI/tests/ESMF_IOCompUTest.F90
PASS: mpich3/g: src/Superstructure/PreESMFMod/tests/ESMF_FileRegridUTes=
t.F90
PASS: mpich3/g: src/Superstructure/PreESMFMod/tests/ESMF_RegridWeightGe=
nUTest.F90
PASS: mpich3/g: src/Superstructure/State/tests/ESMC_StateUTest.C
PASS: mpich3/g: src/Superstructure/State/tests/ESMF_StateCreateUTest.F9=
0
PASS: mpich3/g: src/Superstructure/State/tests/ESMF_StateReadWriteUTest=
.F90
PASS: mpich3/g: src/Superstructure/State/tests/ESMF_StateReconcileUTest=
.F90
PASS: mpich3/g: src/Superstructure/State/tests/ESMF_StateUTest.F90
PASS: mpich3/g: src/addon/NUOPC/tests/ESMF_NUOPC_UTest.F90
PASS: mpich3/g: src/epilogue/tests/ESMCI_TestUTest.C
PASS: mpich3/g: src/epilogue/tests/ESMC_TestUTest.C
PASS: mpich3/g: src/epilogue/tests/ESMF_TestUTest.F90
PASS: mpich3/g: src/prologue/tests/ESMCI_ExceptionsUTest.C
PASS: mpich3/g: src/prologue/tests/ESMCI_FeatureUTest.C
PASS: mpich3/g: src/prologue/tests/ESMF_F90ArrayPtrUTest.F90
PASS: mpich3/g: src/prologue/tests/ESMF_FeatureUTest.F90
PASS: mpich3/g: src/prologue/tests/ESMF_LAPACKUTest.F90
PASS: mpich3/g: src/prologue/tests/ESMF_StringUTest.F90
PASS: mpich3/g: src/prologue/tests/ESMF_WordsizeUTest.F90


The following test harness unit tests pass:
PASS: mpich3/g: ESMF_array_default_NP4UTest
PASS: mpich3/g: ESMF_field_default_NP4UTest


The log and stdout files for the unit tests can be found at:
/lcrc/project/ESMF/scripts_dirs/daily_builds/intel_bebop/esmf/test/test=
g/Linux.intel.64.mpich3.default


Found 9075 exhaustive multi-processor unit tests, 9075 passed and 0 fai=
led.



_______________________________________________________________________=
________________________


Mon Mar 16 11:16:11 CDT 2020 on beboplogin2=20

ESMF Checkout Source: https://github.com/esmf-org/esmf

Compiler and configuration information:
=20
--------------------------------------------------------------=20

Currently Loaded Modules:
  1) intel/17.0.3-gbgtimn
  2) mpich/3.2-5koqqym

=20

=20
Repository:
origin=09https://github.com/esmf-org/esmf (fetch)
origin=09https://github.com/esmf-org/esmf (push)
=20
ESMF_8_1_0_beta_snapshot_11
=20
=20
=20
--------------------------------------------------------------
ESMF_VERSION_STRING:    8.1.0 beta snapshot
ESMF_8_1_0_beta_snapshot_11
--------------------------------------------------------------
# On branch master
# Untracked files:
#   (use "git add <file>..." to include in what will be committed)
#
#=09queue_results
#=09src/installcheck/esmc_application
#=09src/installcheck/esmc_application.o
#=09src/installcheck/esmf_application
#=09src/installcheck/esmf_application.o
#=09tmp
#
# It took 2.62 seconds to enumerate untracked files. 'status -uno'
# may speed it up, but you have to be careful not to forget to add
# new files yourself (see 'git help status').
nothing added to commit but untracked files present (use "git add" to t=
rack)
--------------------------------------------------------------
=20
--------------------------------------------------------------
Make version:
GNU Make 3.82
Built for x86_64-redhat-linux-gnu
Copyright (C) 2010  Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl=
.html>
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.

--------------------------------------------------------------
Fortran Compiler version:
mpifort for MPICH version 3.2
Intel(R) Fortran Intel(R) 64 Compiler for applications running on Intel=
(R) 64, Version 17.0.3.191 Build 20170404
Copyright (C) 1985-2017 Intel Corporation.  All rights reserved.

ifort version 17.0.3

--------------------------------------------------------------
C++ Compiler version:
mpicxx for MPICH version 3.2
Intel(R) C++ Intel(R) 64 Compiler for applications running on Intel(R) =
64, Version 17.0.3.191 Build 20170404
Copyright (C) 1985-2017 Intel Corporation.  All rights reserved.

icpc version 17.0.3 (gcc version 4.8.5 compatibility)

--------------------------------------------------------------
Preprocessor version:
gcc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-36)
Copyright (C) 2015 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is=
 NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURP=
OSE.

=20
--------------------------------------------------------------
 * User set ESMF environment variables *
ESMF_ABI=3D64
ESMF_BOPT=3DO
ESMF_COMM=3Dmpich3
ESMF_COMPILER=3Dintel
ESMF_DIR=3D/lcrc/project/ESMF/scripts_dirs/daily_builds/intel_bebop/esm=
f
ESMF_INSTALL_PREFIX=3D/lcrc/project/ESMF/scripts_dirs/daily_builds/inte=
l_bebop/esmf/../install_dir
ESMF_MPIRUN=3D/lcrc/project/ESMF/scripts_dirs/daily_builds/intel_bebop/=
esmf/scripts/mpirun.srun
ESMF_OS=3DLinux
ESMF_PROJ4=3Dexternal
ESMF_PROJ4_INCLUDE=3D/home/svasquez/proj4/include
ESMF_PROJ4_LIBPATH=3D/home/svasquez/proj4/lib
ESMF_SITE=3Ddefault
ESMF_TESTCOMPTUNNEL=3DOFF
ESMF_TESTEXHAUSTIVE=3DON
ESMF_TESTHARNESS_ARRAY=3DRUN_ESMF_TestHarnessArray_default
ESMF_TESTHARNESS_FIELD=3DRUN_ESMF_TestHarnessField_default
ESMF_TESTMPMD=3DOFF
ESMF_TESTWITHTHREADS=3DOFF
=20
--------------------------------------------------------------
 * ESMF environment variables *
ESMF_DIR: /lcrc/project/ESMF/scripts_dirs/daily_builds/intel_bebop/esmf
ESMF_OS:                Linux
ESMF_MACHINE:           x86_64
ESMF_ABI:               64
ESMF_COMPILER:          intel
ESMF_BOPT:              O
ESMF_COMM:              mpich3
ESMF_SITE:              default
ESMF_PTHREADS:          ON
ESMF_OPENMP:            ON
ESMF_OPENACC:           OFF
ESMF_CXXSTD:            11
ESMF_ARRAY_LITE:        FALSE
ESMF_NO_INTEGER_1_BYTE: TRUE
ESMF_NO_INTEGER_2_BYTE: TRUE
ESMF_FORTRANSYMBOLS:    default
ESMF_MAPPER_BUILD:      OFF
ESMF_AUTO_LIB_BUILD:    ON
ESMF_DEFER_LIB_BUILD:   ON
ESMF_SHARED_LIB_BUILD:  ON
ESMF_TRACE_LIB_BUILD:   ON
ESMF_TESTEXHAUSTIVE:    ON
ESMF_TESTCOMPTUNNEL:    OFF
ESMF_TESTWITHTHREADS:   OFF
ESMF_TESTMPMD:          OFF
ESMF_TESTSHAREDOBJ:     OFF
ESMF_TESTFORCEOPENMP:   OFF
ESMF_TESTFORCEOPENACC:  OFF
ESMF_TESTHARNESS_ARRAY: RUN_ESMF_TestHarnessArray_default
ESMF_TESTHARNESS_FIELD: RUN_ESMF_TestHarnessField_default
ESMF_MPIRUN:            /lcrc/project/ESMF/scripts_dirs/daily_builds/in=
tel_bebop/esmf/scripts/mpirun.srun
=20
--------------------------------------------------------------
 * ESMF environment variables pointing to 3rd party software *
ESMF_MOAB:               internal
ESMF_LAPACK:             internal
ESMF_ACC_SOFTWARE_STACK: none
ESMF_YAMLCPP:            internal
ESMF_PIO:                internal
ESMF_PROJ4:                external
ESMF_PROJ4_INCLUDE:        /home/svasquez/proj4/include
ESMF_PROJ4_LIBS:           -lproj
ESMF_PROJ4_LIBPATH:        /home/svasquez/proj4/lib
=20
--------------------------------------------------------------
 * ESMF environment variables for final installation *
ESMF_INSTALL_PREFIX:    /lcrc/project/ESMF/scripts_dirs/daily_builds/in=
tel_bebop/esmf/../install_dir
ESMF_INSTALL_HEADERDIR: include
ESMF_INSTALL_MODDIR:    mod/modO/Linux.intel.64.mpich3.default
ESMF_INSTALL_LIBDIR:    lib/libO/Linux.intel.64.mpich3.default
ESMF_INSTALL_BINDIR:    bin/binO/Linux.intel.64.mpich3.default
ESMF_INSTALL_DOCDIR:    doc
=20
--------------------------------------------------------------
 * ESMF Benchmark directory and parameters *
ESMF_BENCHMARK_PREFIX:         ./DEFAULTBENCHMARKDIR
ESMF_BENCHMARK_TOLERANCE:      20%
ESMF_BENCHMARK_THRESHOLD_MSEC: 500
=20
--------------------------------------------------------------
 * Other relevant environment variables *
PATH:    /blues/gpfs/home/software/spack-0.10.1/opt/spack/linux-centos7=
-x86_64/intel-17.0.3/mpich-3.2-5koqqymkjuonxuxqcp6353jxy4jabaqg/bin:/bl=
ues/gpfs/home/software/spack-0.10.1/opt/spack/linux-centos7-x86_64/gcc-=
4.8.5/intel-17.0.3-gbgtimncxmczihdqphudp4l3gye5fqmq/bin:/home/svasquez/=
bin:/usr/bin:/bin:/usr/local/sbin:/usr/sbin:/soft/lcrc/bebop/bin:/soft/=
lcrc/bebop/bin:/soft/lcrc/bebop/bin
LD_LIBRARY_PATH: /blues/gpfs/home/software/spack-0.10.1/opt/spack/linux=
-centos7-x86_64/intel-17.0.3/mpich-3.2-5koqqymkjuonxuxqcp6353jxy4jabaqg=
/lib:/blues/gpfs/home/software/spack-0.10.1/opt/spack/linux-centos7-x86=
_64/gcc-4.8.5/intel-17.0.3-gbgtimncxmczihdqphudp4l3gye5fqmq/tbb/lib/int=
el64/gcc4.4:/blues/gpfs/home/software/spack-0.10.1/opt/spack/linux-cent=
os7-x86_64/gcc-4.8.5/intel-17.0.3-gbgtimncxmczihdqphudp4l3gye5fqmq/lib/=
intel64
=20
--------------------------------------------------------------
 * Compilers, Linkers, Flags, and Libraries *
Location of the preprocessor:      /usr/bin/gcc
Location of the Fortran compiler:  /blues/gpfs/home/software/spack-0.10=
.1/opt/spack/linux-centos7-x86_64/intel-17.0.3/mpich-3.2-5koqqymkjuonxu=
xqcp6353jxy4jabaqg/bin/mpif90
Location of the Fortran linker:    /blues/gpfs/home/software/spack-0.10=
.1/opt/spack/linux-centos7-x86_64/intel-17.0.3/mpich-3.2-5koqqymkjuonxu=
xqcp6353jxy4jabaqg/bin/mpif90
Location of the C++ compiler:      /blues/gpfs/home/software/spack-0.10=
.1/opt/spack/linux-centos7-x86_64/intel-17.0.3/mpich-3.2-5koqqymkjuonxu=
xqcp6353jxy4jabaqg/bin/mpicxx
Location of the C++ linker:        /blues/gpfs/home/software/spack-0.10=
.1/opt/spack/linux-centos7-x86_64/intel-17.0.3/mpich-3.2-5koqqymkjuonxu=
xqcp6353jxy4jabaqg/bin/mpicxx

Fortran compiler flags:
ESMF_F90COMPILER: mpif90
ESMF_F90COMPILEOPTS: -O -fPIC -assume realloc_lhs -m64 -mcmodel=3Dsmall=
 -threads  -qopenmp
ESMF_F90COMPILEPATHS: -I/lcrc/project/ESMF/scripts_dirs/daily_builds/in=
tel_bebop/esmf/mod/modO/Linux.intel.64.mpich3.default -I/lcrc/project/E=
SMF/scripts_dirs/daily_builds/intel_bebop/esmf/src/include -I/home/svas=
quez/proj4/include
ESMF_F90COMPILECPPFLAGS: -DESMF_NO_INTEGER_1_BYTE -DESMF_NO_INTEGER_2_B=
YTE -DESMFVERSIONGIT=3D'ESMF_8_1_0_beta_snapshot_11' -DESMF_MOAB=3D1 -D=
ESMF_LAPACK=3D1 -DESMF_LAPACK_INTERNAL=3D1 -DESMF_NO_ACC_SOFTWARE_STACK=
=3D1 -DESMF_YAMLCPP=3D1 -DESMF_YAML=3D1 -DESMF_PIO=3D1 -DESMF_MPIIO -DE=
SMF_PROJ4=3D1 -DESMF_NO_OPENACC -DESMF_TESTEXHAUSTIVE -DESMF_BOPT_O -DS=
x86_64_small=3D1 -DESMF_OS_Linux=3D1 -DESMF_COMM=3Dmpich3 -DESMF_DIR=3D=
/lcrc/project/ESMF/scripts_dirs/daily_builds/intel_bebop/esmf
ESMF_F90COMPILEFREECPP:=20
ESMF_F90COMPILEFREENOCPP:=20
ESMF_F90COMPILEFIXCPP:=20
ESMF_F90COMPILEFIXNOCPP:=20

Fortran linker flags:
ESMF_F90LINKOPTS:   -m64 -mcmodel=3Dsmall -threads -Wl,--no-as-needed  =
-qopenmp
ESMF_F90LINKPATHS: -L/lcrc/project/ESMF/scripts_dirs/daily_builds/intel=
_bebop/esmf/lib/libO/Linux.intel.64.mpich3.default -L/home/svasquez/pro=
j4/lib=20
ESMF_F90LINKRPATHS: -Wl,-rpath,/lcrc/project/ESMF/scripts_dirs/daily_bu=
ilds/intel_bebop/esmf/lib/libO/Linux.intel.64.mpich3.default  -Wl,-rpat=
h,/home/svasquez/proj4/lib
ESMF_F90LINKLIBS:  -cxxlib -lrt -ldl -lproj
ESMF_F90ESMFLINKLIBS: -lesmf  -cxxlib -lrt -ldl -lproj

C++ compiler flags:
ESMF_CXXCOMPILER: mpicxx
ESMF_CXXCOMPILEOPTS: -std=3Dc++11 -O -DNDEBUG -fPIC -m64 -mcmodel=3Dsma=
ll -pthread  -qopenmp
ESMF_CXXCOMPILEPATHS:  -I/lcrc/project/ESMF/scripts_dirs/daily_builds/i=
ntel_bebop/esmf/src/include  -I/home/svasquez/proj4/include -I/lcrc/pro=
ject/ESMF/scripts_dirs/daily_builds/intel_bebop/esmf/src/prologue/yaml-=
cpp/include
ESMF_CXXCOMPILECPPFLAGS: -DESMF_NO_INTEGER_1_BYTE -DESMF_NO_INTEGER_2_B=
YTE -DESMFVERSIONGIT=3D'ESMF_8_1_0_beta_snapshot_11' -DESMF_MOAB=3D1 -D=
ESMF_LAPACK=3D1 -DESMF_LAPACK_INTERNAL=3D1 -DESMF_NO_ACC_SOFTWARE_STACK=
=3D1 -DESMF_YAMLCPP=3D1 -DESMF_YAML=3D1 -DESMF_PIO=3D1 -DESMF_MPIIO -DE=
SMF_PROJ4=3D1 -DESMF_NO_OPENACC -DESMF_TESTEXHAUSTIVE -DESMF_BOPT_O -DS=
x86_64_small=3D1 -DESMF_OS_Linux=3D1 -DESMF_COMM=3Dmpich3 -DESMF_DIR=3D=
/lcrc/project/ESMF/scripts_dirs/daily_builds/intel_bebop/esmf -D__SDIR_=
_=3D'' -DESMF_CXXSTD=3D11

C++ linker flags:
ESMF_CXXLINKOPTS:   -m64 -mcmodel=3Dsmall -pthread -Wl,--no-as-needed  =
-qopenmp
ESMF_CXXLINKPATHS: -L/lcrc/project/ESMF/scripts_dirs/daily_builds/intel=
_bebop/esmf/lib/libO/Linux.intel.64.mpich3.default -L/home/svasquez/pro=
j4/lib -L/blues/gpfs/home/software/spack-0.10.1/opt/spack/linux-centos7=
-x86_64/gcc-4.8.5/intel-17.0.3-gbgtimncxmczihdqphudp4l3gye5fqmq/compile=
rs_and_libraries_2017.3.191/linux/compiler/lib/intel64_lin/
ESMF_CXXLINKRPATHS: -Wl,-rpath,/lcrc/project/ESMF/scripts_dirs/daily_bu=
ilds/intel_bebop/esmf/lib/libO/Linux.intel.64.mpich3.default  -Wl,-rpat=
h,/home/svasquez/proj4/lib -Wl,-rpath,/blues/gpfs/home/software/spack-0=
.10.1/opt/spack/linux-centos7-x86_64/gcc-4.8.5/intel-17.0.3-gbgtimncxmc=
zihdqphudp4l3gye5fqmq/compilers_and_libraries_2017.3.191/linux/compiler=
/lib/intel64_lin/
ESMF_CXXLINKLIBS:  -lmpifort -lifport -lifcoremt -limf -lsvml -lm -lipg=
o -liomp5 -lintlc -lpthread -lsvml -lgcc -lgcc_s -lirc_s -ldl -lrt -ldl=
 -lproj
ESMF_CXXESMFLINKLIBS: -lesmf  -lmpifort -lifport -lifcoremt -limf -lsvm=
l -lm -lipgo -liomp5 -lintlc -lpthread -lsvml -lgcc -lgcc_s -lirc_s -ld=
l -lrt -ldl -lproj

Shared library build:
ESMF_SL_LIBS_TO_MAKE: libesmf
ESMF_SL_SUFFIX:       so
ESMF_SL_LIBLINKER:    mpicxx
ESMF_SL_LIBOPTS:       -pthread -shared  -qopenmp
ESMF_SL_LIBLIBS:     =20

ESMF Tracing linker options:
ESMF_TRACE_LDPRELOAD=3D/lcrc/project/ESMF/scripts_dirs/daily_builds/int=
el_bebop/esmf/lib/libO/Linux.intel.64.mpich3.default/libesmftrace_prelo=
ad.so
ESMF_TRACE_STATICLINKOPTS=3D-static -Wl,--wrap=3Dc_esmftrace_notify_wra=
ppers -Wl,--wrap=3Dc_esmftrace_isinitialized -Wl,--wrap=3Dwrite -Wl,--w=
rap=3Dwritev -Wl,--wrap=3Dpwrite -Wl,--wrap=3Dread -Wl,--wrap=3Dopen -W=
l,--wrap=3DMPI_Allgather -Wl,--wrap=3DMPI_Allgatherv -Wl,--wrap=3DMPI_A=
llreduce -Wl,--wrap=3DMPI_Alltoall -Wl,--wrap=3DMPI_Alltoallv -Wl,--wra=
p=3DMPI_Alltoallw -Wl,--wrap=3DMPI_Barrier -Wl,--wrap=3DMPI_Bcast -Wl,-=
-wrap=3DMPI_Gather -Wl,--wrap=3DMPI_Gatherv -Wl,--wrap=3DMPI_Recv -Wl,-=
-wrap=3DMPI_Reduce -Wl,--wrap=3DMPI_Scatter -Wl,--wrap=3DMPI_Send -Wl,-=
-wrap=3DMPI_Sendrecv -Wl,--wrap=3DMPI_Wait -Wl,--wrap=3DMPI_Waitall -Wl=
,--wrap=3DMPI_Waitany -Wl,--wrap=3DMPI_Waitsome -Wl,--wrap=3Dmpi_allgat=
her_ -Wl,--wrap=3Dmpi_allgather__ -Wl,--wrap=3Dmpi_allgatherv_ -Wl,--wr=
ap=3Dmpi_allgatherv__ -Wl,--wrap=3Dmpi_allreduce_ -Wl,--wrap=3Dmpi_allr=
educe__ -Wl,--wrap=3Dmpi_alltoall_ -Wl,--wrap=3Dmpi_alltoall__ -Wl,--wr=
ap=3Dmpi_alltoallv_ -Wl,--wrap=3Dmpi_alltoallv__ -Wl,--wrap=3Dmpi_allto=
allw_ -Wl,--wrap=3Dmpi_alltoallw__ -Wl,--wrap=3Dmpi_barrier_ -Wl,--wrap=
=3Dmpi_barrier__ -Wl,--wrap=3Dmpi_bcast_ -Wl,--wrap=3Dmpi_bcast__ -Wl,-=
-wrap=3Dmpi_exscan_ -Wl,--wrap=3Dmpi_exscan__ -Wl,--wrap=3Dmpi_gather_ =
-Wl,--wrap=3Dmpi_gather__ -Wl,--wrap=3Dmpi_gatherv_ -Wl,--wrap=3Dmpi_ga=
therv__ -Wl,--wrap=3Dmpi_recv_ -Wl,--wrap=3Dmpi_recv__ -Wl,--wrap=3Dmpi=
_reduce_ -Wl,--wrap=3Dmpi_reduce__ -Wl,--wrap=3Dmpi_reduce_scatter_ -Wl=
,--wrap=3Dmpi_reduce_scatter__ -Wl,--wrap=3Dmpi_scatter_ -Wl,--wrap=3Dm=
pi_scatter__ -Wl,--wrap=3Dmpi_scatterv_ -Wl,--wrap=3Dmpi_scatterv__ -Wl=
,--wrap=3Dmpi_scan_ -Wl,--wrap=3Dmpi_scan__ -Wl,--wrap=3Dmpi_send_ -Wl,=
--wrap=3Dmpi_send__ -Wl,--wrap=3Dmpi_wait_ -Wl,--wrap=3Dmpi_wait__ -Wl,=
--wrap=3Dmpi_waitall_ -Wl,--wrap=3Dmpi_waitall__ -Wl,--wrap=3Dmpi_waita=
ny_ -Wl,--wrap=3Dmpi_waitany__
ESMF_TRACE_STATICLINKLIBS=3D-lesmftrace_static


--------------------------------------------------------------
Compiling on Mon Mar 16 11:16:31 CDT 2020 on beboplogin2
Machine characteristics: Linux beboplogin2 3.10.0-957.21.3.el7.x86_64 #=
1 SMP Tue Jun 18 16:35:19 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
=20
Mon Mar 16 11:48:49 CDT 2020 library build -j16 ...........PASS
Mon Mar 16 11:49:41 CDT 2020 library install -j4 ..........PASS
Mon Mar 16 11:49:44 CDT 2020 library installcheck -j4 .....PASS
Mon Mar 16 11:55:36 CDT 2020 quickstart build -j4 .........PASS

|------------------------ APPs TESTS --------------------------|
Mon Mar 16 11:56:02 CDT 2020 apps build -j4 ...............PASS

|--------------------------------------------------------------|
Mon Mar 16 11:56:16 CDT 2020 ESMF_Regrid --help ...........PASS
The following is the output of ESMF_Regrid --help

 Usage: ESMF_Regrid
                       --source|-s src_grid_filename
                       --destination|-d dst_grid_filename
                       --src_var varname1[,varname2,...]
                       --dst_var  varname1[,varname2,...]
                       [--srcdatafile]
                       [--dstdatafile]
                       [--tilefile_path tile_file_path]
                       [--dst_loc center|corner]
                       [--method|-m bilinear|patch|neareststod|nearestd=
tos|conse
 rve|conserve2nd]
                       [--pole|-p all|none|teeth|<N>]
                       [--ignore_unmapped|-i]
                       [--ignore_degenerate]
                       [-r]
                       [--src_regional]
                       [--dst_regional]
                       [--check]
                       [--no_log]
                       [--help]
                       [--version]
                       [-V]
 where
 --source or -s - a required argument specifying the source grid file
               name
 --destination or -d - a required argument specifying the destination g=
rid
               file name
 --src_var  - a required argument specifying the variable names to be r=
egridded
               in the source grid file.  If more than one, separated th=
em with
               comma.
 --dst_var  - a required argument specifying the destination variable n=
ame in
               the destination grid file.  If more than one, separated =
them with
               comma.  The number of dst_vars has to be the same as the=
 number
               of src_var
 --srcdatafile - If the source grid is of type MOSAIC, the data is stor=
ed=20
               in separated files, one per tile. srcdatafile is the pre=
fix of
               the source data file.  The filename is srcdatafile.tilen=
ame.nc,
               where tilename is the tile name defined in the source gr=
id file
 --dstdatafile - If the destination grid is of type MOSAIC, the data is=
 stored
               in separated files, one per tile. dstdatafile is the pre=
fix of
               the destination data file.  The filename is srcdatafile.=
tilename.
 nc,
                where tilename is the tile name defined in the destinat=
ion grid=20
 file
 --tilefile_path - The alternative file path for the tile files and mos=
aic data=20
 files
               when either srcFile or dstFile is a GRIDSPEC MOSAIC grid=
.  The pa
 th
               can be either relative or absolute.  If it is relative, =
it is
               relative to the working directory.  When specified, the =
gridlocat
 ion
               variable defined in the Mosaic file will be ignored.
 --method or -m - an optional argument specifying which interpolation m=
ethod is
               used.  The default method is bilinear
 --pole or -p - an optional argument indicating what to do with the pol=
e.
               The default value is all
 --ignore_unmapped or -i - ignore unmapped destination points. If not s=
pecified,
               the default is to stop with an error.
 --ignore_degenerate - ignore degenerate cells in the input grids. If n=
ot specif
 ied,
               the default is to stop with an error.
 -r          - an optional argument specifying the source and destinati=
on grids
               are regional grids.  Without this argument, the grids ar=
e assumed
               to be global. This argument only applies to the GRIDSPEC=
 file
 --src_regional   - an optional argument specifying the source grid is =
regional.
               Without this argument, the src grids is assumed to be gl=
obal. Thi
 s=20
               argument only applies to the GRIDSPEC file
 --dst_regional   - an optional argument specifying the destination gri=
d is regi
 onal
               Without this argument, the dst grids is assumed to be gl=
obal.
               This argument only applies to the GRIDSPEC file
 --check    - Check the regridded fields by comparing the values with
              a synthetic field calculated based on its coordinates.=20
              The mean relative error between the destination field=20
              and synthetic field is computed.  The synthetic value is =
calculate
 d as=20
              data(i,j,k,l)=3D2.0+(k-1)+2*(l-1)+cos(lat(i,j))**2*cos(2*=
lon(i,j)),=20
 assuming
              it is a 2D grid=20
 --no_log    - Turn off the ESMF error log.
 --help     - Print this help message and exit.
 --version  - Print ESMF version and license information and exit.
 -V        - Print ESMF version number and exit.
=20
 For questions, comments, or feature requests please send email to:
 esmf_support@cgd.ucar.edu
=20
 Visit http://www.earthsystemmodeling.org/ to find out more about the
 Earth System Modeling Framework.
=20



|--------------------------------------------------------------|
Mon Mar 16 11:56:17 CDT 2020 ESMF_Regrid --version ........PASS
The following is the output of ESMF_Regrid --version

   ESMF_VERSION_STRING:       8.1.0 beta snapshot
   ESMF_VERSION_MAJOR:                   8
   ESMF_VERSION_MINOR:                   1
   ESMF_VERSION_REVISION:                0
   ESMF_VERSION_PATCHLEVEL:              0
   ESMF_VERSION_PUBLIC:        F
   ESMF_VERSION_BETASNAPSHOT:  T
=20
 Earth System Modeling Framework
=20
 Copyright (c) 2002-2020 University Corporation for Atmospheric Researc=
h,
 Massachusetts Institute of Technology, Geophysical Fluid Dynamics Labo=
ratory,
 University of Michigan, National Centers for Environmental Prediction,
 Los Alamos National Laboratory, Argonne National Laboratory,
 NASA Goddard Space Flight Center.
 All rights reserved.
=20
 Permission is hereby granted, free of charge, to any person obtaining =
a copy
 of this software and associated documentation files (the 'Software'), =
to
 deal with the Software without restriction, including without limitati=
on the
 rights to use, copy, modify, merge, publish, distribute, sublicense, a=
nd/or
 sell copies of the Software, and to permit persons to whom the Softwar=
e is
 furnished to do so, subject to the following conditions:
    1. Redistributions of source code must retain the above copyright n=
otice,
       this list of conditions and the following disclaimers.
    2. Redistributions in binary form must reproduce the above copyrigh=
t
       notice, this list of conditions and the following disclaimers in=
 the
       documentation and/or other materials provided with the distribut=
ion.
    3. Neither the names of the organizations developing this software,=
 nor
       the names of its contributors may be used to endorse or promote =
products
       derived from this Software without specific prior written permis=
sion.
=20
 THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRES=
S OR
 IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILIT=
Y,
 FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHAL=
L THE
 CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR =
OTHER
 LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISIN=
G
 FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DE=
ALINGS
 WITH THE SOFTWARE.



|--------------------------------------------------------------|
Mon Mar 16 11:56:18 CDT 2020 ESMF_Regrid -V ...............PASS
The following is the output of ESMF_Regrid -V

   ESMF_VERSION_STRING:       8.1.0 beta snapshot



|--------------------------------------------------------------|
Mon Mar 16 11:56:18 CDT 2020 ESMF_Info --help .............PASS
The following is the output of ESMF_Info --help=20

 ESMF_Info: Print information about the ESMF installation.
 Options:
   --help        Display this information and exit.
   --version     Display ESMF version and license information and exit.
   -V            Display ESMF version string and exit.
=20



|--------------------------------------------------------------|
Mon Mar 16 11:56:19 CDT 2020 ESMF_Info --version ..........PASS
The following is the output of ESMF_Info --version=20

   ESMF_VERSION_STRING:       8.1.0 beta snapshot
   ESMF_VERSION_MAJOR:                   8
   ESMF_VERSION_MINOR:                   1
   ESMF_VERSION_REVISION:                0
   ESMF_VERSION_PATCHLEVEL:              0
   ESMF_VERSION_PUBLIC:        F
   ESMF_VERSION_BETASNAPSHOT:  T
=20
 Earth System Modeling Framework
=20
 Copyright (c) 2002-2020 University Corporation for Atmospheric Researc=
h,
 Massachusetts Institute of Technology, Geophysical Fluid Dynamics Labo=
ratory,
 University of Michigan, National Centers for Environmental Prediction,
 Los Alamos National Laboratory, Argonne National Laboratory,
 NASA Goddard Space Flight Center.
 All rights reserved.
=20
 Permission is hereby granted, free of charge, to any person obtaining =
a copy
 of this software and associated documentation files (the 'Software'), =
to
 deal with the Software without restriction, including without limitati=
on the
 rights to use, copy, modify, merge, publish, distribute, sublicense, a=
nd/or
 sell copies of the Software, and to permit persons to whom the Softwar=
e is
 furnished to do so, subject to the following conditions:
    1. Redistributions of source code must retain the above copyright n=
otice,
       this list of conditions and the following disclaimers.
    2. Redistributions in binary form must reproduce the above copyrigh=
t
       notice, this list of conditions and the following disclaimers in=
 the
       documentation and/or other materials provided with the distribut=
ion.
    3. Neither the names of the organizations developing this software,=
 nor
       the names of its contributors may be used to endorse or promote =
products
       derived from this Software without specific prior written permis=
sion.
=20
 THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRES=
S OR
 IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILIT=
Y,
 FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHAL=
L THE
 CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR =
OTHER
 LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISIN=
G
 FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DE=
ALINGS
 WITH THE SOFTWARE.



|--------------------------------------------------------------|
Mon Mar 16 11:56:20 CDT 2020 ESMF_Info -V .................PASS
The following is the output of ESMF_Info -V=20

   ESMF_VERSION_STRING:       8.1.0 beta snapshot



|--------------------------------------------------------------|
Mon Mar 16 11:56:21 CDT 2020 ESMF_InfoC --help ............PASS
The following is the output of ESMF_InfoC --help

ESMF_InfoC: Print information about the ESMF installation.
Options:
  --help        Display this information and exit.
  --version     Display ESMF version and license information and exit.
  -V            Display ESMF version string and exit.




|--------------------------------------------------------------|
Mon Mar 16 11:56:21 CDT 2020 ESMF_InfoC --version .........PASS
The following is the output of ESMF_InfoC --version

   ESMF_VERSION_STRING:       8.1.0 beta snapshot
   ESMF_VERSION_MAJOR:                   8
   ESMF_VERSION_MINOR:                   1
   ESMF_VERSION_REVISION:                0
   ESMF_VERSION_PATCHLEVEL:              0
   ESMF_VERSION_PUBLIC:        F
   ESMF_VERSION_BETASNAPSHOT:  T
=20
 Earth System Modeling Framework
=20
 Copyright (c) 2002-2020 University Corporation for Atmospheric Researc=
h,
 Massachusetts Institute of Technology, Geophysical Fluid Dynamics Labo=
ratory,
 University of Michigan, National Centers for Environmental Prediction,
 Los Alamos National Laboratory, Argonne National Laboratory,
 NASA Goddard Space Flight Center.
 All rights reserved.
=20
 Permission is hereby granted, free of charge, to any person obtaining =
a copy
 of this software and associated documentation files (the 'Software'), =
to
 deal with the Software without restriction, including without limitati=
on the
 rights to use, copy, modify, merge, publish, distribute, sublicense, a=
nd/or
 sell copies of the Software, and to permit persons to whom the Softwar=
e is
 furnished to do so, subject to the following conditions:
    1. Redistributions of source code must retain the above copyright n=
otice,
       this list of conditions and the following disclaimers.
    2. Redistributions in binary form must reproduce the above copyrigh=
t
       notice, this list of conditions and the following disclaimers in=
 the
       documentation and/or other materials provided with the distribut=
ion.
    3. Neither the names of the organizations developing this software,=
 nor
       the names of its contributors may be used to endorse or promote =
products
       derived from this Software without specific prior written permis=
sion.
=20
 THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRES=
S OR
 IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILIT=
Y,
 FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHAL=
L THE
 CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR =
OTHER
 LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISIN=
G
 FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DE=
ALINGS
 WITH THE SOFTWARE.



|--------------------------------------------------------------|
Mon Mar 16 11:56:22 CDT 2020 ESMF_InfoC -V ................PASS
The following is the output of ESMF_InfoC -V

   ESMF_VERSION_STRING:       8.1.0 beta snapshot



|--------------------------------------------------------------|
Mon Mar 16 11:56:23 CDT 2020 ESMF_RegridWeightGen --help ..PASS
The following is the output of ESMF_RegridWeightGen --help

 Usage: ESMF_RegridWeightGen --source|-s src_grid_filename
                            --destination|-d dst_grid_filename
                       --weight|-w out_weight_file=20
                       [--method|-m bilinear|patch|neareststod|nearestd=
tos|conse
 rve|conserve2nd]
                       [--pole|-p all|none|teeth|<N>]
                       [--line_type|-l cartesian|greatcircle]
                       [--norm_type dstarea|fracarea]
                       [--extrap_method none|neareststod|nearestidavg|c=
reep]
                       [--extrap_num_src_pnts <N>]
                       [--extrap_dist_exponent <P>]
                       [--extrap_num_levels <L>]
                       [--ignore_unmapped|-i]
                       [--ignore_degenerate]
                       [-r]
                       [--src_regional]
                       [--dst_regional]
                       [--64bit_offset]
                       [--netcdf4]
                       [--weight_only]
                       [--src_missingvalue src_var_name]
                       [--dst_missingvalue dst_var_name]
                       [--src_coordinates lon_var_name,lat_var_name]
                       [--dst_coordinates lon_var_name,lat_var_name]
                       [--user_areas]
                       [--src_loc center|corner]
                       [--dst_loc center|corner]
                       [--tilefile_path tile_file_path]
                       [--no_log]
                       [--check]
                       [--help]
                       [--version]
                       [-V]
 where
 --source or -s - a required argument specifying the source grid file
                  name
 --destination or -d - a required argument specifying the destination g=
rid
                       file name
 --weight or -w - a required argument specifying the output regridding =
weight
                  file name
 --method or -m - an optional argument specifying which interpolation m=
ethod is
                  used.  The default method is bilinear.
 --pole or -p - an optional argument indicating what to do with the pol=
e.
                  The default value is all.
 --line_type or -l - an optional argument indicating the type of path
                      lines (e.g. cell edges) follow on a spherical
                     surface. The default value depends on the regrid
                     method. For non-conservative methods the default i=
s
                     cartesian. For conservative methods the default is=
 greatcir
 cle.
 --norm_type - an optional argument indicating the type of normalizatio=
n to
               do when generating conserative weights. The default valu=
e is dsta
 rea.
 --extrap_method - an optional argument specifying which extrapolation =
method is
                  used.  The default method is none.
 --extrap_num_src_pnts - an optional argument specifying how many sourc=
e points=20
 should
                 be used when the extrapolation method is nearestidavg.=
 The defa
 ult is 8.
 --extrap_dist_exponent - an optional argument specifying the exponent =
that the=20
 distance should
                 be raised to when the extrapolation method is nearesti=
davg. The
  default is 2.0.
 --extrap_num_levels - an optional argument specifying how many levels =
should
                 be filled for level based extrapolation methods (e.g. =
creep).
 --ignore_unmapped or -i - ignore unmapped destination points. If not s=
pecified,
                           the default is to stop with an error.
 --ignore_degenerate - ignore degenerate cells in the input grids. If n=
ot specif
 ied,
                           the default is to stop with an error.
 -r         - an optional argument specifying the source and destinatio=
n grids
              are regional grids.  Without this argument, the grids are=
 assumed
              to be global
 --src_regional   - an optional argument specifying the source grid is =
regional.
              Without this argument, the src grids is assumed to be glo=
bal.
 --dst_regional   - an optional argument specifying the destination gri=
d is regi
 onal
              Without this argument, the dst grids is assumed to be glo=
bal.
 --64bit_offset  - an optional argument specifying the output weight fi=
le is in
              NetCDF 64-bit offset format.  This option only works with=
 NetCDF l
 ibrary
              version 3.6 and above
 --netcdf4  - an optional argument specifying the output weight file is=
 in
              the NetCDF4 format. This option only works with NetCDF li=
brary
              version 4.1 and above
 --weight_only  - an Optional argument specifying the output weight fil=
e only co
 ntains
              the weights and the source and destination grid's indices=
.
 --src_missingvalue  - an optional argument used when the src file type=
 is GRIDS
 PEC
              or UGRID. It defines the variable name whose 'missing_val=
ue' or
              '_FillValue' attribute will be used to construct the mask=
 for the=20
 source
              grid. Without this argument,a GRIDSPEC file or a UGRID fi=
le is not
  masked.
 --dst_missingvalue  - an optional argument used when the destination f=
ile type=20
 is
              GRIDSPEC or UGRID. It defines the variable name whose 'mi=
ssing_val
 ue' or
              '_FillValue' attribute will be used to construct the mask=
 for the=20
 destination
              grid. Without this argument,a GRIDSPEC file or a UGRID fi=
le is not
  masked.
 --src_coordinates  - an optional argument used when the source grid ty=
pe is GRI
 DSPEC.
              It defines the longitude and latitude variable names sepa=
rated by=20
 comma,
              in case there are multiple coordinate variables defined i=
n the fil
 e
 --dst_coordinates  - an optional argument used when the destination gr=
id type i
 s GRIDSPEC.
              It defines the longitude and latitude variable names sepa=
rated by=20
 comma,
              in case there are multiple coordinate variables defined i=
n the fil
 e
 --user_areas  - an optional argument specifying that the conservation =
is adjust
 ed to
              hold for the user areas provided in the grid files.  If n=
ot specif
 ied,
              then the conservation will hold for the ESMF calculated (=
great cir
 cle)
              areas.  Whichever areas the conservation holds for are ou=
tput to t
 he
              weight file.
 --src_loc   - an optional argument specifying which location is used t=
o do the=20
 regridding
             The location can be either 'center' or 'corner'.  Currentl=
y, this a
 rgument
             is only required when the source grid file is an unstructu=
red grid=20
 defined
             in UGRID or ESMF format and the regridding method is non-c=
onservati
 ve. For =20
             all other cases, the default location is 'center'.
 --dst_loc   - an optional argument specifying which location is used t=
o do the=20
 regridding
             The location can be either 'center' or 'corner'.  Currentl=
y, this a
 rgument
             is 'center'.  Currently, this argument will only be used w=
hen the
             is only required when the destination grid file is an unst=
ructured=20
 grid defined
             in UGRID or ESMF format and the regridding method is non-c=
onservati
 ve. For =20
             all other cases, the default location is 'center'.
 --tilefile_path - the alternative file path for the tile files when th=
e grid fi
 le type is
             MOSAIC.
 --no_log    - Turn off the ESMF logs.
 --check    - Check that the generated weights produce reasonable regri=
dded fiel
 ds.  This
              is done by calling ESMF_FieldRegrid() on an analytic sour=
ce field=20
 using the weights
              generated by this application.  The mean relative error b=
etween th
 e destination
              and analytic field is computed, as well as the relative e=
rror betw
 een the mass
              of the source and destination fields in the conservative =
case.
 --help     - Print this help message and exit.
 --version  - Print ESMF version and license information and exit.
 -V        - Print ESMF version number and exit.
=20
 For questions, comments, or feature requests please send email to:
 esmf_support@cgd.ucar.edu
=20
 Visit http://www.earthsystemmodeling.org/ to find out more about the
 Earth System Modeling Framework.
=20



|--------------------------------------------------------------|
Mon Mar 16 11:56:23 CDT 2020 ESMF_RegridWeightGen --version PASS
The following is the output of ESMF_RegridWeightGen --version

   ESMF_VERSION_STRING:       8.1.0 beta snapshot
   ESMF_VERSION_MAJOR:                   8
   ESMF_VERSION_MINOR:                   1
   ESMF_VERSION_REVISION:                0
   ESMF_VERSION_PATCHLEVEL:              0
   ESMF_VERSION_PUBLIC:        F
   ESMF_VERSION_BETASNAPSHOT:  T
=20
 Earth System Modeling Framework
=20
 Copyright (c) 2002-2020 University Corporation for Atmospheric Researc=
h,
 Massachusetts Institute of Technology, Geophysical Fluid Dynamics Labo=
ratory,
 University of Michigan, National Centers for Environmental Prediction,
 Los Alamos National Laboratory, Argonne National Laboratory,
 NASA Goddard Space Flight Center.
 All rights reserved.
=20
 Permission is hereby granted, free of charge, to any person obtaining =
a copy
 of this software and associated documentation files (the 'Software'), =
to
 deal with the Software without restriction, including without limitati=
on the
 rights to use, copy, modify, merge, publish, distribute, sublicense, a=
nd/or
 sell copies of the Software, and to permit persons to whom the Softwar=
e is
 furnished to do so, subject to the following conditions:
    1. Redistributions of source code must retain the above copyright n=
otice,
       this list of conditions and the following disclaimers.
    2. Redistributions in binary form must reproduce the above copyrigh=
t
       notice, this list of conditions and the following disclaimers in=
 the
       documentation and/or other materials provided with the distribut=
ion.
    3. Neither the names of the organizations developing this software,=
 nor
       the names of its contributors may be used to endorse or promote =
products
       derived from this Software without specific prior written permis=
sion.
=20
 THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRES=
S OR
 IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILIT=
Y,
 FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHAL=
L THE
 CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR =
OTHER
 LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISIN=
G
 FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DE=
ALINGS
 WITH THE SOFTWARE.



|--------------------------------------------------------------|
Mon Mar 16 11:56:24 CDT 2020 ESMF_RegridWeightGen -V ......PASS
The following is the output of ESMF_RegridWeightGen -V

   ESMF_VERSION_STRING:       8.1.0 beta snapshot



|--------------------------------------------------------------|
Mon Mar 16 11:56:25 CDT 2020 ESMF_Scrip2Unstruct --help ...PASS
The following is the output of ESMF_Scrip2Unstruct --help

ESMF_Scrip2Unstruct: Convert an unstructured grid file in SCRIP format =
into either a ESMF unstructured file or a UGRID file format.
Usage: ESMF_Scrip2Unstruct [--help] [--version] [-V] inputfile outputfi=
le dualflag [fileformat]
    [--help]        Display this information and exit.
    [--version]     Display ESMF version and license information and ex=
it.
    [-V]            Display ESMF version string and exit.
    inputfile       input grid filename=20
    outputfile      output filename=20
    dualflag        1 to generate a dual mesh, 0 for non-dual mesh
    [fileformat]    Either ESMF or UGRID, the default is ESMF




|--------------------------------------------------------------|
Mon Mar 16 11:56:25 CDT 2020 ESMF_Scrip2Unstruct --version PASS
The following is the output of ESMF_Scrip2Unstruct --version

   ESMF_VERSION_STRING:       8.1.0 beta snapshot
   ESMF_VERSION_MAJOR:                   8
   ESMF_VERSION_MINOR:                   1
   ESMF_VERSION_REVISION:                0
   ESMF_VERSION_PATCHLEVEL:              0
   ESMF_VERSION_PUBLIC:        F
   ESMF_VERSION_BETASNAPSHOT:  T
=20
 Earth System Modeling Framework
=20
 Copyright (c) 2002-2020 University Corporation for Atmospheric Researc=
h,
 Massachusetts Institute of Technology, Geophysical Fluid Dynamics Labo=
ratory,
 University of Michigan, National Centers for Environmental Prediction,
 Los Alamos National Laboratory, Argonne National Laboratory,
 NASA Goddard Space Flight Center.
 All rights reserved.
=20
 Permission is hereby granted, free of charge, to any person obtaining =
a copy
 of this software and associated documentation files (the 'Software'), =
to
 deal with the Software without restriction, including without limitati=
on the
 rights to use, copy, modify, merge, publish, distribute, sublicense, a=
nd/or
 sell copies of the Software, and to permit persons to whom the Softwar=
e is
 furnished to do so, subject to the following conditions:
    1. Redistributions of source code must retain the above copyright n=
otice,
       this list of conditions and the following disclaimers.
    2. Redistributions in binary form must reproduce the above copyrigh=
t
       notice, this list of conditions and the following disclaimers in=
 the
       documentation and/or other materials provided with the distribut=
ion.
    3. Neither the names of the organizations developing this software,=
 nor
       the names of its contributors may be used to endorse or promote =
products
       derived from this Software without specific prior written permis=
sion.
=20
 THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRES=
S OR
 IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILIT=
Y,
 FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHAL=
L THE
 CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR =
OTHER
 LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISIN=
G
 FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DE=
ALINGS
 WITH THE SOFTWARE.



|--------------------------------------------------------------|
Mon Mar 16 11:56:26 CDT 2020 ESMF_Scrip2Unstruct -V .......PASS
The following is the output of ESMF_Scrip2Unstruct -V

   ESMF_VERSION_STRING:       8.1.0 beta snapshot



|--------------------------------------------------------------|
Mon Mar 16 11:56:27 CDT 2020 ESMF_WebServController --help PASS
The following is the output of ESMF_WebServController --help

ESMF_WebServController: Run a Process Controller that provides access t=
o an ESMF Web Service enabled Component.
Usage: ESMF_WebServController [--help] [--version] [-V] procCtrlPort re=
gistrarHost registrarPort
    [--help]        Display this information and exit.
    [--version]     Display ESMF version and license information and ex=
it.
    [-V]            Display ESMF version string and exit.
    procCtrlPort    Port num for Process Controller listener.
    registrarHost   Host name on which Registrar is running.
    registrarPort   Port num on which Registrar is listening.
    runScriptDir    Directory containing run script.
    runScriptFile   File name of run script.




|--------------------------------------------------------------|
Mon Mar 16 11:56:27 CDT 2020 ESMF_WebServController --version PASS
The following is the output of ESMF_WebServController --version

   ESMF_VERSION_STRING:       8.1.0 beta snapshot
   ESMF_VERSION_MAJOR:                   8
   ESMF_VERSION_MINOR:                   1
   ESMF_VERSION_REVISION:                0
   ESMF_VERSION_PATCHLEVEL:              0
   ESMF_VERSION_PUBLIC:        F
   ESMF_VERSION_BETASNAPSHOT:  T
=20
 Earth System Modeling Framework
=20
 Copyright (c) 2002-2020 University Corporation for Atmospheric Researc=
h,
 Massachusetts Institute of Technology, Geophysical Fluid Dynamics Labo=
ratory,
 University of Michigan, National Centers for Environmental Prediction,
 Los Alamos National Laboratory, Argonne National Laboratory,
 NASA Goddard Space Flight Center.
 All rights reserved.
=20
 Permission is hereby granted, free of charge, to any person obtaining =
a copy
 of this software and associated documentation files (the 'Software'), =
to
 deal with the Software without restriction, including without limitati=
on the
 rights to use, copy, modify, merge, publish, distribute, sublicense, a=
nd/or
 sell copies of the Software, and to permit persons to whom the Softwar=
e is
 furnished to do so, subject to the following conditions:
    1. Redistributions of source code must retain the above copyright n=
otice,
       this list of conditions and the following disclaimers.
    2. Redistributions in binary form must reproduce the above copyrigh=
t
       notice, this list of conditions and the following disclaimers in=
 the
       documentation and/or other materials provided with the distribut=
ion.
    3. Neither the names of the organizations developing this software,=
 nor
       the names of its contributors may be used to endorse or promote =
products
       derived from this Software without specific prior written permis=
sion.
=20
 THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRES=
S OR
 IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILIT=
Y,
 FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHAL=
L THE
 CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR =
OTHER
 LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISIN=
G
 FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DE=
ALINGS
 WITH THE SOFTWARE.



|--------------------------------------------------------------|
Mon Mar 16 11:56:27 CDT 2020 ESMF_WebServController -V ....PASS
The following is the output of ESMF_WebServController -V

   ESMF_VERSION_STRING:       8.1.0 beta snapshot




Ran 18 applications tests, 18 passed and 0 failed.

|----------------------- SYSTEM TESTS -------------------------|
Mon Mar 16 12:01:15 CDT 2020 build_system_tests -j4 .......PASS
Mon Mar 16 12:04:23 CDT 2020 run_system_tests .............PASS


The following system tests passed:


PASS: mpich3/O: src/system_tests/ESMF_ArrayBundleRedist/ESMF_ArrayBundl=
eRedistSTest.F90
PASS: mpich3/O: src/system_tests/ESMF_ArrayBundleSparseMatMul/ESMF_Arra=
yBundleSparseMatMulSTest.F90
PASS: mpich3/O: src/system_tests/ESMF_ArrayRedist/ESMF_ArrayRedistSTest=
.F90
PASS: mpich3/O: src/system_tests/ESMF_ArrayRedist3D/ESMF_ArrayRedist3DS=
Test.F90
PASS: mpich3/O: src/system_tests/ESMF_ArrayRedistOpenACC/ESMF_ArrayRedi=
stOpenACCSTest.F90
PASS: mpich3/O: src/system_tests/ESMF_ArrayRedistOpenMP/ESMF_ArrayRedis=
tOpenMPSTest.F90
PASS: mpich3/O: src/system_tests/ESMF_ArrayScatterGather/ESMF_ArrayScat=
terGatherSTest.F90
PASS: mpich3/O: src/system_tests/ESMF_ArraySharedDeSSI/ESMF_ArrayShared=
DeSSISTest.F90
PASS: mpich3/O: src/system_tests/ESMF_ArraySparseMatMul/ESMF_ArraySpars=
eMatMulSTest.F90
PASS: mpich3/O: src/system_tests/ESMF_Attribute/ESMF_AttributeSTest.F90
PASS: mpich3/O: src/system_tests/ESMF_AttributeCIM/ESMF_AttributeCIMSTe=
st.F90
PASS: mpich3/O: src/system_tests/ESMF_CompCreate/ESMF_CompCreateSTest.F=
90
PASS: mpich3/O: src/system_tests/ESMF_CompFortranAndC/ESMF_CompFortranA=
ndCSTest.F90
PASS: mpich3/O: src/system_tests/ESMF_ComplianceChecker/ESMF_Compliance=
CheckerSTest.F90
PASS: mpich3/O: src/system_tests/ESMF_ConcurrentComponent/ESMF_Concurre=
ntCompSTest.F90
PASS: mpich3/O: src/system_tests/ESMF_ConcurrentEnsemble/ESMF_Concurren=
tEnsembleSTest.F90
PASS: mpich3/O: src/system_tests/ESMF_DirectCoupling/ESMF_DirectCouplin=
gSTest.F90
PASS: mpich3/O: src/system_tests/ESMF_FieldBundleLSRedistArb2Arb/ESMF_F=
ieldBundleLSRedistArb2ArbSTest.F90
PASS: mpich3/O: src/system_tests/ESMF_FieldBundleLSRedistArb2ArbUngrdDi=
m/ESMF_FieldBundleLSRedistArb2ArbUngrdDimSTest.F90
PASS: mpich3/O: src/system_tests/ESMF_FieldBundleRedistArb2Arb/ESMF_Fie=
ldBundleRedistArb2ArbSTest.F90
PASS: mpich3/O: src/system_tests/ESMF_FieldBundleRedistBlk2Arb/ESMF_Fie=
ldBundleRedistBlk2ArbSTest.F90
PASS: mpich3/O: src/system_tests/ESMF_FieldBundleRedistBlk2Blk/ESMF_Fie=
ldBundleRedistBlk2BlkSTest.F90
PASS: mpich3/O: src/system_tests/ESMF_FieldBundleSMM/ESMF_FieldBundleSM=
MSTest.F90
PASS: mpich3/O: src/system_tests/ESMF_FieldBundleSMMPacked/ESMF_FieldBu=
ndleSMMPackedSTest.F90
PASS: mpich3/O: src/system_tests/ESMF_FieldConcurrentComp/ESMF_FieldCon=
CompSTest.F90
PASS: mpich3/O: src/system_tests/ESMF_FieldLSRedistArb2Arb/ESMF_FieldLS=
RedistArb2ArbSTest.F90
PASS: mpich3/O: src/system_tests/ESMF_FieldLSRedistArb2ArbUngrdDim/ESMF=
_FieldLSRedistArb2ArbUngrdDimSTest.F90
PASS: mpich3/O: src/system_tests/ESMF_FieldLSSMM/ESMF_FieldLSSMMSTest.F=
90
PASS: mpich3/O: src/system_tests/ESMF_FieldMeshSMM/ESMF_FieldMeshSMMSTe=
st.F90
PASS: mpich3/O: src/system_tests/ESMF_FieldRedist/ESMF_FieldRedistSTest=
.F90
PASS: mpich3/O: src/system_tests/ESMF_FieldRedistArb2Arb/ESMF_FieldRedi=
stArb2ArbSTest.F90
PASS: mpich3/O: src/system_tests/ESMF_FieldRedistBlk2Arb/ESMF_FieldRedi=
stBlk2ArbSTest.F90
PASS: mpich3/O: src/system_tests/ESMF_FieldRedistBlk2Blk/ESMF_FieldRedi=
stBlk2BlkSTest.F90
PASS: mpich3/O: src/system_tests/ESMF_FieldRegrid/ESMF_FieldRegridSTest=
.F90
PASS: mpich3/O: src/system_tests/ESMF_FieldRegridDisjoint/ESMF_FieldReg=
ridDisjointSTest.F90
PASS: mpich3/O: src/system_tests/ESMF_FieldRegridMesh/ESMF_FieldRegridM=
eshSTest.F90
PASS: mpich3/O: src/system_tests/ESMF_FieldRegridMeshToMesh/ESMF_FieldR=
egridMeshToMeshSTest.F90
PASS: mpich3/O: src/system_tests/ESMF_FieldRegridOverlap/ESMF_FieldRegr=
idOverlapSTest.F90
PASS: mpich3/O: src/system_tests/ESMF_FieldSparseMatMul/ESMF_FieldSpars=
eMatMulSTest.F90
PASS: mpich3/O: src/system_tests/ESMF_RecursiveComponent/ESMF_Recursive=
ComponentSTest.F90
PASS: mpich3/O: src/system_tests/ESMF_SequentialEnsemble/ESMF_Sequentia=
lEnsembleSTest.F90
PASS: mpich3/O: src/system_tests/ESMF_Trace/ESMF_TraceSTest.F90
PASS: mpich3/O: src/system_tests/ESMF_TransferGrid/ESMF_TransferGridSTe=
st.F90
PASS: mpich3/O: src/system_tests/ESMF_TransferMesh/ESMF_TransferMeshSTe=
st.F90
PASS: mpich3/O: src/system_tests/ESMF_XGridConcurrent/ESMF_XGridConcurr=
entSTest.F90
PASS: mpich3/O: src/system_tests/ESMF_XGridSerial/ESMF_XGridSerialSTest=
.F90




The stdout files for the system_tests can be found at:
/lcrc/project/ESMF/scripts_dirs/daily_builds/intel_bebop/esmf/test/test=
O/Linux.intel.64.mpich3.default


Found 46 multi-processor system tests, 46 passed and 0 failed.



|------------------------- EXAMPLES ---------------------------|
Mon Mar 16 12:13:07 CDT 2020 build_examples -j4 ...........PASS
Mon Mar 16 12:21:38 CDT 2020 run_examples .................PASS


The following examples passed:


PASS: mpich3/O: src/Infrastructure/Array/examples/ESMF_ArrayArbHaloEx.F=
90
PASS: mpich3/O: src/Infrastructure/Array/examples/ESMF_ArrayCommNBEx.F9=
0
PASS: mpich3/O: src/Infrastructure/Array/examples/ESMF_ArrayEx.F90
PASS: mpich3/O: src/Infrastructure/Array/examples/ESMF_ArrayFarrayEx.F9=
0
PASS: mpich3/O: src/Infrastructure/Array/examples/ESMF_ArrayFarrayHaloE=
x.F90
PASS: mpich3/O: src/Infrastructure/Array/examples/ESMF_ArrayHaloEx.F90
PASS: mpich3/O: src/Infrastructure/Array/examples/ESMF_ArrayLarrayEx.F9=
0
PASS: mpich3/O: src/Infrastructure/Array/examples/ESMF_ArrayRedistEx.F9=
0
PASS: mpich3/O: src/Infrastructure/Array/examples/ESMF_ArrayScatterGath=
erArbEx.F90
PASS: mpich3/O: src/Infrastructure/Array/examples/ESMF_ArrayScatterGath=
erEx.F90
PASS: mpich3/O: src/Infrastructure/Array/examples/ESMF_ArraySparseMatMu=
lEx.F90
PASS: mpich3/O: src/Infrastructure/ArrayBundle/examples/ESMF_ArrayBundl=
eEx.F90
PASS: mpich3/O: src/Infrastructure/ArrayBundle/examples/ESMF_ArrayBundl=
eHaloEx.F90
PASS: mpich3/O: src/Infrastructure/ArraySpec/examples/ESMF_ArraySpecEx.=
F90
PASS: mpich3/O: src/Infrastructure/Config/examples/ESMF_ConfigOverviewE=
x.F90
PASS: mpich3/O: src/Infrastructure/DELayout/examples/ESMF_DELayoutEx.F9=
0
PASS: mpich3/O: src/Infrastructure/DistGrid/examples/ESMF_DistGridEx.F9=
0
PASS: mpich3/O: src/Infrastructure/Field/examples/ESMF_FieldArbGridEx.F=
90
PASS: mpich3/O: src/Infrastructure/Field/examples/ESMF_FieldCommEx.F90
PASS: mpich3/O: src/Infrastructure/Field/examples/ESMF_FieldCreateEx.F9=
0
PASS: mpich3/O: src/Infrastructure/Field/examples/ESMF_FieldEx.F90
PASS: mpich3/O: src/Infrastructure/Field/examples/ESMF_FieldHaloEx.F90
PASS: mpich3/O: src/Infrastructure/Field/examples/ESMF_FieldMeshRegridE=
x.F90
PASS: mpich3/O: src/Infrastructure/Field/examples/ESMF_FieldRedistEx.F9=
0
PASS: mpich3/O: src/Infrastructure/Field/examples/ESMF_FieldRegridEx.F9=
0
PASS: mpich3/O: src/Infrastructure/Field/examples/ESMF_FieldRegridMaskE=
x.F90
PASS: mpich3/O: src/Infrastructure/Field/examples/ESMF_FieldRepDimEx.F9=
0
PASS: mpich3/O: src/Infrastructure/Field/examples/ESMF_FieldSMMEx.F90
PASS: mpich3/O: src/Infrastructure/Field/examples/ESMF_FieldSphereRegri=
dEx.F90
PASS: mpich3/O: src/Infrastructure/FieldBundle/examples/ESMF_FieldBundl=
eCreateEx.F90
PASS: mpich3/O: src/Infrastructure/FieldBundle/examples/ESMF_FieldBundl=
eHaloEx.F90
PASS: mpich3/O: src/Infrastructure/FieldBundle/examples/ESMF_FieldBundl=
eRedistEx.F90
PASS: mpich3/O: src/Infrastructure/FieldBundle/examples/ESMF_FieldBundl=
eSMMEx.F90
PASS: mpich3/O: src/Infrastructure/Grid/examples/ESMF_GridCreateRegFrom=
DGEx.F90
PASS: mpich3/O: src/Infrastructure/Grid/examples/ESMF_GridUsageEx.F90
PASS: mpich3/O: src/Infrastructure/LocStream/examples/ESMF_LocStreamEx.=
F90
PASS: mpich3/O: src/Infrastructure/LogErr/examples/ESMF_LogErrEx.F90
PASS: mpich3/O: src/Infrastructure/Mesh/examples/ESMF_MeshEx.F90
PASS: mpich3/O: src/Infrastructure/Route/examples/ESMF_RHandleBitForBit=
Ex.F90
PASS: mpich3/O: src/Infrastructure/Route/examples/ESMF_RHandleDynamicMa=
skingEx.F90
PASS: mpich3/O: src/Infrastructure/Route/examples/ESMF_RHandleFromFileE=
x.F90
PASS: mpich3/O: src/Infrastructure/Route/examples/ESMF_RHandleFromRHand=
leEx.F90
PASS: mpich3/O: src/Infrastructure/Route/examples/ESMF_RHandleReusabili=
tyEx.F90
PASS: mpich3/O: src/Infrastructure/TimeMgr/examples/ESMF_AlarmEx.F90
PASS: mpich3/O: src/Infrastructure/TimeMgr/examples/ESMF_CalendarEx.F90
PASS: mpich3/O: src/Infrastructure/TimeMgr/examples/ESMF_ClockEx.F90
PASS: mpich3/O: src/Infrastructure/TimeMgr/examples/ESMF_TimeEx.F90
PASS: mpich3/O: src/Infrastructure/TimeMgr/examples/ESMF_TimeIntervalEx=
.F90
PASS: mpich3/O: src/Infrastructure/Trace/examples/ESMF_TraceEx.F90
PASS: mpich3/O: src/Infrastructure/Trace/examples/ESMF_TraceUserEx.F90
PASS: mpich3/O: src/Infrastructure/VM/examples/ESMF_VMAllFullReduceEx.F=
90
PASS: mpich3/O: src/Infrastructure/VM/examples/ESMF_VMComponentEx.F90
PASS: mpich3/O: src/Infrastructure/VM/examples/ESMF_VMDefaultBasicsEx.F=
90
PASS: mpich3/O: src/Infrastructure/VM/examples/ESMF_VMGetMPICommunicato=
rEx.F90
PASS: mpich3/O: src/Infrastructure/VM/examples/ESMF_VMHigherRankDataEx.=
F90
PASS: mpich3/O: src/Infrastructure/VM/examples/ESMF_VMScatterVMGatherEx=
.F90
PASS: mpich3/O: src/Infrastructure/VM/examples/ESMF_VMSendVMRecvEx.F90
PASS: mpich3/O: src/Infrastructure/VM/examples/ESMF_VMUserMpiCommEx.F90
PASS: mpich3/O: src/Infrastructure/VM/examples/ESMF_VMUserMpiCommMultiE=
x.F90
PASS: mpich3/O: src/Infrastructure/VM/examples/ESMF_VMUserMpiEx.F90
PASS: mpich3/O: src/Infrastructure/XGrid/examples/ESMF_XGridEx.F90
PASS: mpich3/O: src/Infrastructure/XGrid/examples/ESMF_XGridSparseMatEx=
.F90
PASS: mpich3/O: src/Superstructure/AttachMethods/examples/ESMF_AttachMe=
thodsEx.F90
PASS: mpich3/O: src/Superstructure/AttributeAPI/examples/ESMF_AttReadCu=
stCplCompEx.F90
PASS: mpich3/O: src/Superstructure/AttributeAPI/examples/ESMF_AttReadFi=
eldEx.F90
PASS: mpich3/O: src/Superstructure/AttributeAPI/examples/ESMF_AttReadGr=
idCompEx.F90
PASS: mpich3/O: src/Superstructure/AttributeAPI/examples/ESMF_Attribute=
CIMEx.F90
PASS: mpich3/O: src/Superstructure/AttributeAPI/examples/ESMF_Attribute=
CustPackEx.F90
PASS: mpich3/O: src/Superstructure/AttributeAPI/examples/ESMF_Attribute=
Ex.F90
PASS: mpich3/O: src/Superstructure/AttributeAPI/examples/ESMF_Attribute=
InternalInfoEx.F90
PASS: mpich3/O: src/Superstructure/AttributeAPI/examples/ESMF_Attribute=
PackageEx.F90
PASS: mpich3/O: src/Superstructure/AttributeAPI/examples/ESMF_Attribute=
UpdateEx.F90
PASS: mpich3/O: src/Superstructure/Component/examples/ESMF_AppMainEx.F9=
0
PASS: mpich3/O: src/Superstructure/Component/examples/ESMF_CompTunnelEx=
.F90
PASS: mpich3/O: src/Superstructure/Component/examples/ESMF_CplEx.F90
PASS: mpich3/O: src/Superstructure/Component/examples/ESMF_GCompEx.F90
PASS: mpich3/O: src/Superstructure/Component/examples/ESMF_InternalStat=
eEx.F90
PASS: mpich3/O: src/Superstructure/Component/examples/ESMF_InternalStat=
eModEx.F90
PASS: mpich3/O: src/Superstructure/Component/examples/ESMF_SCompEx.F90
PASS: mpich3/O: src/Superstructure/State/examples/ESMF_StateEx.F90
PASS: mpich3/O: src/Superstructure/State/examples/ESMF_StateReadWriteEx=
.F90
PASS: mpich3/O: src/Superstructure/State/examples/ESMF_StateReconcileEx=
.F90
PASS: mpich3/O: src/Superstructure/WebServices/examples/ESMF_WebService=
sEx.F90
PASS: mpich3/O: src/addon/NUOPC/examples/ESMF_NUOPCAtmModelEx.F90
PASS: mpich3/O: src/addon/NUOPC/examples/ESMF_NUOPCBasicModelEx.F90




The stdout files for the examples can be found at:
/lcrc/project/ESMF/scripts_dirs/daily_builds/intel_bebop/esmf/examples/=
examplesO/Linux.intel.64.mpich3.default


Found 85 multi-processor examples, 85 passed and 0 failed.



|-------------------- EXHAUSTIVE UNIT TESTS -------------------|
Mon Mar 16 12:40:52 CDT 2020 build_unit_tests -j4 .........PASS
Mon Mar 16 12:55:41 CDT 2020 run_unit_tests ...............PASS




The unit tests in the following files all pass:

PASS: mpich3/O: src/Infrastructure/Array/tests/ESMC_ArrayUTest.C
PASS: mpich3/O: src/Infrastructure/Array/tests/ESMF_ArrayArbIdxSMMUTest=
.F90
PASS: mpich3/O: src/Infrastructure/Array/tests/ESMF_ArrayCreateGetUTest=
.F90
PASS: mpich3/O: src/Infrastructure/Array/tests/ESMF_ArrayDataUTest.F90
PASS: mpich3/O: src/Infrastructure/Array/tests/ESMF_ArrayGatherUTest.F9=
0
PASS: mpich3/O: src/Infrastructure/Array/tests/ESMF_ArrayHaloUTest.F90
PASS: mpich3/O: src/Infrastructure/Array/tests/ESMF_ArrayIOUTest.F90
PASS: mpich3/O: src/Infrastructure/Array/tests/ESMF_ArrayRedistPerfUTes=
t.F90
PASS: mpich3/O: src/Infrastructure/Array/tests/ESMF_ArrayRedistUTest.F9=
0
PASS: mpich3/O: src/Infrastructure/Array/tests/ESMF_ArraySMMFromFileUTe=
st.F90
PASS: mpich3/O: src/Infrastructure/Array/tests/ESMF_ArraySMMUTest.F90
PASS: mpich3/O: src/Infrastructure/Array/tests/ESMF_ArrayScatterUTest.F=
90
PASS: mpich3/O: src/Infrastructure/ArrayBundle/tests/ESMF_ArrayBundleCr=
eateUTest.F90
PASS: mpich3/O: src/Infrastructure/ArrayBundle/tests/ESMF_ArrayBundleIO=
UTest.F90
PASS: mpich3/O: src/Infrastructure/ArrayBundle/tests/ESMF_ArrayBundleRe=
distUTest.F90
PASS: mpich3/O: src/Infrastructure/ArraySpec/tests/ESMC_ArraySpecUTest.=
C
PASS: mpich3/O: src/Infrastructure/ArraySpec/tests/ESMF_ArraySpecUTest.=
F90
PASS: mpich3/O: src/Infrastructure/Base/tests/ESMC_BaseUTest.C
PASS: mpich3/O: src/Infrastructure/Base/tests/ESMF_BaseUTest.F90
PASS: mpich3/O: src/Infrastructure/Config/tests/ESMC_ConfigUTest.C
PASS: mpich3/O: src/Infrastructure/Config/tests/ESMF_ConfigUTest.F90
PASS: mpich3/O: src/Infrastructure/Container/tests/ESMF_ContainerUTest.=
F90
PASS: mpich3/O: src/Infrastructure/DELayout/tests/ESMF_DELayoutUTest.F9=
0
PASS: mpich3/O: src/Infrastructure/DELayout/tests/ESMF_DELayoutWorkQueu=
eUTest.F90
PASS: mpich3/O: src/Infrastructure/DistGrid/tests/ESMC_DistGridUTest.C
PASS: mpich3/O: src/Infrastructure/DistGrid/tests/ESMF_DistGridCreateGe=
tUTest.F90
PASS: mpich3/O: src/Infrastructure/Field/tests/ESMC_FieldGridGridRegrid=
CsrvUTest.C
PASS: mpich3/O: src/Infrastructure/Field/tests/ESMC_FieldGridGridRegrid=
UTest.C
PASS: mpich3/O: src/Infrastructure/Field/tests/ESMC_FieldGridRegrid2UTe=
st.C
PASS: mpich3/O: src/Infrastructure/Field/tests/ESMC_FieldGridRegridCsrv=
2UTest.C
PASS: mpich3/O: src/Infrastructure/Field/tests/ESMC_FieldGridRegridCsrv=
UTest.C
PASS: mpich3/O: src/Infrastructure/Field/tests/ESMC_FieldGridRegridParU=
Test.C
PASS: mpich3/O: src/Infrastructure/Field/tests/ESMC_FieldGridRegridUTes=
t.C
PASS: mpich3/O: src/Infrastructure/Field/tests/ESMC_FieldRegridCsrvUTes=
t.C
PASS: mpich3/O: src/Infrastructure/Field/tests/ESMC_FieldRegridUTest.C
PASS: mpich3/O: src/Infrastructure/Field/tests/ESMC_FieldSMMFromFileUTe=
st.C
PASS: mpich3/O: src/Infrastructure/Field/tests/ESMC_FieldUTest.C
PASS: mpich3/O: src/Infrastructure/Field/tests/ESMF_FieldArbGridUTest.F=
90
PASS: mpich3/O: src/Infrastructure/Field/tests/ESMF_FieldCreateGetUTest=
.F90
PASS: mpich3/O: src/Infrastructure/Field/tests/ESMF_FieldGatherUTest.F9=
0
PASS: mpich3/O: src/Infrastructure/Field/tests/ESMF_FieldHaloUTest.F90
PASS: mpich3/O: src/Infrastructure/Field/tests/ESMF_FieldIOUTest.F90
PASS: mpich3/O: src/Infrastructure/Field/tests/ESMF_FieldLSSMMUTest.F90
PASS: mpich3/O: src/Infrastructure/Field/tests/ESMF_FieldRedistArbUTest=
.F90
PASS: mpich3/O: src/Infrastructure/Field/tests/ESMF_FieldRedistUTest.F9=
0
PASS: mpich3/O: src/Infrastructure/Field/tests/ESMF_FieldRegridCSUTest.=
F90
PASS: mpich3/O: src/Infrastructure/Field/tests/ESMF_FieldRegridCsrv2ndU=
Test.F90
PASS: mpich3/O: src/Infrastructure/Field/tests/ESMF_FieldRegridCsrvUTes=
t.F90
PASS: mpich3/O: src/Infrastructure/Field/tests/ESMF_FieldRegridUTest.F9=
0
PASS: mpich3/O: src/Infrastructure/Field/tests/ESMF_FieldRegridXGSMMUTe=
st.F90
PASS: mpich3/O: src/Infrastructure/Field/tests/ESMF_FieldRegridXGUTest.=
F90
PASS: mpich3/O: src/Infrastructure/Field/tests/ESMF_FieldSMMFromFileUTe=
st.F90
PASS: mpich3/O: src/Infrastructure/Field/tests/ESMF_FieldSMMUTest.F90
PASS: mpich3/O: src/Infrastructure/Field/tests/ESMF_FieldUTest.F90
PASS: mpich3/O: src/Infrastructure/FieldBundle/tests/ESMF_FieldBundleCr=
GetUTest.F90
PASS: mpich3/O: src/Infrastructure/FieldBundle/tests/ESMF_FieldBundleIO=
UTest.F90
PASS: mpich3/O: src/Infrastructure/FieldBundle/tests/ESMF_FieldBundleRe=
distUTest.F90
PASS: mpich3/O: src/Infrastructure/FieldBundle/tests/ESMF_FieldBundleRe=
gridUTest.F90
PASS: mpich3/O: src/Infrastructure/FieldBundle/tests/ESMF_FieldBundleSM=
MUTest.F90
PASS: mpich3/O: src/Infrastructure/FieldBundle/tests/ESMF_FieldBundleUT=
est.F90
PASS: mpich3/O: src/Infrastructure/Grid/tests/ESMC_GridUTest.C
PASS: mpich3/O: src/Infrastructure/Grid/tests/ESMF_GridArbitraryUTest.F=
90
PASS: mpich3/O: src/Infrastructure/Grid/tests/ESMF_GridCoordUTest.F90
PASS: mpich3/O: src/Infrastructure/Grid/tests/ESMF_GridCreateUTest.F90
PASS: mpich3/O: src/Infrastructure/Grid/tests/ESMF_GridItemUTest.F90
PASS: mpich3/O: src/Infrastructure/GridUtil/tests/ESMF_GridToMeshUTest.=
F90
PASS: mpich3/O: src/Infrastructure/IO/tests/ESMCI_IO_NetCDFUTest.C
PASS: mpich3/O: src/Infrastructure/IO/tests/ESMCI_IO_PIOUTest.C
PASS: mpich3/O: src/Infrastructure/IO/tests/ESMC_IO_InqUTest.C
PASS: mpich3/O: src/Infrastructure/IO/tests/ESMF_IOUTest.F90
PASS: mpich3/O: src/Infrastructure/IO/tests/ESMF_IO_PIOUTest.F90
PASS: mpich3/O: src/Infrastructure/IO/tests/ESMF_IO_YAMLUTest.F90
PASS: mpich3/O: src/Infrastructure/LocStream/tests/ESMC_LocStreamUTest.=
C
PASS: mpich3/O: src/Infrastructure/LocStream/tests/ESMF_LocStreamUTest.=
F90
PASS: mpich3/O: src/Infrastructure/LocalArray/tests/ESMF_LocalArrayData=
UTest.F90
PASS: mpich3/O: src/Infrastructure/LocalArray/tests/ESMF_LocalArrayUTes=
t.F90
PASS: mpich3/O: src/Infrastructure/LogErr/tests/ESMC_LogErrPerfUTest.C
PASS: mpich3/O: src/Infrastructure/LogErr/tests/ESMC_LogErrUTest.C
PASS: mpich3/O: src/Infrastructure/LogErr/tests/ESMF_LogErrPerfUTest.F9=
0
PASS: mpich3/O: src/Infrastructure/LogErr/tests/ESMF_LogErrUTest.F90
PASS: mpich3/O: src/Infrastructure/Mesh/tests/ESMC_MBMesh_BilinearParUT=
est.C
PASS: mpich3/O: src/Infrastructure/Mesh/tests/ESMC_MBMesh_BilinearSingl=
eElemUTest.C
PASS: mpich3/O: src/Infrastructure/Mesh/tests/ESMC_MBMesh_BilinearUTest=
.C
PASS: mpich3/O: src/Infrastructure/Mesh/tests/ESMC_MBMesh_CreateParUTes=
t.C
PASS: mpich3/O: src/Infrastructure/Mesh/tests/ESMC_MBMesh_CreateUTest.C
PASS: mpich3/O: src/Infrastructure/Mesh/tests/ESMC_MBMesh_SearchUTest.C
PASS: mpich3/O: src/Infrastructure/Mesh/tests/ESMC_MBMesh_SerializeUTes=
t.C
PASS: mpich3/O: src/Infrastructure/Mesh/tests/ESMC_MBMesh_UtilParUTest.=
C
PASS: mpich3/O: src/Infrastructure/Mesh/tests/ESMC_MBMesh_UtilUTest.C
PASS: mpich3/O: src/Infrastructure/Mesh/tests/ESMC_MeshMOABUTest.C
PASS: mpich3/O: src/Infrastructure/Mesh/tests/ESMC_MeshUTest.C
PASS: mpich3/O: src/Infrastructure/Mesh/tests/ESMC_MeshVTKUTest.C
PASS: mpich3/O: src/Infrastructure/Mesh/tests/ESMC_Proj4UTest.C
PASS: mpich3/O: src/Infrastructure/Mesh/tests/ESMF_MeshOpUTest.F90
PASS: mpich3/O: src/Infrastructure/Mesh/tests/ESMF_MeshUTest.F90
PASS: mpich3/O: src/Infrastructure/PointList/tests/ESMF_PointListUTest.=
F90
PASS: mpich3/O: src/Infrastructure/Route/tests/ESMF_RouteHandleAdvanced=
UTest.F90
PASS: mpich3/O: src/Infrastructure/Route/tests/ESMF_RouteHandleUTest.F9=
0
PASS: mpich3/O: src/Infrastructure/TimeMgr/tests/ESMC_CalendarUTest.C
PASS: mpich3/O: src/Infrastructure/TimeMgr/tests/ESMC_ClockUTest.C
PASS: mpich3/O: src/Infrastructure/TimeMgr/tests/ESMC_TimeIntervalUTest=
.C
PASS: mpich3/O: src/Infrastructure/TimeMgr/tests/ESMC_TimeUTest.C
PASS: mpich3/O: src/Infrastructure/TimeMgr/tests/ESMF_AlarmUTest.F90
PASS: mpich3/O: src/Infrastructure/TimeMgr/tests/ESMF_CalRangeUTest.F90
PASS: mpich3/O: src/Infrastructure/TimeMgr/tests/ESMF_CalendarUTest.F90
PASS: mpich3/O: src/Infrastructure/TimeMgr/tests/ESMF_ClockUTest.F90
PASS: mpich3/O: src/Infrastructure/TimeMgr/tests/ESMF_TimeIntervalUTest=
.F90
PASS: mpich3/O: src/Infrastructure/TimeMgr/tests/ESMF_TimeUTest.F90
PASS: mpich3/O: src/Infrastructure/Trace/tests/ESMC_TraceRegionUTest.C
PASS: mpich3/O: src/Infrastructure/Trace/tests/ESMF_ProfileUTest.F90
PASS: mpich3/O: src/Infrastructure/Trace/tests/ESMF_TraceClkMonoSyncUTe=
st.F90
PASS: mpich3/O: src/Infrastructure/Trace/tests/ESMF_TraceClkMonoUTest.F=
90
PASS: mpich3/O: src/Infrastructure/Trace/tests/ESMF_TraceIOUTest.F90
PASS: mpich3/O: src/Infrastructure/Trace/tests/ESMF_TraceMPIUTest.F90
PASS: mpich3/O: src/Infrastructure/Trace/tests/ESMF_TraceUTest.F90
PASS: mpich3/O: src/Infrastructure/Util/tests/ESMF_FortranWordsizeUTest=
.F90
PASS: mpich3/O: src/Infrastructure/Util/tests/ESMF_InitMacrosUTest.F90
PASS: mpich3/O: src/Infrastructure/Util/tests/ESMF_TypeKindGetUTest.F90
PASS: mpich3/O: src/Infrastructure/Util/tests/ESMF_UtilUTest.F90
PASS: mpich3/O: src/Infrastructure/VM/tests/ESMC_VMUTest.C
PASS: mpich3/O: src/Infrastructure/VM/tests/ESMF_VMAccUTest.F90
PASS: mpich3/O: src/Infrastructure/VM/tests/ESMF_VMAllGatherUTest.F90
PASS: mpich3/O: src/Infrastructure/VM/tests/ESMF_VMAllGatherVUTest.F90
PASS: mpich3/O: src/Infrastructure/VM/tests/ESMF_VMAllToAllUTest.F90
PASS: mpich3/O: src/Infrastructure/VM/tests/ESMF_VMAllToAllVUTest.F90
PASS: mpich3/O: src/Infrastructure/VM/tests/ESMF_VMBarrierUTest.F90
PASS: mpich3/O: src/Infrastructure/VM/tests/ESMF_VMBroadcastUTest.F90
PASS: mpich3/O: src/Infrastructure/VM/tests/ESMF_VMComponentUTest.F90
PASS: mpich3/O: src/Infrastructure/VM/tests/ESMF_VMGatherUTest.F90
PASS: mpich3/O: src/Infrastructure/VM/tests/ESMF_VMOpenMPUTest.F90
PASS: mpich3/O: src/Infrastructure/VM/tests/ESMF_VMScatterUTest.F90
PASS: mpich3/O: src/Infrastructure/VM/tests/ESMF_VMSendNbVMRecvNbUTest.=
F90
PASS: mpich3/O: src/Infrastructure/VM/tests/ESMF_VMSendRecvNbUTest.F90
PASS: mpich3/O: src/Infrastructure/VM/tests/ESMF_VMSendRecvUTest.F90
PASS: mpich3/O: src/Infrastructure/VM/tests/ESMF_VMSendVMRecvUTest.F90
PASS: mpich3/O: src/Infrastructure/VM/tests/ESMF_VMUTest.F90
PASS: mpich3/O: src/Infrastructure/VM/tests/ESMF_VMUserMpiInitUTest.F90
PASS: mpich3/O: src/Infrastructure/XGrid/tests/ESMC_XGridUTest.C
PASS: mpich3/O: src/Infrastructure/XGrid/tests/ESMF_XGridMaskingUTest.F=
90
PASS: mpich3/O: src/Infrastructure/XGrid/tests/ESMF_XGridUTest.F90
PASS: mpich3/O: src/Superstructure/AttributeAPI/tests/ESMF_AttInternalG=
ridUTest.F90
PASS: mpich3/O: src/Superstructure/AttributeAPI/tests/ESMF_AttPackABund=
leUTest.F90
PASS: mpich3/O: src/Superstructure/AttributeAPI/tests/ESMF_AttPackArray=
UTest.F90
PASS: mpich3/O: src/Superstructure/AttributeAPI/tests/ESMF_AttPackCplCo=
mpUTest.F90
PASS: mpich3/O: src/Superstructure/AttributeAPI/tests/ESMF_AttPackDistG=
ridUTest.F90
PASS: mpich3/O: src/Superstructure/AttributeAPI/tests/ESMF_AttPackFBund=
leUTest.F90
PASS: mpich3/O: src/Superstructure/AttributeAPI/tests/ESMF_AttPackField=
UTest.F90
PASS: mpich3/O: src/Superstructure/AttributeAPI/tests/ESMF_AttPackGridC=
ompUTest.F90
PASS: mpich3/O: src/Superstructure/AttributeAPI/tests/ESMF_AttPackGridU=
Test.F90
PASS: mpich3/O: src/Superstructure/AttributeAPI/tests/ESMF_AttPackLocSt=
reamUTest.F90
PASS: mpich3/O: src/Superstructure/AttributeAPI/tests/ESMF_AttPackSciCo=
mpUTest.F90
PASS: mpich3/O: src/Superstructure/AttributeAPI/tests/ESMF_AttPackState=
UTest.F90
PASS: mpich3/O: src/Superstructure/AttributeAPI/tests/ESMF_AttReadCplCo=
mpUTest.F90
PASS: mpich3/O: src/Superstructure/AttributeAPI/tests/ESMF_AttReadField=
UTest.F90
PASS: mpich3/O: src/Superstructure/AttributeAPI/tests/ESMF_AttReadGridC=
ompUTest.F90
PASS: mpich3/O: src/Superstructure/AttributeAPI/tests/ESMF_AttributeABu=
ndleUTest.F90
PASS: mpich3/O: src/Superstructure/AttributeAPI/tests/ESMF_AttributeArr=
ayUTest.F90
PASS: mpich3/O: src/Superstructure/AttributeAPI/tests/ESMF_AttributeAut=
oLinkUTest.F90
PASS: mpich3/O: src/Superstructure/AttributeAPI/tests/ESMF_AttributeCpl=
CompUTest.F90
PASS: mpich3/O: src/Superstructure/AttributeAPI/tests/ESMF_AttributeDis=
tGridUTest.F90
PASS: mpich3/O: src/Superstructure/AttributeAPI/tests/ESMF_AttributeFBu=
ndleUTest.F90
PASS: mpich3/O: src/Superstructure/AttributeAPI/tests/ESMF_AttributeFie=
ldUTest.F90
PASS: mpich3/O: src/Superstructure/AttributeAPI/tests/ESMF_AttributeGri=
dCompUTest.F90
PASS: mpich3/O: src/Superstructure/AttributeAPI/tests/ESMF_AttributeGri=
dUTest.F90
PASS: mpich3/O: src/Superstructure/AttributeAPI/tests/ESMF_AttributeJSO=
NUTest.F90
PASS: mpich3/O: src/Superstructure/AttributeAPI/tests/ESMF_AttributeLoc=
StreamUTest.F90
PASS: mpich3/O: src/Superstructure/AttributeAPI/tests/ESMF_AttributeSci=
CompUTest.F90
PASS: mpich3/O: src/Superstructure/AttributeAPI/tests/ESMF_AttributeSta=
teUTest.F90
PASS: mpich3/O: src/Superstructure/AttributeAPI/tests/ESMF_AttributeUpd=
ateCIMRespPartyUTest.F90
PASS: mpich3/O: src/Superstructure/AttributeAPI/tests/ESMF_AttributeUpd=
ateClosedLoopTreesUTest.F90
PASS: mpich3/O: src/Superstructure/AttributeAPI/tests/ESMF_AttributeUpd=
ateComponentUTest.F90
PASS: mpich3/O: src/Superstructure/AttributeAPI/tests/ESMF_AttributeUpd=
ateContainerStressUTest.F90
PASS: mpich3/O: src/Superstructure/AttributeAPI/tests/ESMF_AttributeUpd=
ateMultiReconcileUTest.F90
PASS: mpich3/O: src/Superstructure/AttributeAPI/tests/ESMF_AttributeUpd=
ateReconcileUTest.F90
PASS: mpich3/O: src/Superstructure/AttributeAPI/tests/ESMF_AttributeUpd=
ateRemoveOnlyUTest.F90
PASS: mpich3/O: src/Superstructure/AttributeAPI/tests/ESMF_AttributeUpd=
ateUTest.F90
PASS: mpich3/O: src/Superstructure/AttributeAPI/tests/ESMF_AttributeWri=
teInternalUTest.F90
PASS: mpich3/O: src/Superstructure/AttributeAPI/tests/ESMF_AttributeXML=
UTest.F90
PASS: mpich3/O: src/Superstructure/Component/tests/ESMC_ComponentUTest.=
C
PASS: mpich3/O: src/Superstructure/Component/tests/ESMF_CompSetServUTes=
t.F90
PASS: mpich3/O: src/Superstructure/Component/tests/ESMF_CompTunnelUTest=
.F90
PASS: mpich3/O: src/Superstructure/Component/tests/ESMF_ComponentUTest.=
F90
PASS: mpich3/O: src/Superstructure/Component/tests/ESMF_CplCompCreateUT=
est.F90
PASS: mpich3/O: src/Superstructure/Component/tests/ESMF_GridCompCreateU=
Test.F90
PASS: mpich3/O: src/Superstructure/Component/tests/ESMF_SciCompCreateUT=
est.F90
PASS: mpich3/O: src/Superstructure/Component/tests/ESMF_StdCompMethodsU=
Test.F90
PASS: mpich3/O: src/Superstructure/ESMFMod/tests/ESMF_FrameworkUTest.F9=
0
PASS: mpich3/O: src/Superstructure/IOAPI/tests/ESMF_IOCompUTest.F90
PASS: mpich3/O: src/Superstructure/PreESMFMod/tests/ESMF_FileRegridUTes=
t.F90
PASS: mpich3/O: src/Superstructure/PreESMFMod/tests/ESMF_RegridWeightGe=
nUTest.F90
PASS: mpich3/O: src/Superstructure/State/tests/ESMC_StateUTest.C
PASS: mpich3/O: src/Superstructure/State/tests/ESMF_StateCreateUTest.F9=
0
PASS: mpich3/O: src/Superstructure/State/tests/ESMF_StateReadWriteUTest=
.F90
PASS: mpich3/O: src/Superstructure/State/tests/ESMF_StateReconcileUTest=
.F90
PASS: mpich3/O: src/Superstructure/State/tests/ESMF_StateUTest.F90
PASS: mpich3/O: src/addon/NUOPC/tests/ESMF_NUOPC_UTest.F90
PASS: mpich3/O: src/epilogue/tests/ESMCI_TestUTest.C
PASS: mpich3/O: src/epilogue/tests/ESMC_TestUTest.C
PASS: mpich3/O: src/epilogue/tests/ESMF_TestUTest.F90
PASS: mpich3/O: src/prologue/tests/ESMCI_ExceptionsUTest.C
PASS: mpich3/O: src/prologue/tests/ESMCI_FeatureUTest.C
PASS: mpich3/O: src/prologue/tests/ESMF_F90ArrayPtrUTest.F90
PASS: mpich3/O: src/prologue/tests/ESMF_FeatureUTest.F90
PASS: mpich3/O: src/prologue/tests/ESMF_LAPACKUTest.F90
PASS: mpich3/O: src/prologue/tests/ESMF_StringUTest.F90
PASS: mpich3/O: src/prologue/tests/ESMF_WordsizeUTest.F90


The following unit test files failed to build, failed to execute or cra=
shed during execution:

CRASHED: mpich3/O: src/Infrastructure/Field/tests/ESMF_FieldStressUTest=
.F90


The following test harness unit tests pass:
PASS: mpich3/O: ESMF_array_default_NP4UTest
PASS: mpich3/O: ESMF_field_default_NP4UTest


The log and stdout files for the unit tests can be found at:
/lcrc/project/ESMF/scripts_dirs/daily_builds/intel_bebop/esmf/test/test=
O/Linux.intel.64.mpich3.default


Found 9075 exhaustive multi-processor unit tests, 9074 passed and 1 fai=
led.



_______________________________________________________________________=
________________________


Mon Mar 16 13:00:47 CDT 2020 on beboplogin2=20

ESMF Checkout Source: https://github.com/esmf-org/esmf

Compiler and configuration information:
=20
--------------------------------------------------------------=20

Currently Loaded Modules:
  1) intel/18.0.4-443hhug
  2) openmpi/3.1.3-bebop-7wj2dww

=20

=20
Repository:
origin=09https://github.com/esmf-org/esmf (fetch)
origin=09https://github.com/esmf-org/esmf (push)
=20
ESMF_8_1_0_beta_snapshot_11
=20
=20
=20
--------------------------------------------------------------
ESMF_VERSION_STRING:    8.1.0 beta snapshot
ESMF_8_1_0_beta_snapshot_11
--------------------------------------------------------------
# On branch master
# Untracked files:
#   (use "git add <file>..." to include in what will be committed)
#
#=09queue_results
#=09src/installcheck/esmc_application
#=09src/installcheck/esmc_application.o
#=09src/installcheck/esmf_application
#=09src/installcheck/esmf_application.o
#=09tmp
nothing added to commit but untracked files present (use "git add" to t=
rack)
--------------------------------------------------------------
=20
--------------------------------------------------------------
Make version:
GNU Make 3.82
Built for x86_64-redhat-linux-gnu
Copyright (C) 2010  Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl=
.html>
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.

--------------------------------------------------------------
Fortran Compiler version:
Intel(R) Fortran Intel(R) 64 Compiler for applications running on Intel=
(R) 64, Version 18.0.5.274 Build 20180823
Copyright (C) 1985-2018 Intel Corporation.  All rights reserved.

ifort version 18.0.5

--------------------------------------------------------------
C++ Compiler version:
Intel(R) C++ Intel(R) 64 Compiler for applications running on Intel(R) =
64, Version 18.0.5.274 Build 20180823
Copyright (C) 1985-2018 Intel Corporation.  All rights reserved.

icpc version 18.0.5 (gcc version 8.1.0 compatibility)

--------------------------------------------------------------
Preprocessor version:
gcc (GCC) 8.1.0
Copyright (C) 2018 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is=
 NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURP=
OSE.

=20
--------------------------------------------------------------
 * User set ESMF environment variables *
ESMF_ABI=3D64
ESMF_BOPT=3Dg
ESMF_COMM=3Dopenmpi
ESMF_COMPILER=3Dintel
ESMF_DIR=3D/lcrc/project/ESMF/scripts_dirs/daily_builds/intel_bebop/esm=
f
ESMF_INSTALL_PREFIX=3D/lcrc/project/ESMF/scripts_dirs/daily_builds/inte=
l_bebop/esmf/../install_dir
ESMF_MPIRUN=3Dmpirun
ESMF_OS=3DLinux
ESMF_PROJ4=3Dexternal
ESMF_PROJ4_INCLUDE=3D/home/svasquez/proj4/include
ESMF_PROJ4_LIBPATH=3D/home/svasquez/proj4/lib
ESMF_SITE=3Ddefault
ESMF_TESTCOMPTUNNEL=3DOFF
ESMF_TESTEXHAUSTIVE=3DON
ESMF_TESTHARNESS_ARRAY=3DRUN_ESMF_TestHarnessArray_default
ESMF_TESTHARNESS_FIELD=3DRUN_ESMF_TestHarnessField_default
ESMF_TESTMPMD=3DOFF
ESMF_TESTWITHTHREADS=3DOFF
=20
--------------------------------------------------------------
 * ESMF environment variables *
ESMF_DIR: /lcrc/project/ESMF/scripts_dirs/daily_builds/intel_bebop/esmf
ESMF_OS:                Linux
ESMF_MACHINE:           x86_64
ESMF_ABI:               64
ESMF_COMPILER:          intel
ESMF_BOPT:              g
ESMF_COMM:              openmpi
ESMF_SITE:              default
ESMF_PTHREADS:          ON
ESMF_OPENMP:            ON
ESMF_OPENACC:           OFF
ESMF_CXXSTD:            11
ESMF_ARRAY_LITE:        FALSE
ESMF_NO_INTEGER_1_BYTE: TRUE
ESMF_NO_INTEGER_2_BYTE: TRUE
ESMF_FORTRANSYMBOLS:    default
ESMF_MAPPER_BUILD:      OFF
ESMF_AUTO_LIB_BUILD:    ON
ESMF_DEFER_LIB_BUILD:   ON
ESMF_SHARED_LIB_BUILD:  ON
ESMF_TRACE_LIB_BUILD:   ON
ESMF_TESTEXHAUSTIVE:    ON
ESMF_TESTCOMPTUNNEL:    OFF
ESMF_TESTWITHTHREADS:   OFF
ESMF_TESTMPMD:          OFF
ESMF_TESTSHAREDOBJ:     OFF
ESMF_TESTFORCEOPENMP:   OFF
ESMF_TESTFORCEOPENACC:  OFF
ESMF_TESTHARNESS_ARRAY: RUN_ESMF_TestHarnessArray_default
ESMF_TESTHARNESS_FIELD: RUN_ESMF_TestHarnessField_default
ESMF_MPIRUN:            mpirun
=20
--------------------------------------------------------------
 * ESMF environment variables pointing to 3rd party software *
ESMF_MOAB:               internal
ESMF_LAPACK:             internal
ESMF_ACC_SOFTWARE_STACK: none
ESMF_YAMLCPP:            internal
ESMF_PIO:                internal
ESMF_PROJ4:                external
ESMF_PROJ4_INCLUDE:        /home/svasquez/proj4/include
ESMF_PROJ4_LIBS:           -lproj
ESMF_PROJ4_LIBPATH:        /home/svasquez/proj4/lib
=20
--------------------------------------------------------------
 * ESMF environment variables for final installation *
ESMF_INSTALL_PREFIX:    /lcrc/project/ESMF/scripts_dirs/daily_builds/in=
tel_bebop/esmf/../install_dir
ESMF_INSTALL_HEADERDIR: include
ESMF_INSTALL_MODDIR:    mod/modg/Linux.intel.64.openmpi.default
ESMF_INSTALL_LIBDIR:    lib/libg/Linux.intel.64.openmpi.default
ESMF_INSTALL_BINDIR:    bin/bing/Linux.intel.64.openmpi.default
ESMF_INSTALL_DOCDIR:    doc
=20
--------------------------------------------------------------
 * ESMF Benchmark directory and parameters *
ESMF_BENCHMARK_PREFIX:         ./DEFAULTBENCHMARKDIR
ESMF_BENCHMARK_TOLERANCE:      20%
ESMF_BENCHMARK_THRESHOLD_MSEC: 500
=20
--------------------------------------------------------------
 * Other relevant environment variables *
PATH:    /blues/gpfs/software/centos7/spack/opt/spack/linux-centos7-x86=
_64/intel-18.0.4/openmpi-3.1.3-7wj2dww/bin:/blues/gpfs/software/centos7=
/spack/opt/spack/linux-centos7-x86_64/gcc-4.8.5/gcc-8.1.0-dc4tau6/bin:/=
blues/gpfs/software/centos7/spack/opt/spack/linux-centos7-x86_64/gcc-8.=
1.0/intel-18.0.4-443hhug/compilers_and_libraries_2018.5.274/linux/bin/i=
ntel64:/blues/gpfs/software/centos7/spack/opt/spack/linux-centos7-x86_6=
4/gcc-8.1.0/intel-18.0.4-443hhug/compilers_and_libraries_2018.5.274/lin=
ux/mpi/intel64/bin:/blues/gpfs/software/centos7/spack/opt/spack/linux-c=
entos7-x86_64/gcc-8.1.0/intel-18.0.4-443hhug/bin:/home/svasquez/bin:/us=
r/bin:/bin:/usr/local/sbin:/usr/sbin:/soft/lcrc/bebop/bin:/soft/lcrc/be=
bop/bin:/soft/lcrc/bebop/bin
LD_LIBRARY_PATH: /blues/gpfs/software/centos7/spack/opt/spack/linux-cen=
tos7-x86_64/intel-18.0.4/openmpi-3.1.3-7wj2dww/lib:/blues/gpfs/software=
/centos7/spack/opt/spack/linux-centos7-x86_64/gcc-4.8.5/gcc-8.1.0-dc4ta=
u6/lib64:/blues/gpfs/software/centos7/spack/opt/spack/linux-centos7-x86=
_64/gcc-4.8.5/gcc-8.1.0-dc4tau6/lib:/blues/gpfs/software/centos7/spack/=
opt/spack/linux-centos7-x86_64/gcc-8.1.0/intel-18.0.4-443hhug/compilers=
_and_libraries_2018.5.274/linux/compiler/lib/intel64:/blues/gpfs/softwa=
re/centos7/spack/opt/spack/linux-centos7-x86_64/gcc-8.1.0/intel-18.0.4-=
443hhug/compilers_and_libraries_2018.5.274/linux/compiler/lib/intel64_l=
in:/blues/gpfs/software/centos7/spack/opt/spack/linux-centos7-x86_64/gc=
c-8.1.0/intel-18.0.4-443hhug/compilers_and_libraries_2018.5.274/linux/m=
pi/intel64/lib:/blues/gpfs/software/centos7/spack/opt/spack/linux-cento=
s7-x86_64/gcc-8.1.0/intel-18.0.4-443hhug/compilers_and_libraries_2018.5=
.274/linux/mpi/mic/lib:/blues/gpfs/software/centos7/spack/opt/spack/lin=
ux-centos7-x86_64/gcc-8.1.0/intel-18.0.4-443hhug/compilers_and_librarie=
s_2018.5.274/linux/tbb/lib/intel64/gcc4.7:/blues/gpfs/software/centos7/=
spack/opt/spack/linux-centos7-x86_64/gcc-8.1.0/intel-18.0.4-443hhug/lib
=20
--------------------------------------------------------------
 * Compilers, Linkers, Flags, and Libraries *
Location of the preprocessor:      /blues/gpfs/software/centos7/spack/o=
pt/spack/linux-centos7-x86_64/gcc-4.8.5/gcc-8.1.0-dc4tau6/bin/gcc
Location of the Fortran compiler:  /blues/gpfs/software/centos7/spack/o=
pt/spack/linux-centos7-x86_64/intel-18.0.4/openmpi-3.1.3-7wj2dww/bin/mp=
ifort
Location of the Fortran linker:    /blues/gpfs/software/centos7/spack/o=
pt/spack/linux-centos7-x86_64/intel-18.0.4/openmpi-3.1.3-7wj2dww/bin/mp=
ifort
Location of the C++ compiler:      /blues/gpfs/software/centos7/spack/o=
pt/spack/linux-centos7-x86_64/intel-18.0.4/openmpi-3.1.3-7wj2dww/bin/mp=
icxx
Location of the C++ linker:        /blues/gpfs/software/centos7/spack/o=
pt/spack/linux-centos7-x86_64/intel-18.0.4/openmpi-3.1.3-7wj2dww/bin/mp=
icxx

Fortran compiler flags:
ESMF_F90COMPILER: mpifort
ESMF_F90COMPILEOPTS: -g -traceback -check arg_temp_created,bounds,forma=
t,output_conversion,stack,uninit -fPIC -assume realloc_lhs -m64 -mcmode=
l=3Dsmall -threads  -qopenmp
ESMF_F90COMPILEPATHS: -I/lcrc/project/ESMF/scripts_dirs/daily_builds/in=
tel_bebop/esmf/mod/modg/Linux.intel.64.openmpi.default -I/lcrc/project/=
ESMF/scripts_dirs/daily_builds/intel_bebop/esmf/src/include -I/home/sva=
squez/proj4/include
ESMF_F90COMPILECPPFLAGS: -DESMF_NO_INTEGER_1_BYTE -DESMF_NO_INTEGER_2_B=
YTE -DESMFVERSIONGIT=3D'ESMF_8_1_0_beta_snapshot_11' -DESMF_MOAB=3D1 -D=
ESMF_LAPACK=3D1 -DESMF_LAPACK_INTERNAL=3D1 -DESMF_NO_ACC_SOFTWARE_STACK=
=3D1 -DESMF_YAMLCPP=3D1 -DESMF_YAML=3D1 -DESMF_PIO=3D1 -DESMF_MPIIO -DE=
SMF_PROJ4=3D1 -DESMF_NO_OPENACC -DESMF_TESTEXHAUSTIVE -DESMF_BOPT_g -DS=
x86_64_small=3D1 -DESMF_OS_Linux=3D1 -DESMF_COMM=3Dopenmpi -DESMF_DIR=
=3D/lcrc/project/ESMF/scripts_dirs/daily_builds/intel_bebop/esmf
ESMF_F90COMPILEFREECPP:=20
ESMF_F90COMPILEFREENOCPP:=20
ESMF_F90COMPILEFIXCPP:=20
ESMF_F90COMPILEFIXNOCPP:=20

Fortran linker flags:
ESMF_F90LINKOPTS:   -m64 -mcmodel=3Dsmall -threads -Wl,--no-as-needed  =
-qopenmp
ESMF_F90LINKPATHS: -L/lcrc/project/ESMF/scripts_dirs/daily_builds/intel=
_bebop/esmf/lib/libg/Linux.intel.64.openmpi.default -L/home/svasquez/pr=
oj4/lib=20
ESMF_F90LINKRPATHS: -Wl,-rpath,/lcrc/project/ESMF/scripts_dirs/daily_bu=
ilds/intel_bebop/esmf/lib/libg/Linux.intel.64.openmpi.default  -Wl,-rpa=
th,/home/svasquez/proj4/lib
ESMF_F90LINKLIBS:  -lmpi_cxx -cxxlib -lrt -ldl -lproj
ESMF_F90ESMFLINKLIBS: -lesmf  -lmpi_cxx -cxxlib -lrt -ldl -lproj

C++ compiler flags:
ESMF_CXXCOMPILER: mpicxx
ESMF_CXXCOMPILEOPTS: -std=3Dc++11 -g -traceback -Wcheck -fPIC -m64 -mcm=
odel=3Dsmall -pthread  -qopenmp
ESMF_CXXCOMPILEPATHS:  -I/lcrc/project/ESMF/scripts_dirs/daily_builds/i=
ntel_bebop/esmf/src/include  -I/home/svasquez/proj4/include -I/lcrc/pro=
ject/ESMF/scripts_dirs/daily_builds/intel_bebop/esmf/src/prologue/yaml-=
cpp/include
ESMF_CXXCOMPILECPPFLAGS: -DESMF_NO_INTEGER_1_BYTE -DESMF_NO_INTEGER_2_B=
YTE -DESMFVERSIONGIT=3D'ESMF_8_1_0_beta_snapshot_11' -DESMF_MOAB=3D1 -D=
ESMF_LAPACK=3D1 -DESMF_LAPACK_INTERNAL=3D1 -DESMF_NO_ACC_SOFTWARE_STACK=
=3D1 -DESMF_YAMLCPP=3D1 -DESMF_YAML=3D1 -DESMF_PIO=3D1 -DESMF_MPIIO -DE=
SMF_PROJ4=3D1 -DESMF_NO_OPENACC -DESMF_TESTEXHAUSTIVE -DESMF_BOPT_g -DS=
x86_64_small=3D1 -DESMF_OS_Linux=3D1 -DESMF_COMM=3Dopenmpi -DESMF_DIR=
=3D/lcrc/project/ESMF/scripts_dirs/daily_builds/intel_bebop/esmf -D__SD=
IR__=3D'' -DESMF_CXXSTD=3D11 -DESMF_NO_SIGUSR2

C++ linker flags:
ESMF_CXXLINKOPTS:   -m64 -mcmodel=3Dsmall -pthread -Wl,--no-as-needed  =
-qopenmp
ESMF_CXXLINKPATHS: -L/lcrc/project/ESMF/scripts_dirs/daily_builds/intel=
_bebop/esmf/lib/libg/Linux.intel.64.openmpi.default -L/home/svasquez/pr=
oj4/lib -L/blues/gpfs/software/centos7/spack/opt/spack/linux-centos7-x8=
6_64/gcc-8.1.0/intel-18.0.4-443hhug/compilers_and_libraries_2018.5.274/=
linux/compiler/lib/intel64_lin/
ESMF_CXXLINKRPATHS: -Wl,-rpath,/lcrc/project/ESMF/scripts_dirs/daily_bu=
ilds/intel_bebop/esmf/lib/libg/Linux.intel.64.openmpi.default  -Wl,-rpa=
th,/home/svasquez/proj4/lib -Wl,-rpath,/blues/gpfs/software/centos7/spa=
ck/opt/spack/linux-centos7-x86_64/gcc-8.1.0/intel-18.0.4-443hhug/compil=
ers_and_libraries_2018.5.274/linux/compiler/lib/intel64_lin/
ESMF_CXXLINKLIBS:  -lmpi_mpifh -lifport -lifcoremt -limf -lsvml -lm -li=
pgo -liomp5 -lintlc -lpthread -lsvml -ldl -lgcc -lgcc_s -lirc_s -ldl -l=
rt -ldl -lproj
ESMF_CXXESMFLINKLIBS: -lesmf  -lmpi_mpifh -lifport -lifcoremt -limf -ls=
vml -lm -lipgo -liomp5 -lintlc -lpthread -lsvml -ldl -lgcc -lgcc_s -lir=
c_s -ldl -lrt -ldl -lproj

Shared library build:
ESMF_SL_LIBS_TO_MAKE: libesmf
ESMF_SL_SUFFIX:       so
ESMF_SL_LIBLINKER:    mpicxx
ESMF_SL_LIBOPTS:       -pthread -shared  -qopenmp
ESMF_SL_LIBLIBS:     =20

ESMF Tracing linker options:
ESMF_TRACE_LDPRELOAD=3D/lcrc/project/ESMF/scripts_dirs/daily_builds/int=
el_bebop/esmf/lib/libg/Linux.intel.64.openmpi.default/libesmftrace_prel=
oad.so
ESMF_TRACE_STATICLINKOPTS=3D-static -Wl,--wrap=3Dc_esmftrace_notify_wra=
ppers -Wl,--wrap=3Dc_esmftrace_isinitialized -Wl,--wrap=3Dwrite -Wl,--w=
rap=3Dwritev -Wl,--wrap=3Dpwrite -Wl,--wrap=3Dread -Wl,--wrap=3Dopen -W=
l,--wrap=3DMPI_Allgather -Wl,--wrap=3DMPI_Allgatherv -Wl,--wrap=3DMPI_A=
llreduce -Wl,--wrap=3DMPI_Alltoall -Wl,--wrap=3DMPI_Alltoallv -Wl,--wra=
p=3DMPI_Alltoallw -Wl,--wrap=3DMPI_Barrier -Wl,--wrap=3DMPI_Bcast -Wl,-=
-wrap=3DMPI_Gather -Wl,--wrap=3DMPI_Gatherv -Wl,--wrap=3DMPI_Recv -Wl,-=
-wrap=3DMPI_Reduce -Wl,--wrap=3DMPI_Scatter -Wl,--wrap=3DMPI_Send -Wl,-=
-wrap=3DMPI_Sendrecv -Wl,--wrap=3DMPI_Wait -Wl,--wrap=3DMPI_Waitall -Wl=
,--wrap=3DMPI_Waitany -Wl,--wrap=3DMPI_Waitsome -Wl,--wrap=3Dmpi_allgat=
her_ -Wl,--wrap=3Dmpi_allgather__ -Wl,--wrap=3Dmpi_allgatherv_ -Wl,--wr=
ap=3Dmpi_allgatherv__ -Wl,--wrap=3Dmpi_allreduce_ -Wl,--wrap=3Dmpi_allr=
educe__ -Wl,--wrap=3Dmpi_alltoall_ -Wl,--wrap=3Dmpi_alltoall__ -Wl,--wr=
ap=3Dmpi_alltoallv_ -Wl,--wrap=3Dmpi_alltoallv__ -Wl,--wrap=3Dmpi_allto=
allw_ -Wl,--wrap=3Dmpi_alltoallw__ -Wl,--wrap=3Dmpi_barrier_ -Wl,--wrap=
=3Dmpi_barrier__ -Wl,--wrap=3Dmpi_bcast_ -Wl,--wrap=3Dmpi_bcast__ -Wl,-=
-wrap=3Dmpi_exscan_ -Wl,--wrap=3Dmpi_exscan__ -Wl,--wrap=3Dmpi_gather_ =
-Wl,--wrap=3Dmpi_gather__ -Wl,--wrap=3Dmpi_gatherv_ -Wl,--wrap=3Dmpi_ga=
therv__ -Wl,--wrap=3Dmpi_recv_ -Wl,--wrap=3Dmpi_recv__ -Wl,--wrap=3Dmpi=
_reduce_ -Wl,--wrap=3Dmpi_reduce__ -Wl,--wrap=3Dmpi_reduce_scatter_ -Wl=
,--wrap=3Dmpi_reduce_scatter__ -Wl,--wrap=3Dmpi_scatter_ -Wl,--wrap=3Dm=
pi_scatter__ -Wl,--wrap=3Dmpi_scatterv_ -Wl,--wrap=3Dmpi_scatterv__ -Wl=
,--wrap=3Dmpi_scan_ -Wl,--wrap=3Dmpi_scan__ -Wl,--wrap=3Dmpi_send_ -Wl,=
--wrap=3Dmpi_send__ -Wl,--wrap=3Dmpi_wait_ -Wl,--wrap=3Dmpi_wait__ -Wl,=
--wrap=3Dmpi_waitall_ -Wl,--wrap=3Dmpi_waitall__ -Wl,--wrap=3Dmpi_waita=
ny_ -Wl,--wrap=3Dmpi_waitany__
ESMF_TRACE_STATICLINKLIBS=3D-lesmftrace_static


--------------------------------------------------------------
Compiling on Mon Mar 16 13:01:05 CDT 2020 on beboplogin2
Machine characteristics: Linux beboplogin2 3.10.0-957.21.3.el7.x86_64 #=
1 SMP Tue Jun 18 16:35:19 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
=20
Mon Mar 16 13:30:53 CDT 2020 library build -j16 ...........PASS
Mon Mar 16 13:32:02 CDT 2020 library install -j4 ..........PASS
Mon Mar 16 13:32:05 CDT 2020 library installcheck -j4 .....PASS
Mon Mar 16 13:36:49 CDT 2020 quickstart build -j4 .........PASS

|------------------------ APPs TESTS --------------------------|
Mon Mar 16 13:37:21 CDT 2020 apps build -j4 ...............PASS

|--------------------------------------------------------------|
Mon Mar 16 13:37:52 CDT 2020 ESMF_Regrid --help ***********FAIL
The following is the output of ESMF_Regrid --help

-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0458:100489] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
*** An error occurred in MPI_Init
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0458:100486] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
[bdw-0458:100487] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0458:100488] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
srun: error: bdw-0458: tasks 0-3: Exited with exit code 1



|--------------------------------------------------------------|
Mon Mar 16 13:37:53 CDT 2020 ESMF_Regrid --version ********FAIL
The following is the output of ESMF_Regrid --version

-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0458:100504] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0458:100503] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0458:100502] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0458:100505] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
srun: error: bdw-0458: tasks 0-3: Exited with exit code 1



|--------------------------------------------------------------|
Mon Mar 16 13:37:54 CDT 2020 ESMF_Regrid -V ***************FAIL
The following is the output of ESMF_Regrid -V

-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0458:100520] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0458:100517] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0458:100519] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0458:100518] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
srun: error: bdw-0458: tasks 0-3: Exited with exit code 1



|--------------------------------------------------------------|
Mon Mar 16 13:37:55 CDT 2020 ESMF_Info --help *************FAIL
The following is the output of ESMF_Info --help=20

-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init_thread
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0458:100532] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init_thread
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0458:100533] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init_thread
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0458:100534] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init_thread
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0458:100535] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
srun: error: bdw-0458: tasks 0-3: Exited with exit code 1



|--------------------------------------------------------------|
Mon Mar 16 13:37:55 CDT 2020 ESMF_Info --version **********FAIL
The following is the output of ESMF_Info --version=20

-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init_thread
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0458:100547] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init_thread
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0458:100550] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init_thread
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0458:100549] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init_thread
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0458:100548] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
srun: error: bdw-0458: tasks 0-3: Exited with exit code 1



|--------------------------------------------------------------|
Mon Mar 16 13:37:56 CDT 2020 ESMF_Info -V *****************FAIL
The following is the output of ESMF_Info -V=20

-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init_thread
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0458:100561] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init_thread
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0458:100562] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init_thread
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0458:100563] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init_thread
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0458:100564] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
srun: error: bdw-0458: tasks 0-3: Exited with exit code 1



|--------------------------------------------------------------|
Mon Mar 16 13:37:57 CDT 2020 ESMF_InfoC --help ************FAIL
The following is the output of ESMF_InfoC --help

-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init_thread
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0458:100579] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init_thread
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0458:100578] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init_thread
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0458:100581] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init_thread
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0458:100580] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
srun: error: bdw-0458: tasks 0-3: Exited with exit code 1



|--------------------------------------------------------------|
Mon Mar 16 13:37:58 CDT 2020 ESMF_InfoC --version *********FAIL
The following is the output of ESMF_InfoC --version

-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init_thread
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0458:100593] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init_thread
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0458:100594] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init_thread
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0458:100596] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init_thread
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0458:100595] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
srun: error: bdw-0458: tasks 0-3: Exited with exit code 1



|--------------------------------------------------------------|
Mon Mar 16 13:37:59 CDT 2020 ESMF_InfoC -V ****************FAIL
The following is the output of ESMF_InfoC -V

-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init_thread
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0458:100611] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init_thread
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0458:100610] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init_thread
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0458:100608] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init_thread
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0458:100609] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
srun: error: bdw-0458: tasks 0-3: Exited with exit code 1



|--------------------------------------------------------------|
Mon Mar 16 13:38:00 CDT 2020 ESMF_RegridWeightGen --help **FAIL
The following is the output of ESMF_RegridWeightGen --help

-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0458:100625] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0458:100624] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0458:100622] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0458:100623] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
srun: error: bdw-0458: tasks 0-3: Exited with exit code 1



|--------------------------------------------------------------|
Mon Mar 16 13:38:01 CDT 2020 ESMF_RegridWeightGen --version FAIL
The following is the output of ESMF_RegridWeightGen --version

-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0458:100639] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0458:100641] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0458:100640] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0458:100638] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
srun: error: bdw-0458: tasks 0-3: Exited with exit code 1



|--------------------------------------------------------------|
Mon Mar 16 13:38:01 CDT 2020 ESMF_RegridWeightGen -V ******FAIL
The following is the output of ESMF_RegridWeightGen -V

-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0458:100656] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0458:100655] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0458:100653] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0458:100654] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
srun: error: bdw-0458: tasks 0-3: Exited with exit code 1



|--------------------------------------------------------------|
Mon Mar 16 13:38:02 CDT 2020 ESMF_Scrip2Unstruct --help ***FAIL
The following is the output of ESMF_Scrip2Unstruct --help

-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init_thread
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0458:100670] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init_thread
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0458:100669] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init_thread
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0458:100667] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init_thread
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0458:100668] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
srun: error: bdw-0458: tasks 0-3: Exited with exit code 1



|--------------------------------------------------------------|
Mon Mar 16 13:38:03 CDT 2020 ESMF_Scrip2Unstruct --version FAIL
The following is the output of ESMF_Scrip2Unstruct --version

-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init_thread
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0458:100683] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init_thread
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0458:100685] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init_thread
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0458:100684] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init_thread
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0458:100682] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
srun: error: bdw-0458: tasks 0-3: Exited with exit code 1



|--------------------------------------------------------------|
Mon Mar 16 13:38:04 CDT 2020 ESMF_Scrip2Unstruct -V *******FAIL
The following is the output of ESMF_Scrip2Unstruct -V

-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init_thread
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0458:100698] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init_thread
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0458:100697] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init_thread
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0458:100700] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init_thread
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0458:100699] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
srun: error: bdw-0458: tasks 0-3: Exited with exit code 1



|--------------------------------------------------------------|
Mon Mar 16 13:38:07 CDT 2020 ESMF_WebServController --help PASS
The following is the output of ESMF_WebServController --help

ESMF_WebServController: Run a Process Controller that provides access t=
o an ESMF Web Service enabled Component.
Usage: ESMF_WebServController [--help] [--version] [-V] procCtrlPort re=
gistrarHost registrarPort
    [--help]        Display this information and exit.
    [--version]     Display ESMF version and license information and ex=
it.
    [-V]            Display ESMF version string and exit.
    procCtrlPort    Port num for Process Controller listener.
    registrarHost   Host name on which Registrar is running.
    registrarPort   Port num on which Registrar is listening.
    runScriptDir    Directory containing run script.
    runScriptFile   File name of run script.




|--------------------------------------------------------------|
Mon Mar 16 13:38:07 CDT 2020 ESMF_WebServController --version PASS
The following is the output of ESMF_WebServController --version

   ESMF_VERSION_STRING:       8.1.0 beta snapshot
   ESMF_VERSION_MAJOR:                   8
   ESMF_VERSION_MINOR:                   1
   ESMF_VERSION_REVISION:                0
   ESMF_VERSION_PATCHLEVEL:              0
   ESMF_VERSION_PUBLIC:        F
   ESMF_VERSION_BETASNAPSHOT:  T
=20
 Earth System Modeling Framework
=20
 Copyright (c) 2002-2020 University Corporation for Atmospheric Researc=
h,
 Massachusetts Institute of Technology, Geophysical Fluid Dynamics Labo=
ratory,
 University of Michigan, National Centers for Environmental Prediction,
 Los Alamos National Laboratory, Argonne National Laboratory,
 NASA Goddard Space Flight Center.
 All rights reserved.
=20
 Permission is hereby granted, free of charge, to any person obtaining =
a copy
 of this software and associated documentation files (the 'Software'), =
to
 deal with the Software without restriction, including without limitati=
on the
 rights to use, copy, modify, merge, publish, distribute, sublicense, a=
nd/or
 sell copies of the Software, and to permit persons to whom the Softwar=
e is
 furnished to do so, subject to the following conditions:
    1. Redistributions of source code must retain the above copyright n=
otice,
       this list of conditions and the following disclaimers.
    2. Redistributions in binary form must reproduce the above copyrigh=
t
       notice, this list of conditions and the following disclaimers in=
 the
       documentation and/or other materials provided with the distribut=
ion.
    3. Neither the names of the organizations developing this software,=
 nor
       the names of its contributors may be used to endorse or promote =
products
       derived from this Software without specific prior written permis=
sion.
=20
 THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRES=
S OR
 IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILIT=
Y,
 FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHAL=
L THE
 CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR =
OTHER
 LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISIN=
G
 FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DE=
ALINGS
 WITH THE SOFTWARE.



|--------------------------------------------------------------|
Mon Mar 16 13:38:07 CDT 2020 ESMF_WebServController -V ....PASS
The following is the output of ESMF_WebServController -V

   ESMF_VERSION_STRING:       8.1.0 beta snapshot




Ran 18 applications tests, 3 passed and 15 failed.

|----------------------- SYSTEM TESTS -------------------------|
Mon Mar 16 13:43:18 CDT 2020 build_system_tests -j4 .......PASS
Mon Mar 16 13:46:25 CDT 2020 run_system_tests .............PASS


The following system tests passed:


PASS: openmpi/g: src/system_tests/ESMF_ArrayBundleRedist/ESMF_ArrayBund=
leRedistSTest.F90
PASS: openmpi/g: src/system_tests/ESMF_ArrayBundleSparseMatMul/ESMF_Arr=
ayBundleSparseMatMulSTest.F90
PASS: openmpi/g: src/system_tests/ESMF_ArrayRedist/ESMF_ArrayRedistSTes=
t.F90
PASS: openmpi/g: src/system_tests/ESMF_ArrayRedist3D/ESMF_ArrayRedist3D=
STest.F90
PASS: openmpi/g: src/system_tests/ESMF_ArrayRedistOpenACC/ESMF_ArrayRed=
istOpenACCSTest.F90
PASS: openmpi/g: src/system_tests/ESMF_ArrayRedistOpenMP/ESMF_ArrayRedi=
stOpenMPSTest.F90
PASS: openmpi/g: src/system_tests/ESMF_ArrayScatterGather/ESMF_ArraySca=
tterGatherSTest.F90
PASS: openmpi/g: src/system_tests/ESMF_ArraySharedDeSSI/ESMF_ArrayShare=
dDeSSISTest.F90
PASS: openmpi/g: src/system_tests/ESMF_ArraySparseMatMul/ESMF_ArraySpar=
seMatMulSTest.F90
PASS: openmpi/g: src/system_tests/ESMF_Attribute/ESMF_AttributeSTest.F9=
0
PASS: openmpi/g: src/system_tests/ESMF_AttributeCIM/ESMF_AttributeCIMST=
est.F90
PASS: openmpi/g: src/system_tests/ESMF_CompCreate/ESMF_CompCreateSTest.=
F90
PASS: openmpi/g: src/system_tests/ESMF_CompFortranAndC/ESMF_CompFortran=
AndCSTest.F90
PASS: openmpi/g: src/system_tests/ESMF_ComplianceChecker/ESMF_Complianc=
eCheckerSTest.F90
PASS: openmpi/g: src/system_tests/ESMF_ConcurrentComponent/ESMF_Concurr=
entCompSTest.F90
PASS: openmpi/g: src/system_tests/ESMF_ConcurrentEnsemble/ESMF_Concurre=
ntEnsembleSTest.F90
PASS: openmpi/g: src/system_tests/ESMF_DirectCoupling/ESMF_DirectCoupli=
ngSTest.F90
PASS: openmpi/g: src/system_tests/ESMF_FieldBundleLSRedistArb2Arb/ESMF_=
FieldBundleLSRedistArb2ArbSTest.F90
PASS: openmpi/g: src/system_tests/ESMF_FieldBundleLSRedistArb2ArbUngrdD=
im/ESMF_FieldBundleLSRedistArb2ArbUngrdDimSTest.F90
PASS: openmpi/g: src/system_tests/ESMF_FieldBundleRedistArb2Arb/ESMF_Fi=
eldBundleRedistArb2ArbSTest.F90
PASS: openmpi/g: src/system_tests/ESMF_FieldBundleRedistBlk2Arb/ESMF_Fi=
eldBundleRedistBlk2ArbSTest.F90
PASS: openmpi/g: src/system_tests/ESMF_FieldBundleRedistBlk2Blk/ESMF_Fi=
eldBundleRedistBlk2BlkSTest.F90
PASS: openmpi/g: src/system_tests/ESMF_FieldBundleSMM/ESMF_FieldBundleS=
MMSTest.F90
PASS: openmpi/g: src/system_tests/ESMF_FieldBundleSMMPacked/ESMF_FieldB=
undleSMMPackedSTest.F90
PASS: openmpi/g: src/system_tests/ESMF_FieldConcurrentComp/ESMF_FieldCo=
nCompSTest.F90
PASS: openmpi/g: src/system_tests/ESMF_FieldLSRedistArb2Arb/ESMF_FieldL=
SRedistArb2ArbSTest.F90
PASS: openmpi/g: src/system_tests/ESMF_FieldLSRedistArb2ArbUngrdDim/ESM=
F_FieldLSRedistArb2ArbUngrdDimSTest.F90
PASS: openmpi/g: src/system_tests/ESMF_FieldLSSMM/ESMF_FieldLSSMMSTest.=
F90
PASS: openmpi/g: src/system_tests/ESMF_FieldMeshSMM/ESMF_FieldMeshSMMST=
est.F90
PASS: openmpi/g: src/system_tests/ESMF_FieldRedist/ESMF_FieldRedistSTes=
t.F90
PASS: openmpi/g: src/system_tests/ESMF_FieldRedistArb2Arb/ESMF_FieldRed=
istArb2ArbSTest.F90
PASS: openmpi/g: src/system_tests/ESMF_FieldRedistBlk2Arb/ESMF_FieldRed=
istBlk2ArbSTest.F90
PASS: openmpi/g: src/system_tests/ESMF_FieldRedistBlk2Blk/ESMF_FieldRed=
istBlk2BlkSTest.F90
PASS: openmpi/g: src/system_tests/ESMF_FieldRegrid/ESMF_FieldRegridSTes=
t.F90
PASS: openmpi/g: src/system_tests/ESMF_FieldRegridMesh/ESMF_FieldRegrid=
MeshSTest.F90
PASS: openmpi/g: src/system_tests/ESMF_FieldRegridMeshToMesh/ESMF_Field=
RegridMeshToMeshSTest.F90
PASS: openmpi/g: src/system_tests/ESMF_FieldRegridOverlap/ESMF_FieldReg=
ridOverlapSTest.F90
PASS: openmpi/g: src/system_tests/ESMF_FieldSparseMatMul/ESMF_FieldSpar=
seMatMulSTest.F90
PASS: openmpi/g: src/system_tests/ESMF_RecursiveComponent/ESMF_Recursiv=
eComponentSTest.F90
PASS: openmpi/g: src/system_tests/ESMF_SequentialEnsemble/ESMF_Sequenti=
alEnsembleSTest.F90
PASS: openmpi/g: src/system_tests/ESMF_Trace/ESMF_TraceSTest.F90
PASS: openmpi/g: src/system_tests/ESMF_TransferGrid/ESMF_TransferGridST=
est.F90
PASS: openmpi/g: src/system_tests/ESMF_TransferMesh/ESMF_TransferMeshST=
est.F90
PASS: openmpi/g: src/system_tests/ESMF_XGridConcurrent/ESMF_XGridConcur=
rentSTest.F90
PASS: openmpi/g: src/system_tests/ESMF_XGridSerial/ESMF_XGridSerialSTes=
t.F90


The following system test failed, did not build, or did not execute:


FAIL: openmpi/g: src/system_tests/ESMF_FieldRegridDisjoint/ESMF_FieldRe=
gridDisjointSTest.F90




The stdout files for the system_tests can be found at:
/lcrc/project/ESMF/scripts_dirs/daily_builds/intel_bebop/esmf/test/test=
g/Linux.intel.64.openmpi.default


Found 46 multi-processor system tests, 45 passed and 1 failed.



|------------------------- EXAMPLES ---------------------------|
Mon Mar 16 13:54:43 CDT 2020 build_examples -j4 ...........PASS
Mon Mar 16 14:05:58 CDT 2020 run_examples .................PASS


The following examples passed:


PASS: openmpi/g: src/Infrastructure/Array/examples/ESMF_ArrayArbHaloEx.=
F90
PASS: openmpi/g: src/Infrastructure/Array/examples/ESMF_ArrayCommNBEx.F=
90
PASS: openmpi/g: src/Infrastructure/Array/examples/ESMF_ArrayEx.F90
PASS: openmpi/g: src/Infrastructure/Array/examples/ESMF_ArrayFarrayEx.F=
90
PASS: openmpi/g: src/Infrastructure/Array/examples/ESMF_ArrayFarrayHalo=
Ex.F90
PASS: openmpi/g: src/Infrastructure/Array/examples/ESMF_ArrayHaloEx.F90
PASS: openmpi/g: src/Infrastructure/Array/examples/ESMF_ArrayLarrayEx.F=
90
PASS: openmpi/g: src/Infrastructure/Array/examples/ESMF_ArrayRedistEx.F=
90
PASS: openmpi/g: src/Infrastructure/Array/examples/ESMF_ArrayScatterGat=
herArbEx.F90
PASS: openmpi/g: src/Infrastructure/Array/examples/ESMF_ArrayScatterGat=
herEx.F90
PASS: openmpi/g: src/Infrastructure/Array/examples/ESMF_ArraySparseMatM=
ulEx.F90
PASS: openmpi/g: src/Infrastructure/ArrayBundle/examples/ESMF_ArrayBund=
leEx.F90
PASS: openmpi/g: src/Infrastructure/ArrayBundle/examples/ESMF_ArrayBund=
leHaloEx.F90
PASS: openmpi/g: src/Infrastructure/ArraySpec/examples/ESMF_ArraySpecEx=
.F90
PASS: openmpi/g: src/Infrastructure/Config/examples/ESMF_ConfigOverview=
Ex.F90
PASS: openmpi/g: src/Infrastructure/DELayout/examples/ESMF_DELayoutEx.F=
90
PASS: openmpi/g: src/Infrastructure/DistGrid/examples/ESMF_DistGridEx.F=
90
PASS: openmpi/g: src/Infrastructure/Field/examples/ESMF_FieldArbGridEx.=
F90
PASS: openmpi/g: src/Infrastructure/Field/examples/ESMF_FieldCommEx.F90
PASS: openmpi/g: src/Infrastructure/Field/examples/ESMF_FieldCreateEx.F=
90
PASS: openmpi/g: src/Infrastructure/Field/examples/ESMF_FieldEx.F90
PASS: openmpi/g: src/Infrastructure/Field/examples/ESMF_FieldHaloEx.F90
PASS: openmpi/g: src/Infrastructure/Field/examples/ESMF_FieldMeshRegrid=
Ex.F90
PASS: openmpi/g: src/Infrastructure/Field/examples/ESMF_FieldRedistEx.F=
90
PASS: openmpi/g: src/Infrastructure/Field/examples/ESMF_FieldRegridEx.F=
90
PASS: openmpi/g: src/Infrastructure/Field/examples/ESMF_FieldRegridMask=
Ex.F90
PASS: openmpi/g: src/Infrastructure/Field/examples/ESMF_FieldRepDimEx.F=
90
PASS: openmpi/g: src/Infrastructure/Field/examples/ESMF_FieldSMMEx.F90
PASS: openmpi/g: src/Infrastructure/Field/examples/ESMF_FieldSphereRegr=
idEx.F90
PASS: openmpi/g: src/Infrastructure/FieldBundle/examples/ESMF_FieldBund=
leCreateEx.F90
PASS: openmpi/g: src/Infrastructure/FieldBundle/examples/ESMF_FieldBund=
leHaloEx.F90
PASS: openmpi/g: src/Infrastructure/FieldBundle/examples/ESMF_FieldBund=
leRedistEx.F90
PASS: openmpi/g: src/Infrastructure/Grid/examples/ESMF_GridCreateRegFro=
mDGEx.F90
PASS: openmpi/g: src/Infrastructure/Grid/examples/ESMF_GridUsageEx.F90
PASS: openmpi/g: src/Infrastructure/LocStream/examples/ESMF_LocStreamEx=
.F90
PASS: openmpi/g: src/Infrastructure/LogErr/examples/ESMF_LogErrEx.F90
PASS: openmpi/g: src/Infrastructure/Mesh/examples/ESMF_MeshEx.F90
PASS: openmpi/g: src/Infrastructure/Route/examples/ESMF_RHandleBitForBi=
tEx.F90
PASS: openmpi/g: src/Infrastructure/Route/examples/ESMF_RHandleDynamicM=
askingEx.F90
PASS: openmpi/g: src/Infrastructure/Route/examples/ESMF_RHandleFromFile=
Ex.F90
PASS: openmpi/g: src/Infrastructure/Route/examples/ESMF_RHandleFromRHan=
dleEx.F90
PASS: openmpi/g: src/Infrastructure/Route/examples/ESMF_RHandleReusabil=
ityEx.F90
PASS: openmpi/g: src/Infrastructure/TimeMgr/examples/ESMF_AlarmEx.F90
PASS: openmpi/g: src/Infrastructure/TimeMgr/examples/ESMF_CalendarEx.F9=
0
PASS: openmpi/g: src/Infrastructure/TimeMgr/examples/ESMF_ClockEx.F90
PASS: openmpi/g: src/Infrastructure/TimeMgr/examples/ESMF_TimeEx.F90
PASS: openmpi/g: src/Infrastructure/TimeMgr/examples/ESMF_TimeIntervalE=
x.F90
PASS: openmpi/g: src/Infrastructure/Trace/examples/ESMF_TraceEx.F90
PASS: openmpi/g: src/Infrastructure/Trace/examples/ESMF_TraceUserEx.F90
PASS: openmpi/g: src/Infrastructure/VM/examples/ESMF_VMAllFullReduceEx.=
F90
PASS: openmpi/g: src/Infrastructure/VM/examples/ESMF_VMComponentEx.F90
PASS: openmpi/g: src/Infrastructure/VM/examples/ESMF_VMDefaultBasicsEx.=
F90
PASS: openmpi/g: src/Infrastructure/VM/examples/ESMF_VMGetMPICommunicat=
orEx.F90
PASS: openmpi/g: src/Infrastructure/VM/examples/ESMF_VMHigherRankDataEx=
.F90
PASS: openmpi/g: src/Infrastructure/VM/examples/ESMF_VMScatterVMGatherE=
x.F90
PASS: openmpi/g: src/Infrastructure/VM/examples/ESMF_VMSendVMRecvEx.F90
PASS: openmpi/g: src/Infrastructure/VM/examples/ESMF_VMUserMpiCommEx.F9=
0
PASS: openmpi/g: src/Infrastructure/VM/examples/ESMF_VMUserMpiCommMulti=
Ex.F90
PASS: openmpi/g: src/Infrastructure/VM/examples/ESMF_VMUserMpiEx.F90
PASS: openmpi/g: src/Infrastructure/XGrid/examples/ESMF_XGridEx.F90
PASS: openmpi/g: src/Infrastructure/XGrid/examples/ESMF_XGridSparseMatE=
x.F90
PASS: openmpi/g: src/Superstructure/AttachMethods/examples/ESMF_AttachM=
ethodsEx.F90
PASS: openmpi/g: src/Superstructure/AttributeAPI/examples/ESMF_AttReadC=
ustCplCompEx.F90
PASS: openmpi/g: src/Superstructure/AttributeAPI/examples/ESMF_AttReadF=
ieldEx.F90
PASS: openmpi/g: src/Superstructure/AttributeAPI/examples/ESMF_AttReadG=
ridCompEx.F90
PASS: openmpi/g: src/Superstructure/AttributeAPI/examples/ESMF_Attribut=
eCIMEx.F90
PASS: openmpi/g: src/Superstructure/AttributeAPI/examples/ESMF_Attribut=
eCustPackEx.F90
PASS: openmpi/g: src/Superstructure/AttributeAPI/examples/ESMF_Attribut=
eEx.F90
PASS: openmpi/g: src/Superstructure/AttributeAPI/examples/ESMF_Attribut=
eInternalInfoEx.F90
PASS: openmpi/g: src/Superstructure/AttributeAPI/examples/ESMF_Attribut=
ePackageEx.F90
PASS: openmpi/g: src/Superstructure/AttributeAPI/examples/ESMF_Attribut=
eUpdateEx.F90
PASS: openmpi/g: src/Superstructure/Component/examples/ESMF_AppMainEx.F=
90
PASS: openmpi/g: src/Superstructure/Component/examples/ESMF_CompTunnelE=
x.F90
PASS: openmpi/g: src/Superstructure/Component/examples/ESMF_CplEx.F90
PASS: openmpi/g: src/Superstructure/Component/examples/ESMF_GCompEx.F90
PASS: openmpi/g: src/Superstructure/Component/examples/ESMF_InternalSta=
teEx.F90
PASS: openmpi/g: src/Superstructure/Component/examples/ESMF_InternalSta=
teModEx.F90
PASS: openmpi/g: src/Superstructure/Component/examples/ESMF_SCompEx.F90
PASS: openmpi/g: src/Superstructure/State/examples/ESMF_StateEx.F90
PASS: openmpi/g: src/Superstructure/State/examples/ESMF_StateReadWriteE=
x.F90
PASS: openmpi/g: src/Superstructure/State/examples/ESMF_StateReconcileE=
x.F90
PASS: openmpi/g: src/Superstructure/WebServices/examples/ESMF_WebServic=
esEx.F90
PASS: openmpi/g: src/addon/NUOPC/examples/ESMF_NUOPCAtmModelEx.F90
PASS: openmpi/g: src/addon/NUOPC/examples/ESMF_NUOPCBasicModelEx.F90


The following example failed, did not build, or did not execute:


FAIL: openmpi/g: src/Infrastructure/FieldBundle/examples/ESMF_FieldBund=
leSMMEx.F90




The stdout files for the examples can be found at:
/lcrc/project/ESMF/scripts_dirs/daily_builds/intel_bebop/esmf/examples/=
examplesg/Linux.intel.64.openmpi.default


Found 85 multi-processor examples, 84 passed and 1 failed.



|-------------------- EXHAUSTIVE UNIT TESTS -------------------|
Mon Mar 16 14:22:22 CDT 2020 build_unit_tests -j4 .........PASS
Mon Mar 16 14:40:11 CDT 2020 run_unit_tests ...............PASS




The unit tests in the following files all pass:

PASS: openmpi/g: src/Infrastructure/Array/tests/ESMC_ArrayUTest.C
PASS: openmpi/g: src/Infrastructure/Array/tests/ESMF_ArrayArbIdxSMMUTes=
t.F90
PASS: openmpi/g: src/Infrastructure/Array/tests/ESMF_ArrayCreateGetUTes=
t.F90
PASS: openmpi/g: src/Infrastructure/Array/tests/ESMF_ArrayDataUTest.F90
PASS: openmpi/g: src/Infrastructure/Array/tests/ESMF_ArrayGatherUTest.F=
90
PASS: openmpi/g: src/Infrastructure/Array/tests/ESMF_ArrayHaloUTest.F90
PASS: openmpi/g: src/Infrastructure/Array/tests/ESMF_ArrayIOUTest.F90
PASS: openmpi/g: src/Infrastructure/Array/tests/ESMF_ArrayRedistPerfUTe=
st.F90
PASS: openmpi/g: src/Infrastructure/Array/tests/ESMF_ArrayRedistUTest.F=
90
PASS: openmpi/g: src/Infrastructure/Array/tests/ESMF_ArraySMMFromFileUT=
est.F90
PASS: openmpi/g: src/Infrastructure/Array/tests/ESMF_ArraySMMUTest.F90
PASS: openmpi/g: src/Infrastructure/Array/tests/ESMF_ArrayScatterUTest.=
F90
PASS: openmpi/g: src/Infrastructure/ArrayBundle/tests/ESMF_ArrayBundleC=
reateUTest.F90
PASS: openmpi/g: src/Infrastructure/ArrayBundle/tests/ESMF_ArrayBundleI=
OUTest.F90
PASS: openmpi/g: src/Infrastructure/ArrayBundle/tests/ESMF_ArrayBundleR=
edistUTest.F90
PASS: openmpi/g: src/Infrastructure/ArraySpec/tests/ESMC_ArraySpecUTest=
.C
PASS: openmpi/g: src/Infrastructure/ArraySpec/tests/ESMF_ArraySpecUTest=
.F90
PASS: openmpi/g: src/Infrastructure/Base/tests/ESMC_BaseUTest.C
PASS: openmpi/g: src/Infrastructure/Base/tests/ESMF_BaseUTest.F90
PASS: openmpi/g: src/Infrastructure/Config/tests/ESMC_ConfigUTest.C
PASS: openmpi/g: src/Infrastructure/Config/tests/ESMF_ConfigUTest.F90
PASS: openmpi/g: src/Infrastructure/Container/tests/ESMF_ContainerUTest=
.F90
PASS: openmpi/g: src/Infrastructure/DELayout/tests/ESMF_DELayoutUTest.F=
90
PASS: openmpi/g: src/Infrastructure/DELayout/tests/ESMF_DELayoutWorkQue=
ueUTest.F90
PASS: openmpi/g: src/Infrastructure/DistGrid/tests/ESMC_DistGridUTest.C
PASS: openmpi/g: src/Infrastructure/DistGrid/tests/ESMF_DistGridCreateG=
etUTest.F90
PASS: openmpi/g: src/Infrastructure/Field/tests/ESMC_FieldGridGridRegri=
dCsrvUTest.C
PASS: openmpi/g: src/Infrastructure/Field/tests/ESMC_FieldGridGridRegri=
dUTest.C
PASS: openmpi/g: src/Infrastructure/Field/tests/ESMC_FieldGridRegrid2UT=
est.C
PASS: openmpi/g: src/Infrastructure/Field/tests/ESMC_FieldGridRegridCsr=
v2UTest.C
PASS: openmpi/g: src/Infrastructure/Field/tests/ESMC_FieldGridRegridCsr=
vUTest.C
PASS: openmpi/g: src/Infrastructure/Field/tests/ESMC_FieldGridRegridPar=
UTest.C
PASS: openmpi/g: src/Infrastructure/Field/tests/ESMC_FieldGridRegridUTe=
st.C
PASS: openmpi/g: src/Infrastructure/Field/tests/ESMC_FieldRegridCsrvUTe=
st.C
PASS: openmpi/g: src/Infrastructure/Field/tests/ESMC_FieldRegridUTest.C
PASS: openmpi/g: src/Infrastructure/Field/tests/ESMC_FieldSMMFromFileUT=
est.C
PASS: openmpi/g: src/Infrastructure/Field/tests/ESMC_FieldUTest.C
PASS: openmpi/g: src/Infrastructure/Field/tests/ESMF_FieldArbGridUTest.=
F90
PASS: openmpi/g: src/Infrastructure/Field/tests/ESMF_FieldCreateGetUTes=
t.F90
PASS: openmpi/g: src/Infrastructure/Field/tests/ESMF_FieldGatherUTest.F=
90
PASS: openmpi/g: src/Infrastructure/Field/tests/ESMF_FieldHaloUTest.F90
PASS: openmpi/g: src/Infrastructure/Field/tests/ESMF_FieldIOUTest.F90
PASS: openmpi/g: src/Infrastructure/Field/tests/ESMF_FieldLSSMMUTest.F9=
0
PASS: openmpi/g: src/Infrastructure/Field/tests/ESMF_FieldRedistArbUTes=
t.F90
PASS: openmpi/g: src/Infrastructure/Field/tests/ESMF_FieldRedistUTest.F=
90
PASS: openmpi/g: src/Infrastructure/Field/tests/ESMF_FieldRegridCSUTest=
.F90
PASS: openmpi/g: src/Infrastructure/Field/tests/ESMF_FieldRegridCsrv2nd=
UTest.F90
PASS: openmpi/g: src/Infrastructure/Field/tests/ESMF_FieldRegridCsrvUTe=
st.F90
PASS: openmpi/g: src/Infrastructure/Field/tests/ESMF_FieldRegridUTest.F=
90
PASS: openmpi/g: src/Infrastructure/Field/tests/ESMF_FieldRegridXGSMMUT=
est.F90
PASS: openmpi/g: src/Infrastructure/Field/tests/ESMF_FieldRegridXGUTest=
.F90
PASS: openmpi/g: src/Infrastructure/Field/tests/ESMF_FieldSMMFromFileUT=
est.F90
PASS: openmpi/g: src/Infrastructure/Field/tests/ESMF_FieldSMMUTest.F90
PASS: openmpi/g: src/Infrastructure/Field/tests/ESMF_FieldUTest.F90
PASS: openmpi/g: src/Infrastructure/FieldBundle/tests/ESMF_FieldBundleC=
rGetUTest.F90
PASS: openmpi/g: src/Infrastructure/FieldBundle/tests/ESMF_FieldBundleI=
OUTest.F90
PASS: openmpi/g: src/Infrastructure/FieldBundle/tests/ESMF_FieldBundleR=
edistUTest.F90
PASS: openmpi/g: src/Infrastructure/FieldBundle/tests/ESMF_FieldBundleR=
egridUTest.F90
PASS: openmpi/g: src/Infrastructure/FieldBundle/tests/ESMF_FieldBundleS=
MMUTest.F90
PASS: openmpi/g: src/Infrastructure/FieldBundle/tests/ESMF_FieldBundleU=
Test.F90
PASS: openmpi/g: src/Infrastructure/Grid/tests/ESMC_GridUTest.C
PASS: openmpi/g: src/Infrastructure/Grid/tests/ESMF_GridArbitraryUTest.=
F90
PASS: openmpi/g: src/Infrastructure/Grid/tests/ESMF_GridCoordUTest.F90
PASS: openmpi/g: src/Infrastructure/Grid/tests/ESMF_GridCreateUTest.F90
PASS: openmpi/g: src/Infrastructure/Grid/tests/ESMF_GridItemUTest.F90
PASS: openmpi/g: src/Infrastructure/GridUtil/tests/ESMF_GridToMeshUTest=
.F90
PASS: openmpi/g: src/Infrastructure/IO/tests/ESMCI_IO_NetCDFUTest.C
PASS: openmpi/g: src/Infrastructure/IO/tests/ESMCI_IO_PIOUTest.C
PASS: openmpi/g: src/Infrastructure/IO/tests/ESMC_IO_InqUTest.C
PASS: openmpi/g: src/Infrastructure/IO/tests/ESMF_IOUTest.F90
PASS: openmpi/g: src/Infrastructure/IO/tests/ESMF_IO_PIOUTest.F90
PASS: openmpi/g: src/Infrastructure/IO/tests/ESMF_IO_YAMLUTest.F90
PASS: openmpi/g: src/Infrastructure/LocStream/tests/ESMC_LocStreamUTest=
.C
PASS: openmpi/g: src/Infrastructure/LocStream/tests/ESMF_LocStreamUTest=
.F90
PASS: openmpi/g: src/Infrastructure/LocalArray/tests/ESMF_LocalArrayDat=
aUTest.F90
PASS: openmpi/g: src/Infrastructure/LocalArray/tests/ESMF_LocalArrayUTe=
st.F90
PASS: openmpi/g: src/Infrastructure/LogErr/tests/ESMC_LogErrPerfUTest.C
PASS: openmpi/g: src/Infrastructure/LogErr/tests/ESMC_LogErrUTest.C
PASS: openmpi/g: src/Infrastructure/LogErr/tests/ESMF_LogErrPerfUTest.F=
90
PASS: openmpi/g: src/Infrastructure/LogErr/tests/ESMF_LogErrUTest.F90
PASS: openmpi/g: src/Infrastructure/Mesh/tests/ESMC_MBMesh_BilinearParU=
Test.C
PASS: openmpi/g: src/Infrastructure/Mesh/tests/ESMC_MBMesh_BilinearSing=
leElemUTest.C
PASS: openmpi/g: src/Infrastructure/Mesh/tests/ESMC_MBMesh_BilinearUTes=
t.C
PASS: openmpi/g: src/Infrastructure/Mesh/tests/ESMC_MBMesh_CreateParUTe=
st.C
PASS: openmpi/g: src/Infrastructure/Mesh/tests/ESMC_MBMesh_CreateUTest.=
C
PASS: openmpi/g: src/Infrastructure/Mesh/tests/ESMC_MBMesh_SearchUTest.=
C
PASS: openmpi/g: src/Infrastructure/Mesh/tests/ESMC_MBMesh_SerializeUTe=
st.C
PASS: openmpi/g: src/Infrastructure/Mesh/tests/ESMC_MBMesh_UtilParUTest=
.C
PASS: openmpi/g: src/Infrastructure/Mesh/tests/ESMC_MBMesh_UtilUTest.C
PASS: openmpi/g: src/Infrastructure/Mesh/tests/ESMC_MeshMOABUTest.C
PASS: openmpi/g: src/Infrastructure/Mesh/tests/ESMC_MeshUTest.C
PASS: openmpi/g: src/Infrastructure/Mesh/tests/ESMC_MeshVTKUTest.C
PASS: openmpi/g: src/Infrastructure/Mesh/tests/ESMC_Proj4UTest.C
PASS: openmpi/g: src/Infrastructure/Mesh/tests/ESMF_MeshOpUTest.F90
PASS: openmpi/g: src/Infrastructure/Mesh/tests/ESMF_MeshUTest.F90
PASS: openmpi/g: src/Infrastructure/PointList/tests/ESMF_PointListUTest=
.F90
PASS: openmpi/g: src/Infrastructure/Route/tests/ESMF_RouteHandleAdvance=
dUTest.F90
PASS: openmpi/g: src/Infrastructure/Route/tests/ESMF_RouteHandleUTest.F=
90
PASS: openmpi/g: src/Infrastructure/TimeMgr/tests/ESMC_CalendarUTest.C
PASS: openmpi/g: src/Infrastructure/TimeMgr/tests/ESMC_ClockUTest.C
PASS: openmpi/g: src/Infrastructure/TimeMgr/tests/ESMC_TimeIntervalUTes=
t.C
PASS: openmpi/g: src/Infrastructure/TimeMgr/tests/ESMC_TimeUTest.C
PASS: openmpi/g: src/Infrastructure/TimeMgr/tests/ESMF_AlarmUTest.F90
PASS: openmpi/g: src/Infrastructure/TimeMgr/tests/ESMF_CalRangeUTest.F9=
0
PASS: openmpi/g: src/Infrastructure/TimeMgr/tests/ESMF_CalendarUTest.F9=
0
PASS: openmpi/g: src/Infrastructure/TimeMgr/tests/ESMF_ClockUTest.F90
PASS: openmpi/g: src/Infrastructure/TimeMgr/tests/ESMF_TimeIntervalUTes=
t.F90
PASS: openmpi/g: src/Infrastructure/TimeMgr/tests/ESMF_TimeUTest.F90
PASS: openmpi/g: src/Infrastructure/Trace/tests/ESMC_TraceRegionUTest.C
PASS: openmpi/g: src/Infrastructure/Trace/tests/ESMF_ProfileUTest.F90
PASS: openmpi/g: src/Infrastructure/Trace/tests/ESMF_TraceClkMonoSyncUT=
est.F90
PASS: openmpi/g: src/Infrastructure/Trace/tests/ESMF_TraceClkMonoUTest.=
F90
PASS: openmpi/g: src/Infrastructure/Trace/tests/ESMF_TraceIOUTest.F90
PASS: openmpi/g: src/Infrastructure/Trace/tests/ESMF_TraceMPIUTest.F90
PASS: openmpi/g: src/Infrastructure/Trace/tests/ESMF_TraceUTest.F90
PASS: openmpi/g: src/Infrastructure/Util/tests/ESMF_FortranWordsizeUTes=
t.F90
PASS: openmpi/g: src/Infrastructure/Util/tests/ESMF_InitMacrosUTest.F90
PASS: openmpi/g: src/Infrastructure/Util/tests/ESMF_TypeKindGetUTest.F9=
0
PASS: openmpi/g: src/Infrastructure/Util/tests/ESMF_UtilUTest.F90
PASS: openmpi/g: src/Infrastructure/VM/tests/ESMC_VMUTest.C
PASS: openmpi/g: src/Infrastructure/VM/tests/ESMF_VMAccUTest.F90
PASS: openmpi/g: src/Infrastructure/VM/tests/ESMF_VMAllGatherUTest.F90
PASS: openmpi/g: src/Infrastructure/VM/tests/ESMF_VMAllGatherVUTest.F90
PASS: openmpi/g: src/Infrastructure/VM/tests/ESMF_VMAllToAllUTest.F90
PASS: openmpi/g: src/Infrastructure/VM/tests/ESMF_VMAllToAllVUTest.F90
PASS: openmpi/g: src/Infrastructure/VM/tests/ESMF_VMBarrierUTest.F90
PASS: openmpi/g: src/Infrastructure/VM/tests/ESMF_VMBroadcastUTest.F90
PASS: openmpi/g: src/Infrastructure/VM/tests/ESMF_VMComponentUTest.F90
PASS: openmpi/g: src/Infrastructure/VM/tests/ESMF_VMGatherUTest.F90
PASS: openmpi/g: src/Infrastructure/VM/tests/ESMF_VMOpenMPUTest.F90
PASS: openmpi/g: src/Infrastructure/VM/tests/ESMF_VMScatterUTest.F90
PASS: openmpi/g: src/Infrastructure/VM/tests/ESMF_VMSendNbVMRecvNbUTest=
.F90
PASS: openmpi/g: src/Infrastructure/VM/tests/ESMF_VMSendRecvNbUTest.F90
PASS: openmpi/g: src/Infrastructure/VM/tests/ESMF_VMSendRecvUTest.F90
PASS: openmpi/g: src/Infrastructure/VM/tests/ESMF_VMSendVMRecvUTest.F90
PASS: openmpi/g: src/Infrastructure/VM/tests/ESMF_VMUTest.F90
PASS: openmpi/g: src/Infrastructure/VM/tests/ESMF_VMUserMpiInitUTest.F9=
0
PASS: openmpi/g: src/Infrastructure/XGrid/tests/ESMC_XGridUTest.C
PASS: openmpi/g: src/Infrastructure/XGrid/tests/ESMF_XGridMaskingUTest.=
F90
PASS: openmpi/g: src/Infrastructure/XGrid/tests/ESMF_XGridUTest.F90
PASS: openmpi/g: src/Superstructure/AttributeAPI/tests/ESMF_AttInternal=
GridUTest.F90
PASS: openmpi/g: src/Superstructure/AttributeAPI/tests/ESMF_AttPackABun=
dleUTest.F90
PASS: openmpi/g: src/Superstructure/AttributeAPI/tests/ESMF_AttPackArra=
yUTest.F90
PASS: openmpi/g: src/Superstructure/AttributeAPI/tests/ESMF_AttPackCplC=
ompUTest.F90
PASS: openmpi/g: src/Superstructure/AttributeAPI/tests/ESMF_AttPackDist=
GridUTest.F90
PASS: openmpi/g: src/Superstructure/AttributeAPI/tests/ESMF_AttPackFBun=
dleUTest.F90
PASS: openmpi/g: src/Superstructure/AttributeAPI/tests/ESMF_AttPackFiel=
dUTest.F90
PASS: openmpi/g: src/Superstructure/AttributeAPI/tests/ESMF_AttPackGrid=
CompUTest.F90
PASS: openmpi/g: src/Superstructure/AttributeAPI/tests/ESMF_AttPackGrid=
UTest.F90
PASS: openmpi/g: src/Superstructure/AttributeAPI/tests/ESMF_AttPackLocS=
treamUTest.F90
PASS: openmpi/g: src/Superstructure/AttributeAPI/tests/ESMF_AttPackSciC=
ompUTest.F90
PASS: openmpi/g: src/Superstructure/AttributeAPI/tests/ESMF_AttPackStat=
eUTest.F90
PASS: openmpi/g: src/Superstructure/AttributeAPI/tests/ESMF_AttReadCplC=
ompUTest.F90
PASS: openmpi/g: src/Superstructure/AttributeAPI/tests/ESMF_AttReadFiel=
dUTest.F90
PASS: openmpi/g: src/Superstructure/AttributeAPI/tests/ESMF_AttReadGrid=
CompUTest.F90
PASS: openmpi/g: src/Superstructure/AttributeAPI/tests/ESMF_AttributeAB=
undleUTest.F90
PASS: openmpi/g: src/Superstructure/AttributeAPI/tests/ESMF_AttributeAr=
rayUTest.F90
PASS: openmpi/g: src/Superstructure/AttributeAPI/tests/ESMF_AttributeAu=
toLinkUTest.F90
PASS: openmpi/g: src/Superstructure/AttributeAPI/tests/ESMF_AttributeCp=
lCompUTest.F90
PASS: openmpi/g: src/Superstructure/AttributeAPI/tests/ESMF_AttributeDi=
stGridUTest.F90
PASS: openmpi/g: src/Superstructure/AttributeAPI/tests/ESMF_AttributeFB=
undleUTest.F90
PASS: openmpi/g: src/Superstructure/AttributeAPI/tests/ESMF_AttributeFi=
eldUTest.F90
PASS: openmpi/g: src/Superstructure/AttributeAPI/tests/ESMF_AttributeGr=
idCompUTest.F90
PASS: openmpi/g: src/Superstructure/AttributeAPI/tests/ESMF_AttributeGr=
idUTest.F90
PASS: openmpi/g: src/Superstructure/AttributeAPI/tests/ESMF_AttributeJS=
ONUTest.F90
PASS: openmpi/g: src/Superstructure/AttributeAPI/tests/ESMF_AttributeLo=
cStreamUTest.F90
PASS: openmpi/g: src/Superstructure/AttributeAPI/tests/ESMF_AttributeSc=
iCompUTest.F90
PASS: openmpi/g: src/Superstructure/AttributeAPI/tests/ESMF_AttributeSt=
ateUTest.F90
PASS: openmpi/g: src/Superstructure/AttributeAPI/tests/ESMF_AttributeUp=
dateCIMRespPartyUTest.F90
PASS: openmpi/g: src/Superstructure/AttributeAPI/tests/ESMF_AttributeUp=
dateClosedLoopTreesUTest.F90
PASS: openmpi/g: src/Superstructure/AttributeAPI/tests/ESMF_AttributeUp=
dateComponentUTest.F90
PASS: openmpi/g: src/Superstructure/AttributeAPI/tests/ESMF_AttributeUp=
dateContainerStressUTest.F90
PASS: openmpi/g: src/Superstructure/AttributeAPI/tests/ESMF_AttributeUp=
dateMultiReconcileUTest.F90
PASS: openmpi/g: src/Superstructure/AttributeAPI/tests/ESMF_AttributeUp=
dateReconcileUTest.F90
PASS: openmpi/g: src/Superstructure/AttributeAPI/tests/ESMF_AttributeUp=
dateRemoveOnlyUTest.F90
PASS: openmpi/g: src/Superstructure/AttributeAPI/tests/ESMF_AttributeUp=
dateUTest.F90
PASS: openmpi/g: src/Superstructure/AttributeAPI/tests/ESMF_AttributeWr=
iteInternalUTest.F90
PASS: openmpi/g: src/Superstructure/AttributeAPI/tests/ESMF_AttributeXM=
LUTest.F90
PASS: openmpi/g: src/Superstructure/Component/tests/ESMC_ComponentUTest=
.C
PASS: openmpi/g: src/Superstructure/Component/tests/ESMF_CompSetServUTe=
st.F90
PASS: openmpi/g: src/Superstructure/Component/tests/ESMF_CompTunnelUTes=
t.F90
PASS: openmpi/g: src/Superstructure/Component/tests/ESMF_ComponentUTest=
.F90
PASS: openmpi/g: src/Superstructure/Component/tests/ESMF_CplCompCreateU=
Test.F90
PASS: openmpi/g: src/Superstructure/Component/tests/ESMF_GridCompCreate=
UTest.F90
PASS: openmpi/g: src/Superstructure/Component/tests/ESMF_SciCompCreateU=
Test.F90
PASS: openmpi/g: src/Superstructure/Component/tests/ESMF_StdCompMethods=
UTest.F90
PASS: openmpi/g: src/Superstructure/ESMFMod/tests/ESMF_FrameworkUTest.F=
90
PASS: openmpi/g: src/Superstructure/IOAPI/tests/ESMF_IOCompUTest.F90
PASS: openmpi/g: src/Superstructure/PreESMFMod/tests/ESMF_FileRegridUTe=
st.F90
PASS: openmpi/g: src/Superstructure/PreESMFMod/tests/ESMF_RegridWeightG=
enUTest.F90
PASS: openmpi/g: src/Superstructure/State/tests/ESMC_StateUTest.C
PASS: openmpi/g: src/Superstructure/State/tests/ESMF_StateCreateUTest.F=
90
PASS: openmpi/g: src/Superstructure/State/tests/ESMF_StateReadWriteUTes=
t.F90
PASS: openmpi/g: src/Superstructure/State/tests/ESMF_StateReconcileUTes=
t.F90
PASS: openmpi/g: src/Superstructure/State/tests/ESMF_StateUTest.F90
PASS: openmpi/g: src/addon/NUOPC/tests/ESMF_NUOPC_UTest.F90
PASS: openmpi/g: src/epilogue/tests/ESMCI_TestUTest.C
PASS: openmpi/g: src/epilogue/tests/ESMC_TestUTest.C
PASS: openmpi/g: src/epilogue/tests/ESMF_TestUTest.F90
PASS: openmpi/g: src/prologue/tests/ESMCI_ExceptionsUTest.C
PASS: openmpi/g: src/prologue/tests/ESMCI_FeatureUTest.C
PASS: openmpi/g: src/prologue/tests/ESMF_F90ArrayPtrUTest.F90
PASS: openmpi/g: src/prologue/tests/ESMF_FeatureUTest.F90
PASS: openmpi/g: src/prologue/tests/ESMF_LAPACKUTest.F90
PASS: openmpi/g: src/prologue/tests/ESMF_StringUTest.F90
PASS: openmpi/g: src/prologue/tests/ESMF_WordsizeUTest.F90


The following unit test files failed to build, failed to execute or cra=
shed during execution:

CRASHED: openmpi/g: src/Infrastructure/Field/tests/ESMF_FieldStressUTes=
t.F90


The following test harness unit tests pass:
PASS: openmpi/g: ESMF_array_default_NP4UTest
PASS: openmpi/g: ESMF_field_default_NP4UTest


The log and stdout files for the unit tests can be found at:
/lcrc/project/ESMF/scripts_dirs/daily_builds/intel_bebop/esmf/test/test=
g/Linux.intel.64.openmpi.default


Found 9075 exhaustive multi-processor unit tests, 9074 passed and 1 fai=
led.



_______________________________________________________________________=
________________________


Mon Mar 16 14:45:09 CDT 2020 on beboplogin2=20

ESMF Checkout Source: https://github.com/esmf-org/esmf

Compiler and configuration information:
=20
--------------------------------------------------------------=20

Currently Loaded Modules:
  1) intel/18.0.4-443hhug
  2) openmpi/3.1.3-bebop-7wj2dww

=20

=20
Repository:
origin=09https://github.com/esmf-org/esmf (fetch)
origin=09https://github.com/esmf-org/esmf (push)
=20
ESMF_8_1_0_beta_snapshot_11
=20
=20
=20
--------------------------------------------------------------
ESMF_VERSION_STRING:    8.1.0 beta snapshot
ESMF_8_1_0_beta_snapshot_11
--------------------------------------------------------------
# On branch master
# Untracked files:
#   (use "git add <file>..." to include in what will be committed)
#
#=09queue_results
#=09src/installcheck/esmc_application
#=09src/installcheck/esmc_application.o
#=09src/installcheck/esmf_application
#=09src/installcheck/esmf_application.o
#=09tmp
nothing added to commit but untracked files present (use "git add" to t=
rack)
--------------------------------------------------------------
=20
--------------------------------------------------------------
Make version:
GNU Make 3.82
Built for x86_64-redhat-linux-gnu
Copyright (C) 2010  Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl=
.html>
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.

--------------------------------------------------------------
Fortran Compiler version:
Intel(R) Fortran Intel(R) 64 Compiler for applications running on Intel=
(R) 64, Version 18.0.5.274 Build 20180823
Copyright (C) 1985-2018 Intel Corporation.  All rights reserved.

ifort version 18.0.5

--------------------------------------------------------------
C++ Compiler version:
Intel(R) C++ Intel(R) 64 Compiler for applications running on Intel(R) =
64, Version 18.0.5.274 Build 20180823
Copyright (C) 1985-2018 Intel Corporation.  All rights reserved.

icpc version 18.0.5 (gcc version 8.1.0 compatibility)

--------------------------------------------------------------
Preprocessor version:
gcc (GCC) 8.1.0
Copyright (C) 2018 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is=
 NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURP=
OSE.

=20
--------------------------------------------------------------
 * User set ESMF environment variables *
ESMF_ABI=3D64
ESMF_BOPT=3DO
ESMF_COMM=3Dopenmpi
ESMF_COMPILER=3Dintel
ESMF_DIR=3D/lcrc/project/ESMF/scripts_dirs/daily_builds/intel_bebop/esm=
f
ESMF_INSTALL_PREFIX=3D/lcrc/project/ESMF/scripts_dirs/daily_builds/inte=
l_bebop/esmf/../install_dir
ESMF_MPIRUN=3Dmpirun
ESMF_OS=3DLinux
ESMF_PROJ4=3Dexternal
ESMF_PROJ4_INCLUDE=3D/home/svasquez/proj4/include
ESMF_PROJ4_LIBPATH=3D/home/svasquez/proj4/lib
ESMF_SITE=3Ddefault
ESMF_TESTCOMPTUNNEL=3DOFF
ESMF_TESTEXHAUSTIVE=3DON
ESMF_TESTHARNESS_ARRAY=3DRUN_ESMF_TestHarnessArray_default
ESMF_TESTHARNESS_FIELD=3DRUN_ESMF_TestHarnessField_default
ESMF_TESTMPMD=3DOFF
ESMF_TESTWITHTHREADS=3DOFF
=20
--------------------------------------------------------------
 * ESMF environment variables *
ESMF_DIR: /lcrc/project/ESMF/scripts_dirs/daily_builds/intel_bebop/esmf
ESMF_OS:                Linux
ESMF_MACHINE:           x86_64
ESMF_ABI:               64
ESMF_COMPILER:          intel
ESMF_BOPT:              O
ESMF_COMM:              openmpi
ESMF_SITE:              default
ESMF_PTHREADS:          ON
ESMF_OPENMP:            ON
ESMF_OPENACC:           OFF
ESMF_CXXSTD:            11
ESMF_ARRAY_LITE:        FALSE
ESMF_NO_INTEGER_1_BYTE: TRUE
ESMF_NO_INTEGER_2_BYTE: TRUE
ESMF_FORTRANSYMBOLS:    default
ESMF_MAPPER_BUILD:      OFF
ESMF_AUTO_LIB_BUILD:    ON
ESMF_DEFER_LIB_BUILD:   ON
ESMF_SHARED_LIB_BUILD:  ON
ESMF_TRACE_LIB_BUILD:   ON
ESMF_TESTEXHAUSTIVE:    ON
ESMF_TESTCOMPTUNNEL:    OFF
ESMF_TESTWITHTHREADS:   OFF
ESMF_TESTMPMD:          OFF
ESMF_TESTSHAREDOBJ:     OFF
ESMF_TESTFORCEOPENMP:   OFF
ESMF_TESTFORCEOPENACC:  OFF
ESMF_TESTHARNESS_ARRAY: RUN_ESMF_TestHarnessArray_default
ESMF_TESTHARNESS_FIELD: RUN_ESMF_TestHarnessField_default
ESMF_MPIRUN:            mpirun
=20
--------------------------------------------------------------
 * ESMF environment variables pointing to 3rd party software *
ESMF_MOAB:               internal
ESMF_LAPACK:             internal
ESMF_ACC_SOFTWARE_STACK: none
ESMF_YAMLCPP:            internal
ESMF_PIO:                internal
ESMF_PROJ4:                external
ESMF_PROJ4_INCLUDE:        /home/svasquez/proj4/include
ESMF_PROJ4_LIBS:           -lproj
ESMF_PROJ4_LIBPATH:        /home/svasquez/proj4/lib
=20
--------------------------------------------------------------
 * ESMF environment variables for final installation *
ESMF_INSTALL_PREFIX:    /lcrc/project/ESMF/scripts_dirs/daily_builds/in=
tel_bebop/esmf/../install_dir
ESMF_INSTALL_HEADERDIR: include
ESMF_INSTALL_MODDIR:    mod/modO/Linux.intel.64.openmpi.default
ESMF_INSTALL_LIBDIR:    lib/libO/Linux.intel.64.openmpi.default
ESMF_INSTALL_BINDIR:    bin/binO/Linux.intel.64.openmpi.default
ESMF_INSTALL_DOCDIR:    doc
=20
--------------------------------------------------------------
 * ESMF Benchmark directory and parameters *
ESMF_BENCHMARK_PREFIX:         ./DEFAULTBENCHMARKDIR
ESMF_BENCHMARK_TOLERANCE:      20%
ESMF_BENCHMARK_THRESHOLD_MSEC: 500
=20
--------------------------------------------------------------
 * Other relevant environment variables *
PATH:    /blues/gpfs/software/centos7/spack/opt/spack/linux-centos7-x86=
_64/intel-18.0.4/openmpi-3.1.3-7wj2dww/bin:/blues/gpfs/software/centos7=
/spack/opt/spack/linux-centos7-x86_64/gcc-4.8.5/gcc-8.1.0-dc4tau6/bin:/=
blues/gpfs/software/centos7/spack/opt/spack/linux-centos7-x86_64/gcc-8.=
1.0/intel-18.0.4-443hhug/compilers_and_libraries_2018.5.274/linux/bin/i=
ntel64:/blues/gpfs/software/centos7/spack/opt/spack/linux-centos7-x86_6=
4/gcc-8.1.0/intel-18.0.4-443hhug/compilers_and_libraries_2018.5.274/lin=
ux/mpi/intel64/bin:/blues/gpfs/software/centos7/spack/opt/spack/linux-c=
entos7-x86_64/gcc-8.1.0/intel-18.0.4-443hhug/bin:/home/svasquez/bin:/us=
r/bin:/bin:/usr/local/sbin:/usr/sbin:/soft/lcrc/bebop/bin:/soft/lcrc/be=
bop/bin:/soft/lcrc/bebop/bin
LD_LIBRARY_PATH: /blues/gpfs/software/centos7/spack/opt/spack/linux-cen=
tos7-x86_64/intel-18.0.4/openmpi-3.1.3-7wj2dww/lib:/blues/gpfs/software=
/centos7/spack/opt/spack/linux-centos7-x86_64/gcc-4.8.5/gcc-8.1.0-dc4ta=
u6/lib64:/blues/gpfs/software/centos7/spack/opt/spack/linux-centos7-x86=
_64/gcc-4.8.5/gcc-8.1.0-dc4tau6/lib:/blues/gpfs/software/centos7/spack/=
opt/spack/linux-centos7-x86_64/gcc-8.1.0/intel-18.0.4-443hhug/compilers=
_and_libraries_2018.5.274/linux/compiler/lib/intel64:/blues/gpfs/softwa=
re/centos7/spack/opt/spack/linux-centos7-x86_64/gcc-8.1.0/intel-18.0.4-=
443hhug/compilers_and_libraries_2018.5.274/linux/compiler/lib/intel64_l=
in:/blues/gpfs/software/centos7/spack/opt/spack/linux-centos7-x86_64/gc=
c-8.1.0/intel-18.0.4-443hhug/compilers_and_libraries_2018.5.274/linux/m=
pi/intel64/lib:/blues/gpfs/software/centos7/spack/opt/spack/linux-cento=
s7-x86_64/gcc-8.1.0/intel-18.0.4-443hhug/compilers_and_libraries_2018.5=
.274/linux/mpi/mic/lib:/blues/gpfs/software/centos7/spack/opt/spack/lin=
ux-centos7-x86_64/gcc-8.1.0/intel-18.0.4-443hhug/compilers_and_librarie=
s_2018.5.274/linux/tbb/lib/intel64/gcc4.7:/blues/gpfs/software/centos7/=
spack/opt/spack/linux-centos7-x86_64/gcc-8.1.0/intel-18.0.4-443hhug/lib
=20
--------------------------------------------------------------
 * Compilers, Linkers, Flags, and Libraries *
Location of the preprocessor:      /blues/gpfs/software/centos7/spack/o=
pt/spack/linux-centos7-x86_64/gcc-4.8.5/gcc-8.1.0-dc4tau6/bin/gcc
Location of the Fortran compiler:  /blues/gpfs/software/centos7/spack/o=
pt/spack/linux-centos7-x86_64/intel-18.0.4/openmpi-3.1.3-7wj2dww/bin/mp=
ifort
Location of the Fortran linker:    /blues/gpfs/software/centos7/spack/o=
pt/spack/linux-centos7-x86_64/intel-18.0.4/openmpi-3.1.3-7wj2dww/bin/mp=
ifort
Location of the C++ compiler:      /blues/gpfs/software/centos7/spack/o=
pt/spack/linux-centos7-x86_64/intel-18.0.4/openmpi-3.1.3-7wj2dww/bin/mp=
icxx
Location of the C++ linker:        /blues/gpfs/software/centos7/spack/o=
pt/spack/linux-centos7-x86_64/intel-18.0.4/openmpi-3.1.3-7wj2dww/bin/mp=
icxx

Fortran compiler flags:
ESMF_F90COMPILER: mpifort
ESMF_F90COMPILEOPTS: -O -fPIC -assume realloc_lhs -m64 -mcmodel=3Dsmall=
 -threads  -qopenmp
ESMF_F90COMPILEPATHS: -I/lcrc/project/ESMF/scripts_dirs/daily_builds/in=
tel_bebop/esmf/mod/modO/Linux.intel.64.openmpi.default -I/lcrc/project/=
ESMF/scripts_dirs/daily_builds/intel_bebop/esmf/src/include -I/home/sva=
squez/proj4/include
ESMF_F90COMPILECPPFLAGS: -DESMF_NO_INTEGER_1_BYTE -DESMF_NO_INTEGER_2_B=
YTE -DESMFVERSIONGIT=3D'ESMF_8_1_0_beta_snapshot_11' -DESMF_MOAB=3D1 -D=
ESMF_LAPACK=3D1 -DESMF_LAPACK_INTERNAL=3D1 -DESMF_NO_ACC_SOFTWARE_STACK=
=3D1 -DESMF_YAMLCPP=3D1 -DESMF_YAML=3D1 -DESMF_PIO=3D1 -DESMF_MPIIO -DE=
SMF_PROJ4=3D1 -DESMF_NO_OPENACC -DESMF_TESTEXHAUSTIVE -DESMF_BOPT_O -DS=
x86_64_small=3D1 -DESMF_OS_Linux=3D1 -DESMF_COMM=3Dopenmpi -DESMF_DIR=
=3D/lcrc/project/ESMF/scripts_dirs/daily_builds/intel_bebop/esmf
ESMF_F90COMPILEFREECPP:=20
ESMF_F90COMPILEFREENOCPP:=20
ESMF_F90COMPILEFIXCPP:=20
ESMF_F90COMPILEFIXNOCPP:=20

Fortran linker flags:
ESMF_F90LINKOPTS:   -m64 -mcmodel=3Dsmall -threads -Wl,--no-as-needed  =
-qopenmp
ESMF_F90LINKPATHS: -L/lcrc/project/ESMF/scripts_dirs/daily_builds/intel=
_bebop/esmf/lib/libO/Linux.intel.64.openmpi.default -L/home/svasquez/pr=
oj4/lib=20
ESMF_F90LINKRPATHS: -Wl,-rpath,/lcrc/project/ESMF/scripts_dirs/daily_bu=
ilds/intel_bebop/esmf/lib/libO/Linux.intel.64.openmpi.default  -Wl,-rpa=
th,/home/svasquez/proj4/lib
ESMF_F90LINKLIBS:  -lmpi_cxx -cxxlib -lrt -ldl -lproj
ESMF_F90ESMFLINKLIBS: -lesmf  -lmpi_cxx -cxxlib -lrt -ldl -lproj

C++ compiler flags:
ESMF_CXXCOMPILER: mpicxx
ESMF_CXXCOMPILEOPTS: -std=3Dc++11 -O -DNDEBUG -fPIC -m64 -mcmodel=3Dsma=
ll -pthread  -qopenmp
ESMF_CXXCOMPILEPATHS:  -I/lcrc/project/ESMF/scripts_dirs/daily_builds/i=
ntel_bebop/esmf/src/include  -I/home/svasquez/proj4/include -I/lcrc/pro=
ject/ESMF/scripts_dirs/daily_builds/intel_bebop/esmf/src/prologue/yaml-=
cpp/include
ESMF_CXXCOMPILECPPFLAGS: -DESMF_NO_INTEGER_1_BYTE -DESMF_NO_INTEGER_2_B=
YTE -DESMFVERSIONGIT=3D'ESMF_8_1_0_beta_snapshot_11' -DESMF_MOAB=3D1 -D=
ESMF_LAPACK=3D1 -DESMF_LAPACK_INTERNAL=3D1 -DESMF_NO_ACC_SOFTWARE_STACK=
=3D1 -DESMF_YAMLCPP=3D1 -DESMF_YAML=3D1 -DESMF_PIO=3D1 -DESMF_MPIIO -DE=
SMF_PROJ4=3D1 -DESMF_NO_OPENACC -DESMF_TESTEXHAUSTIVE -DESMF_BOPT_O -DS=
x86_64_small=3D1 -DESMF_OS_Linux=3D1 -DESMF_COMM=3Dopenmpi -DESMF_DIR=
=3D/lcrc/project/ESMF/scripts_dirs/daily_builds/intel_bebop/esmf -D__SD=
IR__=3D'' -DESMF_CXXSTD=3D11 -DESMF_NO_SIGUSR2

C++ linker flags:
ESMF_CXXLINKOPTS:   -m64 -mcmodel=3Dsmall -pthread -Wl,--no-as-needed  =
-qopenmp
ESMF_CXXLINKPATHS: -L/lcrc/project/ESMF/scripts_dirs/daily_builds/intel=
_bebop/esmf/lib/libO/Linux.intel.64.openmpi.default -L/home/svasquez/pr=
oj4/lib -L/blues/gpfs/software/centos7/spack/opt/spack/linux-centos7-x8=
6_64/gcc-8.1.0/intel-18.0.4-443hhug/compilers_and_libraries_2018.5.274/=
linux/compiler/lib/intel64_lin/
ESMF_CXXLINKRPATHS: -Wl,-rpath,/lcrc/project/ESMF/scripts_dirs/daily_bu=
ilds/intel_bebop/esmf/lib/libO/Linux.intel.64.openmpi.default  -Wl,-rpa=
th,/home/svasquez/proj4/lib -Wl,-rpath,/blues/gpfs/software/centos7/spa=
ck/opt/spack/linux-centos7-x86_64/gcc-8.1.0/intel-18.0.4-443hhug/compil=
ers_and_libraries_2018.5.274/linux/compiler/lib/intel64_lin/
ESMF_CXXLINKLIBS:  -lmpi_mpifh -lifport -lifcoremt -limf -lsvml -lm -li=
pgo -liomp5 -lintlc -lpthread -lsvml -lgcc -lgcc_s -lirc_s -ldl -lrt -l=
dl -lproj
ESMF_CXXESMFLINKLIBS: -lesmf  -lmpi_mpifh -lifport -lifcoremt -limf -ls=
vml -lm -lipgo -liomp5 -lintlc -lpthread -lsvml -lgcc -lgcc_s -lirc_s -=
ldl -lrt -ldl -lproj

Shared library build:
ESMF_SL_LIBS_TO_MAKE: libesmf
ESMF_SL_SUFFIX:       so
ESMF_SL_LIBLINKER:    mpicxx
ESMF_SL_LIBOPTS:       -pthread -shared  -qopenmp
ESMF_SL_LIBLIBS:     =20

ESMF Tracing linker options:
ESMF_TRACE_LDPRELOAD=3D/lcrc/project/ESMF/scripts_dirs/daily_builds/int=
el_bebop/esmf/lib/libO/Linux.intel.64.openmpi.default/libesmftrace_prel=
oad.so
ESMF_TRACE_STATICLINKOPTS=3D-static -Wl,--wrap=3Dc_esmftrace_notify_wra=
ppers -Wl,--wrap=3Dc_esmftrace_isinitialized -Wl,--wrap=3Dwrite -Wl,--w=
rap=3Dwritev -Wl,--wrap=3Dpwrite -Wl,--wrap=3Dread -Wl,--wrap=3Dopen -W=
l,--wrap=3DMPI_Allgather -Wl,--wrap=3DMPI_Allgatherv -Wl,--wrap=3DMPI_A=
llreduce -Wl,--wrap=3DMPI_Alltoall -Wl,--wrap=3DMPI_Alltoallv -Wl,--wra=
p=3DMPI_Alltoallw -Wl,--wrap=3DMPI_Barrier -Wl,--wrap=3DMPI_Bcast -Wl,-=
-wrap=3DMPI_Gather -Wl,--wrap=3DMPI_Gatherv -Wl,--wrap=3DMPI_Recv -Wl,-=
-wrap=3DMPI_Reduce -Wl,--wrap=3DMPI_Scatter -Wl,--wrap=3DMPI_Send -Wl,-=
-wrap=3DMPI_Sendrecv -Wl,--wrap=3DMPI_Wait -Wl,--wrap=3DMPI_Waitall -Wl=
,--wrap=3DMPI_Waitany -Wl,--wrap=3DMPI_Waitsome -Wl,--wrap=3Dmpi_allgat=
her_ -Wl,--wrap=3Dmpi_allgather__ -Wl,--wrap=3Dmpi_allgatherv_ -Wl,--wr=
ap=3Dmpi_allgatherv__ -Wl,--wrap=3Dmpi_allreduce_ -Wl,--wrap=3Dmpi_allr=
educe__ -Wl,--wrap=3Dmpi_alltoall_ -Wl,--wrap=3Dmpi_alltoall__ -Wl,--wr=
ap=3Dmpi_alltoallv_ -Wl,--wrap=3Dmpi_alltoallv__ -Wl,--wrap=3Dmpi_allto=
allw_ -Wl,--wrap=3Dmpi_alltoallw__ -Wl,--wrap=3Dmpi_barrier_ -Wl,--wrap=
=3Dmpi_barrier__ -Wl,--wrap=3Dmpi_bcast_ -Wl,--wrap=3Dmpi_bcast__ -Wl,-=
-wrap=3Dmpi_exscan_ -Wl,--wrap=3Dmpi_exscan__ -Wl,--wrap=3Dmpi_gather_ =
-Wl,--wrap=3Dmpi_gather__ -Wl,--wrap=3Dmpi_gatherv_ -Wl,--wrap=3Dmpi_ga=
therv__ -Wl,--wrap=3Dmpi_recv_ -Wl,--wrap=3Dmpi_recv__ -Wl,--wrap=3Dmpi=
_reduce_ -Wl,--wrap=3Dmpi_reduce__ -Wl,--wrap=3Dmpi_reduce_scatter_ -Wl=
,--wrap=3Dmpi_reduce_scatter__ -Wl,--wrap=3Dmpi_scatter_ -Wl,--wrap=3Dm=
pi_scatter__ -Wl,--wrap=3Dmpi_scatterv_ -Wl,--wrap=3Dmpi_scatterv__ -Wl=
,--wrap=3Dmpi_scan_ -Wl,--wrap=3Dmpi_scan__ -Wl,--wrap=3Dmpi_send_ -Wl,=
--wrap=3Dmpi_send__ -Wl,--wrap=3Dmpi_wait_ -Wl,--wrap=3Dmpi_wait__ -Wl,=
--wrap=3Dmpi_waitall_ -Wl,--wrap=3Dmpi_waitall__ -Wl,--wrap=3Dmpi_waita=
ny_ -Wl,--wrap=3Dmpi_waitany__
ESMF_TRACE_STATICLINKLIBS=3D-lesmftrace_static


--------------------------------------------------------------
Compiling on Mon Mar 16 14:45:52 CDT 2020 on beboplogin2
Machine characteristics: Linux beboplogin2 3.10.0-957.21.3.el7.x86_64 #=
1 SMP Tue Jun 18 16:35:19 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
=20
Mon Mar 16 15:13:54 CDT 2020 library build -j16 ...........PASS
Mon Mar 16 15:14:39 CDT 2020 library install -j4 ..........PASS
Mon Mar 16 15:14:42 CDT 2020 library installcheck -j4 .....PASS
Mon Mar 16 15:19:22 CDT 2020 quickstart build -j4 .........PASS

|------------------------ APPs TESTS --------------------------|
Mon Mar 16 15:19:45 CDT 2020 apps build -j4 ...............PASS

|--------------------------------------------------------------|
Mon Mar 16 15:27:16 CDT 2020 ESMF_Regrid --help ***********FAIL
The following is the output of ESMF_Regrid --help

-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init
*** on a NULL communicator
*** An error occurred in MPI_Init
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
*** An error occurred in MPI_Init
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
*** An error occurred in MPI_Init
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0053:101240] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0053:101241] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
[bdw-0053:101238] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
[bdw-0053:101239] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
srun: error: bdw-0053: tasks 0-3: Exited with exit code 1



|--------------------------------------------------------------|
Mon Mar 16 15:27:16 CDT 2020 ESMF_Regrid --version ********FAIL
The following is the output of ESMF_Regrid --version

-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0053:101255] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0053:101256] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0053:101257] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0053:101258] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
srun: error: bdw-0053: tasks 0-3: Exited with exit code 1



|--------------------------------------------------------------|
Mon Mar 16 15:27:17 CDT 2020 ESMF_Regrid -V ***************FAIL
The following is the output of ESMF_Regrid -V

-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0053:101272] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0053:101271] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0053:101270] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0053:101273] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
srun: error: bdw-0053: tasks 0-3: Exited with exit code 1



|--------------------------------------------------------------|
Mon Mar 16 15:27:18 CDT 2020 ESMF_Info --help *************FAIL
The following is the output of ESMF_Info --help=20

-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init_thread
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init_thread
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0053:101287] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0053:101285] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init_thread
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0053:101286] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init_thread
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0053:101288] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
srun: error: bdw-0053: tasks 0-3: Exited with exit code 1



|--------------------------------------------------------------|
Mon Mar 16 15:27:19 CDT 2020 ESMF_Info --version **********FAIL
The following is the output of ESMF_Info --version=20

-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init_thread
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0053:101300] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init_thread
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0053:101302] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init_thread
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0053:101303] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init_thread
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0053:101301] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
srun: error: bdw-0053: tasks 0-3: Exited with exit code 1



|--------------------------------------------------------------|
Mon Mar 16 15:27:20 CDT 2020 ESMF_Info -V *****************FAIL
The following is the output of ESMF_Info -V=20

-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init_thread
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0053:101315] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init_thread
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0053:101317] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init_thread
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0053:101316] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init_thread
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0053:101314] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
srun: error: bdw-0053: tasks 0-3: Exited with exit code 1



|--------------------------------------------------------------|
Mon Mar 16 15:27:20 CDT 2020 ESMF_InfoC --help ************FAIL
The following is the output of ESMF_InfoC --help

-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init_thread
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0053:101329] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init_thread
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0053:101330] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init_thread
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0053:101331] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init_thread
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0053:101332] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
srun: error: bdw-0053: tasks 0-3: Exited with exit code 1



|--------------------------------------------------------------|
Mon Mar 16 15:27:21 CDT 2020 ESMF_InfoC --version *********FAIL
The following is the output of ESMF_InfoC --version

-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init_thread
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0053:101346] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init_thread
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0053:101345] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init_thread
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0053:101343] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init_thread
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0053:101344] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
srun: error: bdw-0053: tasks 0-3: Exited with exit code 1



|--------------------------------------------------------------|
Mon Mar 16 15:27:22 CDT 2020 ESMF_InfoC -V ****************FAIL
The following is the output of ESMF_InfoC -V

-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init_thread
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0053:101361] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init_thread
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0053:101359] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init_thread
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0053:101360] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init_thread
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0053:101358] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
srun: error: bdw-0053: tasks 0-3: Exited with exit code 1



|--------------------------------------------------------------|
Mon Mar 16 15:27:23 CDT 2020 ESMF_RegridWeightGen --help **FAIL
The following is the output of ESMF_RegridWeightGen --help

-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0053:101375] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0053:101376] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0053:101373] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0053:101374] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
srun: error: bdw-0053: tasks 0-3: Exited with exit code 1



|--------------------------------------------------------------|
Mon Mar 16 15:27:24 CDT 2020 ESMF_RegridWeightGen --version FAIL
The following is the output of ESMF_RegridWeightGen --version

-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0053:101388] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0053:101391] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0053:101389] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0053:101390] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
srun: error: bdw-0053: tasks 0-3: Exited with exit code 1



|--------------------------------------------------------------|
Mon Mar 16 15:27:24 CDT 2020 ESMF_RegridWeightGen -V ******FAIL
The following is the output of ESMF_RegridWeightGen -V

-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0053:101405] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0053:101402] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0053:101403] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0053:101404] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
srun: error: bdw-0053: tasks 0-3: Exited with exit code 1



|--------------------------------------------------------------|
Mon Mar 16 15:27:25 CDT 2020 ESMF_Scrip2Unstruct --help ***FAIL
The following is the output of ESMF_Scrip2Unstruct --help

-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init_thread
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0053:101420] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init_thread
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0053:101417] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init_thread
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0053:101419] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init_thread
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0053:101418] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
srun: error: bdw-0053: tasks 0-3: Exited with exit code 1



|--------------------------------------------------------------|
Mon Mar 16 15:27:26 CDT 2020 ESMF_Scrip2Unstruct --version FAIL
The following is the output of ESMF_Scrip2Unstruct --version

-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init_thread
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0053:101433] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init_thread
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0053:101431] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init_thread
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0053:101434] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init_thread
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0053:101432] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
srun: error: bdw-0053: tasks 0-3: Exited with exit code 1



|--------------------------------------------------------------|
Mon Mar 16 15:27:27 CDT 2020 ESMF_Scrip2Unstruct -V *******FAIL
The following is the output of ESMF_Scrip2Unstruct -V

-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init_thread
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0053:101447] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init_thread
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0053:101446] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init_thread
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0053:101449] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
-----------------------------------------------------------------------=
---
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
-----------------------------------------------------------------------=
---
*** An error occurred in MPI_Init_thread
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort=
,
***    and potentially your MPI job)
[bdw-0053:101448] Local abort before MPI_INIT completed completed succe=
ssfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!
srun: error: bdw-0053: tasks 0-3: Exited with exit code 1



|--------------------------------------------------------------|
Mon Mar 16 15:27:28 CDT 2020 ESMF_WebServController --help PASS
The following is the output of ESMF_WebServController --help

ESMF_WebServController: Run a Process Controller that provides access t=
o an ESMF Web Service enabled Component.
Usage: ESMF_WebServController [--help] [--version] [-V] procCtrlPort re=
gistrarHost registrarPort
    [--help]        Display this information and exit.
    [--version]     Display ESMF version and license information and ex=
it.
    [-V]            Display ESMF version string and exit.
    procCtrlPort    Port num for Process Controller listener.
    registrarHost   Host name on which Registrar is running.
    registrarPort   Port num on which Registrar is listening.
    runScriptDir    Directory containing run script.
    runScriptFile   File name of run script.




|--------------------------------------------------------------|
Mon Mar 16 15:27:28 CDT 2020 ESMF_WebServController --version PASS
The following is the output of ESMF_WebServController --version

   ESMF_VERSION_STRING:       8.1.0 beta snapshot
   ESMF_VERSION_MAJOR:                   8
   ESMF_VERSION_MINOR:                   1
   ESMF_VERSION_REVISION:                0
   ESMF_VERSION_PATCHLEVEL:              0
   ESMF_VERSION_PUBLIC:        F
   ESMF_VERSION_BETASNAPSHOT:  T
=20
 Earth System Modeling Framework
=20
 Copyright (c) 2002-2020 University Corporation for Atmospheric Researc=
h,
 Massachusetts Institute of Technology, Geophysical Fluid Dynamics Labo=
ratory,
 University of Michigan, National Centers for Environmental Prediction,
 Los Alamos National Laboratory, Argonne National Laboratory,
 NASA Goddard Space Flight Center.
 All rights reserved.
=20
 Permission is hereby granted, free of charge, to any person obtaining =
a copy
 of this software and associated documentation files (the 'Software'), =
to
 deal with the Software without restriction, including without limitati=
on the
 rights to use, copy, modify, merge, publish, distribute, sublicense, a=
nd/or
 sell copies of the Software, and to permit persons to whom the Softwar=
e is
 furnished to do so, subject to the following conditions:
    1. Redistributions of source code must retain the above copyright n=
otice,
       this list of conditions and the following disclaimers.
    2. Redistributions in binary form must reproduce the above copyrigh=
t
       notice, this list of conditions and the following disclaimers in=
 the
       documentation and/or other materials provided with the distribut=
ion.
    3. Neither the names of the organizations developing this software,=
 nor
       the names of its contributors may be used to endorse or promote =
products
       derived from this Software without specific prior written permis=
sion.
=20
 THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRES=
S OR
 IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILIT=
Y,
 FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHAL=
L THE
 CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR =
OTHER
 LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISIN=
G
 FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DE=
ALINGS
 WITH THE SOFTWARE.



|--------------------------------------------------------------|
Mon Mar 16 15:27:28 CDT 2020 ESMF_WebServController -V ....PASS
The following is the output of ESMF_WebServController -V

   ESMF_VERSION_STRING:       8.1.0 beta snapshot




Ran 18 applications tests, 3 passed and 15 failed.

|----------------------- SYSTEM TESTS -------------------------|
Mon Mar 16 15:35:47 CDT 2020 build_system_tests -j4 .......PASS
Mon Mar 16 15:39:12 CDT 2020 run_system_tests .............PASS


The following system tests passed:


PASS: openmpi/O: src/system_tests/ESMF_ArrayBundleRedist/ESMF_ArrayBund=
leRedistSTest.F90
PASS: openmpi/O: src/system_tests/ESMF_ArrayBundleSparseMatMul/ESMF_Arr=
ayBundleSparseMatMulSTest.F90
PASS: openmpi/O: src/system_tests/ESMF_ArrayRedist/ESMF_ArrayRedistSTes=
t.F90
PASS: openmpi/O: src/system_tests/ESMF_ArrayRedist3D/ESMF_ArrayRedist3D=
STest.F90
PASS: openmpi/O: src/system_tests/ESMF_ArrayRedistOpenACC/ESMF_ArrayRed=
istOpenACCSTest.F90
PASS: openmpi/O: src/system_tests/ESMF_ArrayRedistOpenMP/ESMF_ArrayRedi=
stOpenMPSTest.F90
PASS: openmpi/O: src/system_tests/ESMF_ArrayScatterGather/ESMF_ArraySca=
tterGatherSTest.F90
PASS: openmpi/O: src/system_tests/ESMF_ArraySharedDeSSI/ESMF_ArrayShare=
dDeSSISTest.F90
PASS: openmpi/O: src/system_tests/ESMF_ArraySparseMatMul/ESMF_ArraySpar=
seMatMulSTest.F90
PASS: openmpi/O: src/system_tests/ESMF_Attribute/ESMF_AttributeSTest.F9=
0
PASS: openmpi/O: src/system_tests/ESMF_AttributeCIM/ESMF_AttributeCIMST=
est.F90
PASS: openmpi/O: src/system_tests/ESMF_CompCreate/ESMF_CompCreateSTest.=
F90
PASS: openmpi/O: src/system_tests/ESMF_CompFortranAndC/ESMF_CompFortran=
AndCSTest.F90
PASS: openmpi/O: src/system_tests/ESMF_ComplianceChecker/ESMF_Complianc=
eCheckerSTest.F90
PASS: openmpi/O: src/system_tests/ESMF_ConcurrentComponent/ESMF_Concurr=
entCompSTest.F90
PASS: openmpi/O: src/system_tests/ESMF_ConcurrentEnsemble/ESMF_Concurre=
ntEnsembleSTest.F90
PASS: openmpi/O: src/system_tests/ESMF_DirectCoupling/ESMF_DirectCoupli=
ngSTest.F90
PASS: openmpi/O: src/system_tests/ESMF_FieldBundleLSRedistArb2Arb/ESMF_=
FieldBundleLSRedistArb2ArbSTest.F90
PASS: openmpi/O: src/system_tests/ESMF_FieldBundleLSRedistArb2ArbUngrdD=
im/ESMF_FieldBundleLSRedistArb2ArbUngrdDimSTest.F90
PASS: openmpi/O: src/system_tests/ESMF_FieldBundleRedistArb2Arb/ESMF_Fi=
eldBundleRedistArb2ArbSTest.F90
PASS: openmpi/O: src/system_tests/ESMF_FieldBundleRedistBlk2Arb/ESMF_Fi=
eldBundleRedistBlk2ArbSTest.F90
PASS: openmpi/O: src/system_tests/ESMF_FieldBundleRedistBlk2Blk/ESMF_Fi=
eldBundleRedistBlk2BlkSTest.F90
PASS: openmpi/O: src/system_tests/ESMF_FieldBundleSMM/ESMF_FieldBundleS=
MMSTest.F90
PASS: openmpi/O: src/system_tests/ESMF_FieldBundleSMMPacked/ESMF_FieldB=
undleSMMPackedSTest.F90
PASS: openmpi/O: src/system_tests/ESMF_FieldConcurrentComp/ESMF_FieldCo=
nCompSTest.F90
PASS: openmpi/O: src/system_tests/ESMF_FieldLSRedistArb2Arb/ESMF_FieldL=
SRedistArb2ArbSTest.F90
PASS: openmpi/O: src/system_tests/ESMF_FieldLSRedistArb2ArbUngrdDim/ESM=
F_FieldLSRedistArb2ArbUngrdDimSTest.F90
PASS: openmpi/O: src/system_tests/ESMF_FieldLSSMM/ESMF_FieldLSSMMSTest.=
F90
PASS: openmpi/O: src/system_tests/ESMF_FieldMeshSMM/ESMF_FieldMeshSMMST=
est.F90
PASS: openmpi/O: src/system_tests/ESMF_FieldRedist/ESMF_FieldRedistSTes=
t.F90
PASS: openmpi/O: src/system_tests/ESMF_FieldRedistArb2Arb/ESMF_FieldRed=
istArb2ArbSTest.F90
PASS: openmpi/O: src/system_tests/ESMF_FieldRedistBlk2Arb/ESMF_FieldRed=
istBlk2ArbSTest.F90
PASS: openmpi/O: src/system_tests/ESMF_FieldRedistBlk2Blk/ESMF_FieldRed=
istBlk2BlkSTest.F90
PASS: openmpi/O: src/system_tests/ESMF_FieldRegrid/ESMF_FieldRegridSTes=
t.F90
PASS: openmpi/O: src/system_tests/ESMF_FieldRegridDisjoint/ESMF_FieldRe=
gridDisjointSTest.F90
PASS: openmpi/O: src/system_tests/ESMF_FieldRegridMesh/ESMF_FieldRegrid=
MeshSTest.F90
PASS: openmpi/O: src/system_tests/ESMF_FieldRegridMeshToMesh/ESMF_Field=
RegridMeshToMeshSTest.F90
PASS: openmpi/O: src/system_tests/ESMF_FieldRegridOverlap/ESMF_FieldReg=
ridOverlapSTest.F90
PASS: openmpi/O: src/system_tests/ESMF_FieldSparseMatMul/ESMF_FieldSpar=
seMatMulSTest.F90
PASS: openmpi/O: src/system_tests/ESMF_RecursiveComponent/ESMF_Recursiv=
eComponentSTest.F90
PASS: openmpi/O: src/system_tests/ESMF_SequentialEnsemble/ESMF_Sequenti=
alEnsembleSTest.F90
PASS: openmpi/O: src/system_tests/ESMF_Trace/ESMF_TraceSTest.F90
PASS: openmpi/O: src/system_tests/ESMF_TransferGrid/ESMF_TransferGridST=
est.F90
PASS: openmpi/O: src/system_tests/ESMF_TransferMesh/ESMF_TransferMeshST=
est.F90
PASS: openmpi/O: src/system_tests/ESMF_XGridConcurrent/ESMF_XGridConcur=
rentSTest.F90
PASS: openmpi/O: src/system_tests/ESMF_XGridSerial/ESMF_XGridSerialSTes=
t.F90




The stdout files for the system_tests can be found at:
/lcrc/project/ESMF/scripts_dirs/daily_builds/intel_bebop/esmf/test/test=
O/Linux.intel.64.openmpi.default


Found 46 multi-processor system tests, 46 passed and 0 failed.



|------------------------- EXAMPLES ---------------------------|
Mon Mar 16 15:53:27 CDT 2020 build_examples -j4 ...........PASS
Mon Mar 16 16:01:24 CDT 2020 run_examples .................PASS


The following examples passed:


PASS: openmpi/O: src/Infrastructure/Array/examples/ESMF_ArrayArbHaloEx.=
F90
PASS: openmpi/O: src/Infrastructure/Array/examples/ESMF_ArrayCommNBEx.F=
90
PASS: openmpi/O: src/Infrastructure/Array/examples/ESMF_ArrayEx.F90
PASS: openmpi/O: src/Infrastructure/Array/examples/ESMF_ArrayFarrayEx.F=
90
PASS: openmpi/O: src/Infrastructure/Array/examples/ESMF_ArrayFarrayHalo=
Ex.F90
PASS: openmpi/O: src/Infrastructure/Array/examples/ESMF_ArrayHaloEx.F90
PASS: openmpi/O: src/Infrastructure/Array/examples/ESMF_ArrayLarrayEx.F=
90
PASS: openmpi/O: src/Infrastructure/Array/examples/ESMF_ArrayRedistEx.F=
90
PASS: openmpi/O: src/Infrastructure/Array/examples/ESMF_ArrayScatterGat=
herArbEx.F90
PASS: openmpi/O: src/Infrastructure/Array/examples/ESMF_ArrayScatterGat=
herEx.F90
PASS: openmpi/O: src/Infrastructure/Array/examples/ESMF_ArraySparseMatM=
ulEx.F90
PASS: openmpi/O: src/Infrastructure/ArrayBundle/examples/ESMF_ArrayBund=
leEx.F90
PASS: openmpi/O: src/Infrastructure/ArrayBundle/examples/ESMF_ArrayBund=
leHaloEx.F90
PASS: openmpi/O: src/Infrastructure/ArraySpec/examples/ESMF_ArraySpecEx=
.F90
PASS: openmpi/O: src/Infrastructure/Config/examples/ESMF_ConfigOverview=
Ex.F90
PASS: openmpi/O: src/Infrastructure/DELayout/examples/ESMF_DELayoutEx.F=
90
PASS: openmpi/O: src/Infrastructure/DistGrid/examples/ESMF_DistGridEx.F=
90
PASS: openmpi/O: src/Infrastructure/Field/examples/ESMF_FieldArbGridEx.=
F90
PASS: openmpi/O: src/Infrastructure/Field/examples/ESMF_FieldCommEx.F90
PASS: openmpi/O: src/Infrastructure/Field/examples/ESMF_FieldCreateEx.F=
90
PASS: openmpi/O: src/Infrastructure/Field/examples/ESMF_FieldEx.F90
PASS: openmpi/O: src/Infrastructure/Field/examples/ESMF_FieldHaloEx.F90
PASS: openmpi/O: src/Infrastructure/Field/examples/ESMF_FieldMeshRegrid=
Ex.F90
PASS: openmpi/O: src/Infrastructure/Field/examples/ESMF_FieldRedistEx.F=
90
PASS: openmpi/O: src/Infrastructure/Field/examples/ESMF_FieldRegridEx.F=
90
PASS: openmpi/O: src/Infrastructure/Field/examples/ESMF_FieldRegridMask=
Ex.F90
PASS: openmpi/O: src/Infrastructure/Field/examples/ESMF_FieldRepDimEx.F=
90
PASS: openmpi/O: src/Infrastructure/Field/examples/ESMF_FieldSMMEx.F90
PASS: openmpi/O: src/Infrastructure/Field/examples/ESMF_FieldSphereRegr=
idEx.F90
PASS: openmpi/O: src/Infrastructure/FieldBundle/examples/ESMF_FieldBund=
leCreateEx.F90
PASS: openmpi/O: src/Infrastructure/FieldBundle/examples/ESMF_FieldBund=
leHaloEx.F90
PASS: openmpi/O: src/Infrastructure/FieldBundle/examples/ESMF_FieldBund=
leRedistEx.F90
PASS: openmpi/O: src/Infrastructure/FieldBundle/examples/ESMF_FieldBund=
leSMMEx.F90
PASS: openmpi/O: src/Infrastructure/Grid/examples/ESMF_GridCreateRegFro=
mDGEx.F90
PASS: openmpi/O: src/Infrastructure/Grid/examples/ESMF_GridUsageEx.F90
PASS: openmpi/O: src/Infrastructure/LocStream/examples/ESMF_LocStreamEx=
.F90
PASS: openmpi/O: src/Infrastructure/LogErr/examples/ESMF_LogErrEx.F90
PASS: openmpi/O: src/Infrastructure/Mesh/examples/ESMF_MeshEx.F90
PASS: openmpi/O: src/Infrastructure/Route/examples/ESMF_RHandleBitForBi=
tEx.F90
PASS: openmpi/O: src/Infrastructure/Route/examples/ESMF_RHandleDynamicM=
askingEx.F90
PASS: openmpi/O: src/Infrastructure/Route/examples/ESMF_RHandleFromFile=
Ex.F90
PASS: openmpi/O: src/Infrastructure/Route/examples/ESMF_RHandleFromRHan=
dleEx.F90
PASS: openmpi/O: src/Infrastructure/Route/examples/ESMF_RHandleReusabil=
ityEx.F90
PASS: openmpi/O: src/Infrastructure/TimeMgr/examples/ESMF_AlarmEx.F90
PASS: openmpi/O: src/Infrastructure/TimeMgr/examples/ESMF_CalendarEx.F9=
0
PASS: openmpi/O: src/Infrastructure/TimeMgr/examples/ESMF_ClockEx.F90
PASS: openmpi/O: src/Infrastructure/TimeMgr/examples/ESMF_TimeEx.F90
PASS: openmpi/O: src/Infrastructure/TimeMgr/examples/ESMF_TimeIntervalE=
x.F90
PASS: openmpi/O: src/Infrastructure/Trace/examples/ESMF_TraceEx.F90
PASS: openmpi/O: src/Infrastructure/Trace/examples/ESMF_TraceUserEx.F90
PASS: openmpi/O: src/Infrastructure/VM/examples/ESMF_VMAllFullReduceEx.=
F90
PASS: openmpi/O: src/Infrastructure/VM/examples/ESMF_VMComponentEx.F90
PASS: openmpi/O: src/Infrastructure/VM/examples/ESMF_VMDefaultBasicsEx.=
F90
PASS: openmpi/O: src/Infrastructure/VM/examples/ESMF_VMGetMPICommunicat=
orEx.F90
PASS: openmpi/O: src/Infrastructure/VM/examples/ESMF_VMHigherRankDataEx=
.F90
PASS: openmpi/O: src/Infrastructure/VM/examples/ESMF_VMScatterVMGatherE=
x.F90
PASS: openmpi/O: src/Infrastructure/VM/examples/ESMF_VMSendVMRecvEx.F90
PASS: openmpi/O: src/Infrastructure/VM/examples/ESMF_VMUserMpiCommEx.F9=
0
PASS: openmpi/O: src/Infrastructure/VM/examples/ESMF_VMUserMpiCommMulti=
Ex.F90
PASS: openmpi/O: src/Infrastructure/VM/examples/ESMF_VMUserMpiEx.F90
PASS: openmpi/O: src/Infrastructure/XGrid/examples/ESMF_XGridEx.F90
PASS: openmpi/O: src/Infrastructure/XGrid/examples/ESMF_XGridSparseMatE=
x.F90
PASS: openmpi/O: src/Superstructure/AttachMethods/examples/ESMF_AttachM=
ethodsEx.F90
PASS: openmpi/O: src/Superstructure/AttributeAPI/examples/ESMF_AttReadC=
ustCplCompEx.F90
PASS: openmpi/O: src/Superstructure/AttributeAPI/examples/ESMF_AttReadF=
ieldEx.F90
PASS: openmpi/O: src/Superstructure/AttributeAPI/examples/ESMF_AttReadG=
ridCompEx.F90
PASS: openmpi/O: src/Superstructure/AttributeAPI/examples/ESMF_Attribut=
eCIMEx.F90
PASS: openmpi/O: src/Superstructure/AttributeAPI/examples/ESMF_Attribut=
eCustPackEx.F90
PASS: openmpi/O: src/Superstructure/AttributeAPI/examples/ESMF_Attribut=
eEx.F90
PASS: openmpi/O: src/Superstructure/AttributeAPI/examples/ESMF_Attribut=
eInternalInfoEx.F90
PASS: openmpi/O: src/Superstructure/AttributeAPI/examples/ESMF_Attribut=
ePackageEx.F90
PASS: openmpi/O: src/Superstructure/AttributeAPI/examples/ESMF_Attribut=
eUpdateEx.F90
PASS: openmpi/O: src/Superstructure/Component/examples/ESMF_AppMainEx.F=
90
PASS: openmpi/O: src/Superstructure/Component/examples/ESMF_CompTunnelE=
x.F90
PASS: openmpi/O: src/Superstructure/Component/examples/ESMF_CplEx.F90
PASS: openmpi/O: src/Superstructure/Component/examples/ESMF_GCompEx.F90
PASS: openmpi/O: src/Superstructure/Component/examples/ESMF_InternalSta=
teEx.F90
PASS: openmpi/O: src/Superstructure/Component/examples/ESMF_InternalSta=
teModEx.F90
PASS: openmpi/O: src/Superstructure/Component/examples/ESMF_SCompEx.F90
PASS: openmpi/O: src/Superstructure/State/examples/ESMF_StateEx.F90
PASS: openmpi/O: src/Superstructure/State/examples/ESMF_StateReadWriteE=
x.F90
PASS: openmpi/O: src/Superstructure/State/examples/ESMF_StateReconcileE=
x.F90
PASS: openmpi/O: src/Superstructure/WebServices/examples/ESMF_WebServic=
esEx.F90
PASS: openmpi/O: src/addon/NUOPC/examples/ESMF_NUOPCAtmModelEx.F90
PASS: openmpi/O: src/addon/NUOPC/examples/ESMF_NUOPCBasicModelEx.F90




The stdout files for the examples can be found at:
/lcrc/project/ESMF/scripts_dirs/daily_builds/intel_bebop/esmf/examples/=
examplesO/Linux.intel.64.openmpi.default


Found 85 multi-processor examples, 85 passed and 0 failed.



|-------------------- EXHAUSTIVE UNIT TESTS -------------------|
Mon Mar 16 16:43:14 CDT 2020 build_unit_tests -j4 .........PASS
Mon Mar 16 16:58:39 CDT 2020 run_unit_tests ...............PASS




The unit tests in the following files all pass:

PASS: openmpi/O: src/Infrastructure/Array/tests/ESMC_ArrayUTest.C
PASS: openmpi/O: src/Infrastructure/Array/tests/ESMF_ArrayArbIdxSMMUTes=
t.F90
PASS: openmpi/O: src/Infrastructure/Array/tests/ESMF_ArrayCreateGetUTes=
t.F90
PASS: openmpi/O: src/Infrastructure/Array/tests/ESMF_ArrayDataUTest.F90
PASS: openmpi/O: src/Infrastructure/Array/tests/ESMF_ArrayGatherUTest.F=
90
PASS: openmpi/O: src/Infrastructure/Array/tests/ESMF_ArrayHaloUTest.F90
PASS: openmpi/O: src/Infrastructure/Array/tests/ESMF_ArrayIOUTest.F90
PASS: openmpi/O: src/Infrastructure/Array/tests/ESMF_ArrayRedistPerfUTe=
st.F90
PASS: openmpi/O: src/Infrastructure/Array/tests/ESMF_ArrayRedistUTest.F=
90
PASS: openmpi/O: src/Infrastructure/Array/tests/ESMF_ArraySMMFromFileUT=
est.F90
PASS: openmpi/O: src/Infrastructure/Array/tests/ESMF_ArraySMMUTest.F90
PASS: openmpi/O: src/Infrastructure/Array/tests/ESMF_ArrayScatterUTest.=
F90
PASS: openmpi/O: src/Infrastructure/ArrayBundle/tests/ESMF_ArrayBundleC=
reateUTest.F90
PASS: openmpi/O: src/Infrastructure/ArrayBundle/tests/ESMF_ArrayBundleI=
OUTest.F90
PASS: openmpi/O: src/Infrastructure/ArrayBundle/tests/ESMF_ArrayBundleR=
edistUTest.F90
PASS: openmpi/O: src/Infrastructure/ArraySpec/tests/ESMC_ArraySpecUTest=
.C
PASS: openmpi/O: src/Infrastructure/ArraySpec/tests/ESMF_ArraySpecUTest=
.F90
PASS: openmpi/O: src/Infrastructure/Base/tests/ESMC_BaseUTest.C
PASS: openmpi/O: src/Infrastructure/Base/tests/ESMF_BaseUTest.F90
PASS: openmpi/O: src/Infrastructure/Config/tests/ESMC_ConfigUTest.C
PASS: openmpi/O: src/Infrastructure/Config/tests/ESMF_ConfigUTest.F90
PASS: openmpi/O: src/Infrastructure/Container/tests/ESMF_ContainerUTest=
.F90
PASS: openmpi/O: src/Infrastructure/DELayout/tests/ESMF_DELayoutUTest.F=
90
PASS: openmpi/O: src/Infrastructure/DELayout/tests/ESMF_DELayoutWorkQue=
ueUTest.F90
PASS: openmpi/O: src/Infrastructure/DistGrid/tests/ESMC_DistGridUTest.C
PASS: openmpi/O: src/Infrastructure/DistGrid/tests/ESMF_DistGridCreateG=
etUTest.F90
PASS: openmpi/O: src/Infrastructure/Field/tests/ESMC_FieldGridGridRegri=
dCsrvUTest.C
PASS: openmpi/O: src/Infrastructure/Field/tests/ESMC_FieldGridGridRegri=
dUTest.C
PASS: openmpi/O: src/Infrastructure/Field/tests/ESMC_FieldGridRegrid2UT=
est.C
PASS: openmpi/O: src/Infrastructure/Field/tests/ESMC_FieldGridRegridCsr=
v2UTest.C
PASS: openmpi/O: src/Infrastructure/Field/tests/ESMC_FieldGridRegridCsr=
vUTest.C
PASS: openmpi/O: src/Infrastructure/Field/tests/ESMC_FieldGridRegridPar=
UTest.C
PASS: openmpi/O: src/Infrastructure/Field/tests/ESMC_FieldGridRegridUTe=
st.C
PASS: openmpi/O: src/Infrastructure/Field/tests/ESMC_FieldRegridCsrvUTe=
st.C
PASS: openmpi/O: src/Infrastructure/Field/tests/ESMC_FieldRegridUTest.C
PASS: openmpi/O: src/Infrastructure/Field/tests/ESMC_FieldSMMFromFileUT=
est.C
PASS: openmpi/O: src/Infrastructure/Field/tests/ESMC_FieldUTest.C
PASS: openmpi/O: src/Infrastructure/Field/tests/ESMF_FieldArbGridUTest.=
F90
PASS: openmpi/O: src/Infrastructure/Field/tests/ESMF_FieldCreateGetUTes=
t.F90
PASS: openmpi/O: src/Infrastructure/Field/tests/ESMF_FieldGatherUTest.F=
90
PASS: openmpi/O: src/Infrastructure/Field/tests/ESMF_FieldHaloUTest.F90
PASS: openmpi/O: src/Infrastructure/Field/tests/ESMF_FieldIOUTest.F90
PASS: openmpi/O: src/Infrastructure/Field/tests/ESMF_FieldLSSMMUTest.F9=
0
PASS: openmpi/O: src/Infrastructure/Field/tests/ESMF_FieldRedistArbUTes=
t.F90
PASS: openmpi/O: src/Infrastructure/Field/tests/ESMF_FieldRedistUTest.F=
90
PASS: openmpi/O: src/Infrastructure/Field/tests/ESMF_FieldRegridCSUTest=
.F90
PASS: openmpi/O: src/Infrastructure/Field/tests/ESMF_FieldRegridCsrv2nd=
UTest.F90
PASS: openmpi/O: src/Infrastructure/Field/tests/ESMF_FieldRegridCsrvUTe=
st.F90
PASS: openmpi/O: src/Infrastructure/Field/tests/ESMF_FieldRegridUTest.F=
90
PASS: openmpi/O: src/Infrastructure/Field/tests/ESMF_FieldRegridXGSMMUT=
est.F90
PASS: openmpi/O: src/Infrastructure/Field/tests/ESMF_FieldRegridXGUTest=
.F90
PASS: openmpi/O: src/Infrastructure/Field/tests/ESMF_FieldSMMFromFileUT=
est.F90
PASS: openmpi/O: src/Infrastructure/Field/tests/ESMF_FieldSMMUTest.F90
PASS: openmpi/O: src/Infrastructure/Field/tests/ESMF_FieldStressUTest.F=
90
PASS: openmpi/O: src/Infrastructure/Field/tests/ESMF_FieldUTest.F90
PASS: openmpi/O: src/Infrastructure/FieldBundle/tests/ESMF_FieldBundleC=
rGetUTest.F90
PASS: openmpi/O: src/Infrastructure/FieldBundle/tests/ESMF_FieldBundleI=
OUTest.F90
PASS: openmpi/O: src/Infrastructure/FieldBundle/tests/ESMF_FieldBundleR=
edistUTest.F90
PASS: openmpi/O: src/Infrastructure/FieldBundle/tests/ESMF_FieldBundleR=
egridUTest.F90
PASS: openmpi/O: src/Infrastructure/FieldBundle/tests/ESMF_FieldBundleS=
MMUTest.F90
PASS: openmpi/O: src/Infrastructure/FieldBundle/tests/ESMF_FieldBundleU=
Test.F90
PASS: openmpi/O: src/Infrastructure/Grid/tests/ESMC_GridUTest.C
PASS: openmpi/O: src/Infrastructure/Grid/tests/ESMF_GridArbitraryUTest.=
F90
PASS: openmpi/O: src/Infrastructure/Grid/tests/ESMF_GridCoordUTest.F90
PASS: openmpi/O: src/Infrastructure/Grid/tests/ESMF_GridCreateUTest.F90
PASS: openmpi/O: src/Infrastructure/Grid/tests/ESMF_GridItemUTest.F90
PASS: openmpi/O: src/Infrastructure/GridUtil/tests/ESMF_GridToMeshUTest=
.F90
PASS: openmpi/O: src/Infrastructure/IO/tests/ESMCI_IO_NetCDFUTest.C
PASS: openmpi/O: src/Infrastructure/IO/tests/ESMCI_IO_PIOUTest.C
PASS: openmpi/O: src/Infrastructure/IO/tests/ESMC_IO_InqUTest.C
PASS: openmpi/O: src/Infrastructure/IO/tests/ESMF_IOUTest.F90
PASS: openmpi/O: src/Infrastructure/IO/tests/ESMF_IO_PIOUTest.F90
PASS: openmpi/O: src/Infrastructure/IO/tests/ESMF_IO_YAMLUTest.F90
PASS: openmpi/O: src/Infrastructure/LocStream/tests/ESMC_LocStreamUTest=
.C
PASS: openmpi/O: src/Infrastructure/LocStream/tests/ESMF_LocStreamUTest=
.F90
PASS: openmpi/O: src/Infrastructure/LocalArray/tests/ESMF_LocalArrayDat=
aUTest.F90
PASS: openmpi/O: src/Infrastructure/LocalArray/tests/ESMF_LocalArrayUTe=
st.F90
PASS: openmpi/O: src/Infrastructure/LogErr/tests/ESMC_LogErrPerfUTest.C
PASS: openmpi/O: src/Infrastructure/LogErr/tests/ESMC_LogErrUTest.C
PASS: openmpi/O: src/Infrastructure/LogErr/tests/ESMF_LogErrPerfUTest.F=
90
PASS: openmpi/O: src/Infrastructure/LogErr/tests/ESMF_LogErrUTest.F90
PASS: openmpi/O: src/Infrastructure/Mesh/tests/ESMC_MBMesh_BilinearParU=
Test.C
PASS: openmpi/O: src/Infrastructure/Mesh/tests/ESMC_MBMesh_BilinearSing=
leElemUTest.C
PASS: openmpi/O: src/Infrastructure/Mesh/tests/ESMC_MBMesh_BilinearUTes=
t.C
PASS: openmpi/O: src/Infrastructure/Mesh/tests/ESMC_MBMesh_CreateParUTe=
st.C
PASS: openmpi/O: src/Infrastructure/Mesh/tests/ESMC_MBMesh_CreateUTest.=
C
PASS: openmpi/O: src/Infrastructure/Mesh/tests/ESMC_MBMesh_SearchUTest.=
C
PASS: openmpi/O: src/Infrastructure/Mesh/tests/ESMC_MBMesh_SerializeUTe=
st.C
PASS: openmpi/O: src/Infrastructure/Mesh/tests/ESMC_MBMesh_UtilParUTest=
.C
PASS: openmpi/O: src/Infrastructure/Mesh/tests/ESMC_MBMesh_UtilUTest.C
PASS: openmpi/O: src/Infrastructure/Mesh/tests/ESMC_MeshMOABUTest.C
PASS: openmpi/O: src/Infrastructure/Mesh/tests/ESMC_MeshUTest.C
PASS: openmpi/O: src/Infrastructure/Mesh/tests/ESMC_MeshVTKUTest.C
PASS: openmpi/O: src/Infrastructure/Mesh/tests/ESMC_Proj4UTest.C
PASS: openmpi/O: src/Infrastructure/Mesh/tests/ESMF_MeshOpUTest.F90
PASS: openmpi/O: src/Infrastructure/Mesh/tests/ESMF_MeshUTest.F90
PASS: openmpi/O: src/Infrastructure/PointList/tests/ESMF_PointListUTest=
.F90
PASS: openmpi/O: src/Infrastructure/Route/tests/ESMF_RouteHandleAdvance=
dUTest.F90
PASS: openmpi/O: src/Infrastructure/Route/tests/ESMF_RouteHandleUTest.F=
90
PASS: openmpi/O: src/Infrastructure/TimeMgr/tests/ESMC_CalendarUTest.C
PASS: openmpi/O: src/Infrastructure/TimeMgr/tests/ESMC_ClockUTest.C
PASS: openmpi/O: src/Infrastructure/TimeMgr/tests/ESMC_TimeIntervalUTes=
t.C
PASS: openmpi/O: src/Infrastructure/TimeMgr/tests/ESMC_TimeUTest.C
PASS: openmpi/O: src/Infrastructure/TimeMgr/tests/ESMF_AlarmUTest.F90
PASS: openmpi/O: src/Infrastructure/TimeMgr/tests/ESMF_CalRangeUTest.F9=
0
PASS: openmpi/O: src/Infrastructure/TimeMgr/tests/ESMF_CalendarUTest.F9=
0
PASS: openmpi/O: src/Infrastructure/TimeMgr/tests/ESMF_ClockUTest.F90
PASS: openmpi/O: src/Infrastructure/TimeMgr/tests/ESMF_TimeIntervalUTes=
t.F90
PASS: openmpi/O: src/Infrastructure/TimeMgr/tests/ESMF_TimeUTest.F90
PASS: openmpi/O: src/Infrastructure/Trace/tests/ESMC_TraceRegionUTest.C
PASS: openmpi/O: src/Infrastructure/Trace/tests/ESMF_ProfileUTest.F90
PASS: openmpi/O: src/Infrastructure/Trace/tests/ESMF_TraceClkMonoSyncUT=
est.F90
PASS: openmpi/O: src/Infrastructure/Trace/tests/ESMF_TraceClkMonoUTest.=
F90
PASS: openmpi/O: src/Infrastructure/Trace/tests/ESMF_TraceIOUTest.F90
PASS: openmpi/O: src/Infrastructure/Trace/tests/ESMF_TraceMPIUTest.F90
PASS: openmpi/O: src/Infrastructure/Trace/tests/ESMF_TraceUTest.F90
PASS: openmpi/O: src/Infrastructure/Util/tests/ESMF_FortranWordsizeUTes=
t.F90
PASS: openmpi/O: src/Infrastructure/Util/tests/ESMF_InitMacrosUTest.F90
PASS: openmpi/O: src/Infrastructure/Util/tests/ESMF_TypeKindGetUTest.F9=
0
PASS: openmpi/O: src/Infrastructure/Util/tests/ESMF_UtilUTest.F90
PASS: openmpi/O: src/Infrastructure/VM/tests/ESMC_VMUTest.C
PASS: openmpi/O: src/Infrastructure/VM/tests/ESMF_VMAccUTest.F90
PASS: openmpi/O: src/Infrastructure/VM/tests/ESMF_VMAllGatherUTest.F90
PASS: openmpi/O: src/Infrastructure/VM/tests/ESMF_VMAllGatherVUTest.F90
PASS: openmpi/O: src/Infrastructure/VM/tests/ESMF_VMAllToAllUTest.F90
PASS: openmpi/O: src/Infrastructure/VM/tests/ESMF_VMAllToAllVUTest.F90
PASS: openmpi/O: src/Infrastructure/VM/tests/ESMF_VMBarrierUTest.F90
PASS: openmpi/O: src/Infrastructure/VM/tests/ESMF_VMBroadcastUTest.F90
PASS: openmpi/O: src/Infrastructure/VM/tests/ESMF_VMComponentUTest.F90
PASS: openmpi/O: src/Infrastructure/VM/tests/ESMF_VMGatherUTest.F90
PASS: openmpi/O: src/Infrastructure/VM/tests/ESMF_VMOpenMPUTest.F90
PASS: openmpi/O: src/Infrastructure/VM/tests/ESMF_VMScatterUTest.F90
PASS: openmpi/O: src/Infrastructure/VM/tests/ESMF_VMSendNbVMRecvNbUTest=
.F90
PASS: openmpi/O: src/Infrastructure/VM/tests/ESMF_VMSendRecvNbUTest.F90
PASS: openmpi/O: src/Infrastructure/VM/tests/ESMF_VMSendRecvUTest.F90
PASS: openmpi/O: src/Infrastructure/VM/tests/ESMF_VMSendVMRecvUTest.F90
PASS: openmpi/O: src/Infrastructure/VM/tests/ESMF_VMUTest.F90
PASS: openmpi/O: src/Infrastructure/VM/tests/ESMF_VMUserMpiInitUTest.F9=
0
PASS: openmpi/O: src/Infrastructure/XGrid/tests/ESMC_XGridUTest.C
PASS: openmpi/O: src/Infrastructure/XGrid/tests/ESMF_XGridMaskingUTest.=
F90
PASS: openmpi/O: src/Infrastructure/XGrid/tests/ESMF_XGridUTest.F90
PASS: openmpi/O: src/Superstructure/AttributeAPI/tests/ESMF_AttInternal=
GridUTest.F90
PASS: openmpi/O: src/Superstructure/AttributeAPI/tests/ESMF_AttPackABun=
dleUTest.F90
PASS: openmpi/O: src/Superstructure/AttributeAPI/tests/ESMF_AttPackArra=
yUTest.F90
PASS: openmpi/O: src/Superstructure/AttributeAPI/tests/ESMF_AttPackCplC=
ompUTest.F90
PASS: openmpi/O: src/Superstructure/AttributeAPI/tests/ESMF_AttPackDist=
GridUTest.F90
PASS: openmpi/O: src/Superstructure/AttributeAPI/tests/ESMF_AttPackFBun=
dleUTest.F90
PASS: openmpi/O: src/Superstructure/AttributeAPI/tests/ESMF_AttPackFiel=
dUTest.F90
PASS: openmpi/O: src/Superstructure/AttributeAPI/tests/ESMF_AttPackGrid=
CompUTest.F90
PASS: openmpi/O: src/Superstructure/AttributeAPI/tests/ESMF_AttPackGrid=
UTest.F90
PASS: openmpi/O: src/Superstructure/AttributeAPI/tests/ESMF_AttPackLocS=
treamUTest.F90
PASS: openmpi/O: src/Superstructure/AttributeAPI/tests/ESMF_AttPackSciC=
ompUTest.F90
PASS: openmpi/O: src/Superstructure/AttributeAPI/tests/ESMF_AttPackStat=
eUTest.F90
PASS: openmpi/O: src/Superstructure/AttributeAPI/tests/ESMF_AttReadCplC=
ompUTest.F90
PASS: openmpi/O: src/Superstructure/AttributeAPI/tests/ESMF_AttReadFiel=
dUTest.F90
PASS: openmpi/O: src/Superstructure/AttributeAPI/tests/ESMF_AttReadGrid=
CompUTest.F90
PASS: openmpi/O: src/Superstructure/AttributeAPI/tests/ESMF_AttributeAB=
undleUTest.F90
PASS: openmpi/O: src/Superstructure/AttributeAPI/tests/ESMF_AttributeAr=
rayUTest.F90
PASS: openmpi/O: src/Superstructure/AttributeAPI/tests/ESMF_AttributeAu=
toLinkUTest.F90
PASS: openmpi/O: src/Superstructure/AttributeAPI/tests/ESMF_AttributeCp=
lCompUTest.F90
PASS: openmpi/O: src/Superstructure/AttributeAPI/tests/ESMF_AttributeDi=
stGridUTest.F90
PASS: openmpi/O: src/Superstructure/AttributeAPI/tests/ESMF_AttributeFB=
undleUTest.F90
PASS: openmpi/O: src/Superstructure/AttributeAPI/tests/ESMF_AttributeFi=
eldUTest.F90
PASS: openmpi/O: src/Superstructure/AttributeAPI/tests/ESMF_AttributeGr=
idCompUTest.F90
PASS: openmpi/O: src/Superstructure/AttributeAPI/tests/ESMF_AttributeGr=
idUTest.F90
PASS: openmpi/O: src/Superstructure/AttributeAPI/tests/ESMF_AttributeJS=
ONUTest.F90
PASS: openmpi/O: src/Superstructure/AttributeAPI/tests/ESMF_AttributeLo=
cStreamUTest.F90
PASS: openmpi/O: src/Superstructure/AttributeAPI/tests/ESMF_AttributeSc=
iCompUTest.F90
PASS: openmpi/O: src/Superstructure/AttributeAPI/tests/ESMF_AttributeSt=
ateUTest.F90
PASS: openmpi/O: src/Superstructure/AttributeAPI/tests/ESMF_AttributeUp=
dateCIMRespPartyUTest.F90
PASS: openmpi/O: src/Superstructure/AttributeAPI/tests/ESMF_AttributeUp=
dateClosedLoopTreesUTest.F90
PASS: openmpi/O: src/Superstructure/AttributeAPI/tests/ESMF_AttributeUp=
dateComponentUTest.F90
PASS: openmpi/O: src/Superstructure/AttributeAPI/tests/ESMF_AttributeUp=
dateContainerStressUTest.F90
PASS: openmpi/O: src/Superstructure/AttributeAPI/tests/ESMF_AttributeUp=
dateMultiReconcileUTest.F90
PASS: openmpi/O: src/Superstructure/AttributeAPI/tests/ESMF_AttributeUp=
dateReconcileUTest.F90
PASS: openmpi/O: src/Superstructure/AttributeAPI/tests/ESMF_AttributeUp=
dateRemoveOnlyUTest.F90
PASS: openmpi/O: src/Superstructure/AttributeAPI/tests/ESMF_AttributeUp=
dateUTest.F90
PASS: openmpi/O: src/Superstructure/AttributeAPI/tests/ESMF_AttributeWr=
iteInternalUTest.F90
PASS: openmpi/O: src/Superstructure/AttributeAPI/tests/ESMF_AttributeXM=
LUTest.F90
PASS: openmpi/O: src/Superstructure/Component/tests/ESMC_ComponentUTest=
.C
PASS: openmpi/O: src/Superstructure/Component/tests/ESMF_CompSetServUTe=
st.F90
PASS: openmpi/O: src/Superstructure/Component/tests/ESMF_CompTunnelUTes=
t.F90
PASS: openmpi/O: src/Superstructure/Component/tests/ESMF_ComponentUTest=
.F90
PASS: openmpi/O: src/Superstructure/Component/tests/ESMF_CplCompCreateU=
Test.F90
PASS: openmpi/O: src/Superstructure/Component/tests/ESMF_GridCompCreate=
UTest.F90
PASS: openmpi/O: src/Superstructure/Component/tests/ESMF_SciCompCreateU=
Test.F90
PASS: openmpi/O: src/Superstructure/Component/tests/ESMF_StdCompMethods=
UTest.F90
PASS: openmpi/O: src/Superstructure/ESMFMod/tests/ESMF_FrameworkUTest.F=
90
PASS: openmpi/O: src/Superstructure/IOAPI/tests/ESMF_IOCompUTest.F90
PASS: openmpi/O: src/Superstructure/PreESMFMod/tests/ESMF_FileRegridUTe=
st.F90
PASS: openmpi/O: src/Superstructure/PreESMFMod/tests/ESMF_RegridWeightG=
enUTest.F90
PASS: openmpi/O: src/Superstructure/State/tests/ESMC_StateUTest.C
PASS: openmpi/O: src/Superstructure/State/tests/ESMF_StateCreateUTest.F=
90
PASS: openmpi/O: src/Superstructure/State/tests/ESMF_StateReadWriteUTes=
t.F90
PASS: openmpi/O: src/Superstructure/State/tests/ESMF_StateReconcileUTes=
t.F90
PASS: openmpi/O: src/Superstructure/State/tests/ESMF_StateUTest.F90
PASS: openmpi/O: src/addon/NUOPC/tests/ESMF_NUOPC_UTest.F90
PASS: openmpi/O: src/epilogue/tests/ESMCI_TestUTest.C
PASS: openmpi/O: src/epilogue/tests/ESMC_TestUTest.C
PASS: openmpi/O: src/epilogue/tests/ESMF_TestUTest.F90
PASS: openmpi/O: src/prologue/tests/ESMCI_ExceptionsUTest.C
PASS: openmpi/O: src/prologue/tests/ESMCI_FeatureUTest.C
PASS: openmpi/O: src/prologue/tests/ESMF_F90ArrayPtrUTest.F90
PASS: openmpi/O: src/prologue/tests/ESMF_FeatureUTest.F90
PASS: openmpi/O: src/prologue/tests/ESMF_LAPACKUTest.F90
PASS: openmpi/O: src/prologue/tests/ESMF_StringUTest.F90
PASS: openmpi/O: src/prologue/tests/ESMF_WordsizeUTest.F90


The following test harness unit tests pass:
PASS: openmpi/O: ESMF_array_default_NP4UTest
PASS: openmpi/O: ESMF_field_default_NP4UTest


The log and stdout files for the unit tests can be found at:
/lcrc/project/ESMF/scripts_dirs/daily_builds/intel_bebop/esmf/test/test=
O/Linux.intel.64.openmpi.default


Found 9075 exhaustive multi-processor unit tests, 9075 passed and 0 fai=
led.





 The tarballs of the tests and examples directories can be found at:
 /lcrc/project/ESMF/scripts_dirs/daily_builds/intel_bebop/esmf_logs/200=
3_test.
 These tarballs contain the *Log and *stdout files only, not the execut=
ables.
 This directory also contains failed build output files with the naming=
 convention of=20
 build_ESMF_BOPT_(day)(platform)ESMF_OS ESMF_ABI ESMF_COMPILER ESMF_COM=
M.
 For example, if the build fails on longs on the 19th of the month with=
 ESMF_BOPT=3Dg, the file=20
 would be called 'build_g_19longslinux32pgimpiuni'.
Test_results:yellow
Day_of_Week:Monday
Test_Failures:120
